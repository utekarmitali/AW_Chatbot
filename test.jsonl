{"instruction": "Answer the following AWS FAQ question", "input": "Which AWS regions offer server-side encryption for Kinesis Data Streams?", "output": "Kinesis Data Streams server-side encryption is available in the AWS GovCloud Region and all public Regions except the China (Beijing) Region. [Source: https://aws.amazon.com/kinesis/data-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I lock a document to prevent it from receiving further feedback?", "output": "Yes, you can disable feedback for a document and prevent it from receiving additional comments. You can re-enable feedback and users will be able to post comments again. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I customize pricing or terms for select customers?", "output": "Yes. Private offers allow you to make public products available to select AWS customers and to set terms including price, duration, payment schedule, DSA, or refund policy. For more information, seeCreate private offers. [Source: https://aws.amazon.com/data-exchange/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does AWS DataSync access HDFS on my Hadoop cluster?", "output": "AWS DataSync uses an agent that you deploy into your IT environment or into Amazon EC2 to access your Hadoop cluster. The DataSync agent acts as an HDFS client and communicates with the NameNodes and DataNodes in your clusters. When you start a task, DataSync queries the primary NameNode to determine the locations of files and folders on the cluster. DataSync then communicates with the DataNodes in the cluster to copy files and folders to, or from, HDFS. [Source: https://aws.amazon.com/datasync/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use Outposts rack when it is not connected to the AWS Region or in a disconnected environment?", "output": "An Outpost relies on connectivity to the parent AWS Region. Outposts rack is not designed for disconnected operations or environments with limited to no connectivity. We recommend that customers have highly available networking connections back to their AWS Region. If interested in leveraging AWS services in disconnected environments such as cruise ships or remote mining locations, learn more about AWS services such as Snowball Edge, which is optimized to operate in environments with limited to no connectivity. [Source: https://aws.amazon.com/outposts/rack/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How fast is S3 Transfer Acceleration?", "output": "S3 Transfer Acceleration helps you fully use your bandwidth, minimize the effect of distance on throughput, and is designed to ensure consistently fast data transfer to Amazon S3 regardless of your client\u2019s location. The amount of acceleration primarily depends on your available bandwidth, the distance between the source and destination, and packet loss rates on the network path. Generally, you will see more acceleration when the source is farther from the destination, when there is more available bandwidth, and/or when the object size is bigger. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I enable Amazon S3 Replication metrics and events?", "output": "Amazon S3 Replication metrics and events can be enabled for each new or existing replication rules, and are enabled by default for S3 Replication Time Control enabled rules. You can access S3 Replication metrics through the Amazon S3 console and Amazon CloudWatch. Like other Amazon S3 events, S3 Replication events are available through Amazon Simple Queue Service (Amazon SQS), Amazon Simple Notification Service (Amazon SNS), or AWS Lambda. To learn more, please\u00a0visitMonitoring progress with replication metrics and Amazon S3 Event Notificationsin the Amazon S3 developer guide. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What types of failures are covered by Storage Gateway with high availability?", "output": "Storage Gateway with VMware HA enabled and application monitoring configured will detect and recover from hardware failures, hypervisor failures, network failures, as well as software issues that lead to connection timeouts or file-share, volume, or virtual tape library unavailability. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What types of applications can benefit from using EFA?", "output": "HPC applications distribute computational workloads across a cluster of instances for parallel processing. Examples of HPC applications include computational fluid dynamics (CFD), crash simulations, and weather simulations. HPC applications are generally written using the Message Passing Interface (MPI) and impose stringent requirements for inter-instance communication in terms of both latency and bandwidth. Applications using MPI and other HPC middleware that supports the libfabric communication stack can benefit from EFA. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which VMware versions and features do you support using AWS Backup?", "output": "AWS Backup supports VMware ESXi 6.7.X, and 7.0.X VMs running on NFS, VMFS, and VSAN datastores on premises, in VMware CloudTM on AWS, and on VMware CloudTM on AWS Outposts. And AWS Backup supports both SCSI Hot-Add and Network Block Device (NBD) transport modes for copying data from source virtual machines (VMs) to AWS. [Source: https://aws.amazon.com/backup/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I trigger workflow actions on user downloads?", "output": "No. Processing can be invoked only on file arrival using the inbound endpoint. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I move files from my trading partner's business systems to my S3 bucket?", "output": "You can use AWS Transfer Familys fully managed SFTP/FTPS/AS2 capabilities to receive EDI documents that are generated from your trading partners business systems. EDI documents received using AWS Transfer Familys connectivity capabilities are automatically uploaded to Amazon S3 where they can then be transformed into JSON and XML formatted outputs using AWS B2B Data Interchange. Alternatively, you can use any other any other EDI connectivity tool to upload EDI documents to S3. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I remove an AWS account that I created using Organizations and make it a standalone account?", "output": "Yes. When you create an account in an organization using the AWS Organizations console, API, or CLI commands, AWS does not collect all of the information required of standalone accounts. For each account that you want to make standalone, you need to update this information, which can include: providing contact information,providing a valid payment method, and choosing a support plan option. AWS uses the payment method to charge for any billable (not AWS Free Tier) AWS activity that occurs while the account is not attached to an organization. For more information, seeRemoving a Member Account from Your Organization (https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_remove.html?org_product_faq_removeaccount). [Source: https://aws.amazon.com/organizations/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I have two gateways writing independent data to the same bucket?", "output": "We do not recommend configuring multiple writers to a single bucket because it can lead to unpredictable results. You could enforce unique object names or prefixes through your application workflow. S3 File Gateway will emit Health Notifications when conflicts occur in such a setup. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I run imported virtual machines in Amazon Virtual Private Cloud (Amazon VPC)?", "output": "Yes, you can launch imported virtual machines within Amazon VPC. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is there a free trial?", "output": "Yes, there is a 30-day free trial for each new account to Macie. The free trial includes 30 days of automated sensitive data discovery in S3 and bucket-level security and access controls. The AWS Management Console provides a cost estimate of the service based on your total number of buckets in the account. If you are in a multi-account configuration, the cost estimate is rolled up across all accounts to show you what your estimated total would be after each accounts free trial ends. Macie also includes 1 GB of data processed for sensitive data discovery per month at no cost. This free tier offer does not expire and is not bound by the 30-day free trial period. [Source: https://aws.amazon.com/macie/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How is Amazon Comprehend priced?", "output": "Refer to the Amazon Comprehendpricing page (https://aws.amazon.com/comprehend/pricing/)to learn more about pricing tiers and discounts. [Source: https://aws.amazon.com/comprehend/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Who should use Amazon MQ?", "output": "Amazon MQ is suitable for enterprise IT professionals, developers, and architects who plan to adopt industry standard messaging APIs and protocols to decouple and scale their applications on the cloud without the operational burden of managing the message broker itself. [Source: https://aws.amazon.com/amazon-mq/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does AWS WAF block or allow traffic?", "output": "As the underlying service receives requests for your web sites, it forwards those requests to AWS WAF for inspection against your rules. Once a request meets a condition defined in your rules, AWS WAF instructs the underlying service to either block or allow the request based on the action you define. [Source: https://aws.amazon.com/waf/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the relevant limits to using HLS or DASH?", "output": "A Kinesis video stream supports a maximum of ten active HLS or DASH streaming sessions. If a new session is created when the maximum number of sessions is already active, the oldest (earliest created) session is closed. The number of active GetMedia connections on a Kinesis video stream does not count against this limit, and the number of active HLS sessions does not count against the active GetMedia connection limit. SeeKinesis Video Streams Limits (https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/limits.html)for more details. [Source: https://aws.amazon.com/kinesis/video-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why would I want manual control over Kubernetes version updates?", "output": "New versions of Kubernetes introduce significant change to the Kubernetes API, which can change application behavior. Manual control over Kubernetes cluster versioning lets you test applications against new versions of Kubernetes before upgrading production clusters. Amazon EKS offers the ability to choose when you introduce changes to your EKS cluster. [Source: https://aws.amazon.com/eks/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "I do not understand the language supported in the phone verification step. How do I proceed?", "output": "Today, AWS supports English, French, German, Korean, Spanish, Japanese, Mandarin (Chinese) and Portugese during the phone verification process. For all other languages that are not supported in the phone verification step, English will be the default language. We are actively working on improving the user experience for our regional customers and to reduce the friction in completing this step. If you continue to experience problems with the languages supported within the registration process, click here for assistance on completing the account creation process. [Source: https://aws.amazon.com/free/registration-faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the failure scenarios covered and not covered by the feature?", "output": "With Multi-AZ with Standby, Amazon OpenSearch Service detects and automatically recovers from some of the infrastructure failures. Amazon OpenSearch Service automatically fails over from active to standby nodes in under a minute when any of the following events occur:Loss of one active AZ or all nodes in an active AZLoss of connectivity to one active AZInstance hardware failure in the active AZStorage failure on a node in the active AZCurrently Multi-AZ with Standby does not cover the following events:Loss of master Quorum, as recovery from this event can take several minutesLoss of multiple Availability ZonesLoss of connectivity to a RegionLoss of more than 50% nodes in more than one AZDowntime caused due to insufficient compute or storage as a result of change in workload characteristicsDowntime caused due to rouge queriesLoss of one or more services that Amazon OpenSearch Service depends on like ARPS and ALBDowntime of OpenSearch Dashboard during version upgrades [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can a cluster span multiple AZs?", "output": "Yes. When creating a cluster or adding nodes to an existing cluster, you can choose the AZs for the new nodes. You can either specify the requested number of nodes in each AZ or select Spread Nodes Across Zones. If the cluster is in Amazon VPC, nodes can only be placed in AZs that are part of the selected cache subnet group. For additional details, please seeElastiCache VPC documentation (https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/VPCs.CreatingCacheCluster.html). [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I launch an encrypted EBS instance from an unencrypted AMI?", "output": "Yes. See technical documentation for details. [Source: https://aws.amazon.com/ebs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I choose the right Amazon Machine Image (AMI) for my T2 instances?", "output": "You will want to verify that the minimum memory requirements of your operating system and applications are within the memory allocated for each T2 instance size (for example, 512 MiB for t2.nano). Operating systems with Graphical User Interfaces (GUI) that consume significant memory and CPU, for example Microsoft Windows, might need a t2.micro or larger instance size for many use cases. You can find AMIs suitable for the t2.nano instance types onAWS Marketplace. Windows customers who do not need the GUI can use theMicrosoft Windows Server 2012 R2 Core AMI. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why am I charged when my Elastic IP address is not associated with a running instance?", "output": "In order to help ensure our customers are efficiently using the Elastic IP addresses, we impose a small hourly charge for each address when it is not associated with a running instance. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started with Desktop Browser Testing on AWS Device Farm?", "output": "To get started, please see our getting started guidehere (https://docs.aws.amazon.com/devicefarm/latest/testgrid/what-is-testgrid.html). [Source: https://aws.amazon.com/device-farm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why should I use Amazon Elastic Transcoder?", "output": "Amazon Elastic Transcoder manages all the complexity of running media transcoding in the AWS cloud. Amazon Elastic Transcoder enables you to focus on your content, such as the devices you want to support and the quality levels you want to provide, rather than managing the infrastructure and software needed for conversion. Amazon Elastic Transcoder scales to handle the largest encoding jobs. As with all Amazon Web Services, there are no up-front investments required, and you pay only for the resources that you use. We offer a free tier that enables you to explore the service and transcode up to up to 20 minutes of SD video or 10 minutes of HD video a month free of charge. To see terms and additional information on the free tier program, please visit theAWS Free Usage Tier page. [Source: https://aws.amazon.com/elastictranscoder/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is there any limit on the size of each log entry?", "output": "Yes. Each log entry made into CloudWatch will be limited to 255,000 characters. If your log entry is bigger than that, it will be truncated to 255,000 characters. [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What Aurora engines and versions support Data API?", "output": "Data API AWS Region and database version availability forAurora Serverless v2 (https://aws.amazon.com/rds/aurora/serverless/)and Aurora provisioned instances may be found in ourdocumentation (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html). Customers currently using Data API for Aurora Serverless v1 are encouraged to migrate to Aurora Serverless v2 to take advantage of the redesigned Data API and the more granular scaling of Aurora Serverless v2. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What checksum algorithms does Amazon S3 support for data integrity checking?", "output": "Amazon S3 uses a combination of Content-MD5 checksums, secure hash algorithms (SHAs), and cyclic redundancy checks (CRCs) to verify data integrity. Amazon S3 performs these checksums on data at rest and repairs any disparity using redundant data. In addition,\u00a0the latest AWS SDKs automatically calculate efficient CRC-based checksums for all uploads.\u00a0S3 independently verifies that checksum and only accepts objects after confirming that data integrity was maintained in transit over the public internet. If a version of the SDK that does not provide pre-calculated checksums is used to upload an object, S3 calculates a CRC-based checksum of the whole object, even for multipart uploads. Checksums are stored in object metadata and are therefore available to verify data integrity at any time. You can choose from five supported checksum algorithms for data integrity checking on your upload and download requests. You can choose a SHA-1, SHA-256, CRC32, CRC32C, or CRC64NVME checksum algorithm, depending on your application needs. You can automatically calculate and verify checksums as you store or retrieve data from S3, and can access the checksum information at any time using the HeadObject S3 API, the GetObjectAttributes S3 API or an S3 Inventory report. Calculating a checksum as you stream data into S3 saves you time as you\u2019re able to both verify and transmit your data in a single pass, instead of as two sequential operations. Using checksums for data validation is a best practice for data durability, and these capabilities increase the performance and reduce the cost to do so. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How is AWS DataSync different from using command line tools such as rsync or the Amazon S3 command line interface?", "output": "AWS DataSync fully automates and accelerates moving large active datasets to AWS. It is natively integrated with Amazon S3, Amazon EFS, Amazon FSx,Amazon CloudWatch (https://aws.amazon.com/cloudwatch/), andAWS CloudTrail (https://aws.amazon.com/cloudtrail/), which provides seamless and secure access to your storage services, as well as detailed monitoring of the transfer.DataSync uses a purpose-built network protocol and scale-out architecture to transfer data.For data transfer between on premises and AWS Storage services, a single DataSync task is capable of fully utilizing a 10 Gbps network link.DataSync fully automates the data transfer. It comes with retry and network resiliency mechanisms, network optimizations, built-in task scheduling, auditing via task reports, monitoring via the DataSync API and Console, and CloudWatch metrics, events and logs that provide granular visibility into the transfer process. DataSync performs data integrity verification both during the transfer and at the end of the transfer.DataSync provides end-to-end security, and integrates directly with AWS storage services. All data transferred between the source and destination is encrypted via TLS, and access to your AWS storage is enabled via built-in AWS security mechanisms such as IAM roles. DataSync with VPC endpoints are enabled to ensure that data transferred between an organization and AWS does not traverse the public internet, further increasing the security of data as it is copied over the network. [Source: https://aws.amazon.com/datasync/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When should I use Data API with Aurora instead of database drivers?", "output": "You should useData API (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html)for new modern applications, particularly those built withAWS Lambda (https://aws.amazon.com/lambda/)that need to access Aurora in a request/response model. You should use database drivers instead of Data API and manage persistent database connections when an existing application is highly coupled with database drivers, when there are long-running queries, or when the developer wants to take advantage of database features such as temporary tables or use session variables. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does AWS Glue monitor dependencies?", "output": "AWS Glue manages dependencies between two or more jobs or dependencies on external events using triggers. Triggers can watch one or more jobs as well as invoke one or more jobs. You can either have a scheduled trigger that invokes jobs periodically, an on-demand trigger, or a job completion trigger. [Source: https://aws.amazon.com/glue/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If a member account is removed from my organization, what happens to the organization agreements that have been accepted on its behalf?", "output": "When a member account is removed from an organization (e.g. by leaving the organization, or by being removed from the organization by themanagement account), any organization agreements accepted on its behalf will no longer apply to that member account.Managementaccount administrators should alert member accounts prior to removing those accounts from the organization so that member accounts can put new account agreements in place, if necessary. Before member account owners leave an organization, they should determine (with the assistance of legal, privacy, or compliance teams, if appropriate) whether it is necessary to put new agreements in place. [Source: https://aws.amazon.com/artifact/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which languages does the Amazon WorkDocs SDK support?", "output": "The WorkDocs SDK is available for Java, Python, Go, Java Script, .NET, PHP, and Ruby. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I compile my AWS Lambda function Java code?", "output": "You can use standard tools like Maven or Gradle to compile your Lambda function. Your build process should mimic the same build process you would use to compile any Java code that depends on the AWS SDK. Run your Java compiler tool on your source files and include the AWS SDK 1.9 or later with transitive dependencies on your classpath. For more details, see our documentation. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When should I use Amazon SWF vs. AWS Step Functions?", "output": "AWS Step Functions is a fully managed service that makes it easy to coordinate the components of distributed applications and microservices using visual workflows. Instead of writing a Decider program, you define state machines in JSON. AWS customers should consider using Step Functions for new applications. If Step Functions does not fit your needs, then you should consider Amazon Simple Workflow (SWF). Amazon SWF provides you complete control over your orchestration logic, but increases the complexity of developing applications. You may write decider programs in the programming language of your choice, or you may use the Flow framework to use programming constructs that structure asynchronous interactions for you. AWS will continue to provide the Amazon SWF service, Flow framework, and support all Amazon SWF customers. [Source: https://aws.amazon.com/swf/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why would I use an S3 Lifecycle policy to expire incomplete multipart uploads?", "output": "The S3 Lifecycle policy that expires incomplete multipart uploads allows you to save on costs by limiting the time non-completed multipart uploads are stored. For example, if your application uploads several multipart object parts, but never commits them, you will still be charged for that storage. This policy can lower your S3 storage bill by automatically removing incomplete multipart uploads and the associated storage after a predefined number of days. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What does the Amazon MSK SLA guarantee?", "output": "Our Amazon MSK SLA guarantees a Monthly Uptime Percentage of at least 99.9% for Amazon MSK (including MSK Serverless and MSK Connect). [Source: https://aws.amazon.com/msk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does enabling FSR for my snapshot speed up snapshot creation?", "output": "No. FSR-enabled snapshots improve restoring backup data from your snapshot to your volumes. FSR-enabled snapshots do not speed up snapshot creation time. [Source: https://aws.amazon.com/ebs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon Redshift support single sign-on?", "output": "<p>Yes. Customers who want to use their corporate identity providers such as Microsoft Azure Active Directory, Active Directory Federation Services, Okta, Ping Federate, or other SAML compliant identity providers can configure Amazon Redshift to provide single sign-on. You can sign on to Amazon Redshift cluster with Microsoft Azure Active Directory (AD) identities. This allows you to be able to sign on to Redshift without duplicating Azure Active Directory identities in Redshift.</p> [Source: https://aws.amazon.com/redshift/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I optimize my spend on AWS Fargate?", "output": "\nAWS offers Spot instances for AWS Fargate tasks, which utilizes spare compute capacity that is available at a lower price than on-demand instances. By using spot instances you can run interruption tolerant Amazon ECS Tasks at up to a 70 percent discount off the AWS Fargate price.\u00a0\nAWS introduced AWS Fargate Savings Plans, a discount model that provides you with the same discounts as Reserved Instances, in exchange for a commitment to use a specific amount (measured in dollars per hour) of compute power over a one- or three-year period.\u00a0\nAWS Graviton processors are designed by AWS to deliver the best price performance for your cloud workloads running in Amazon EC2, AWS managed containers, and other managed services. AWS Graviton provides up to 40 percent better price performance over comparable x86-based instances. AWS Graviton processors are more energy efficient and use up to 60 percent less energy for the same performance than comparable EC2 instances.\u00a0\nAWS Fargate is included in the AWS Compute Optimizer, which allows you to easily identify and remediate inefficient configurations.\n [Source: https://aws.amazon.com/fargate/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "I'd like AppFlow to support another SaaS integration. How can I make that request?", "output": "Pleasecontact us (mailto:appflow-integrations@amazon.com)to let us know the name of the SaaS vendor as well as your use case. [Source: https://aws.amazon.com/appflow/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I copy backups of my Amazon FSx file systems across AWS Regions and AWS accounts?", "output": "You can configure your backup plans on AWS Backup to periodically create and copy backups of your Amazon FSx file systems to other AWS Regions, other AWS accounts, or both, with your desired frequency and retention policy. For cross-account backup copies, you use your AWS Organizations management account to designate source and destination accounts. [Source: https://aws.amazon.com/fsx/windows/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I monitor my Amazon API Gateway APIs?", "output": "Amazon API Gateway logs API calls, latency, and error rates to Amazon CloudWatch in your AWS account. The metrics are also available through the Amazon API Gateway console in a REST API dashboard. API Gateway also meters utilization by third-party developers, the data is available in the API Gateway console and through the APIs. [Source: https://aws.amazon.com/api-gateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How will I be charged and billed for my use of Amazon S3?", "output": "There are no set up charges or commitments to begin using Amazon S3. At the end of the month, you will automatically be charged for that month\u2019s usage. You can view your charges for the current billing period at any time by logging into your Amazon Web Services account, and selecting the 'Billing Dashboard' associated with your console profile. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will this affect running instances?", "output": "No, opting into vCPU-based limits will not affect any running instances. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I tell if an application needs more CPU resources than a Micro instance is providing?", "output": "The CloudWatch metric for CPU utilization will report 100% utilization if the instance bursts so much that it exceeds its available CPU resources during that CloudWatch monitored minute. CloudWatch reporting 100% CPU utilization is your signal that you should consider scaling \u2013 manually or via Auto Scaling \u2013 up to a larger instance type or scale out to multiple Micro instances. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I enable both Lambda SnapStart and PC on the same function?", "output": "No. Lambda SnapStart and PC cannot be enabled at the same time, on the same function. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do volumes need to be un-mounted to take a snapshot?", "output": "No, snapshots can be done in real time while the volume is attached and in use. However, snapshots only capture data that has been written to your Amazon EBS volume, which might exclude any data that has been locally cached by your application or OS. To ensure consistent snapshots on volumes attached to an instance, we recommend detaching the volume cleanly, issuing the snapshot command, and then reattaching the volume. For Amazon EBS volumes that serve as root devices, we recommend shutting down the machine to take a clean snapshot. [Source: https://aws.amazon.com/ebs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Amazon SES ensure that incoming mail is free of spam and viruses?", "output": "Amazon SES uses a number of spam and virus protection measures. It uses block lists to prevent mail from known spammers from entering the system in the first place. It also performs virus scans on every incoming email that contains an attachment. Amazon SES makes its spam detection verdicts available to you, enabling you to decide if you trust each message. In addition to the spam and virus verdicts, Amazon SES provides the DKIM and SPF check results. [Source: https://aws.amazon.com/ses/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What protocols are supported by ENA Express?", "output": "ENA Express supports TCP by default. UDP can optionally be enabled through an API argument or within the management console. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I get started with Internet Monitor?", "output": "To use Internet Monitor, you create a monitor and associate your application's resources with it, Amazon Virtual Private Clouds (VPCs), CloudFront distributions, or WorkSpaces directories, to enable Internet Monitor to know where your application's internet traffic is. Internet Monitor then provides internet measurements from AWS that are specific to the locations and networks that communicate with your application.Then you can use the CloudWatch dashboard to learn about health events, view performance and availability scores, explore your application's historical data at different geographic granularities, and get insights into how to configure your application to improve performance for your end users.Internet Monitor publishes internet measurements to CloudWatch Logs and CloudWatch Metrics, so you can easily use CloudWatch tools to better understand application health in geographies and networks specific to your application. Internet Monitor also sends health events to Amazon EventBridge so that you can set up notifications. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which AWS accounts can I connect to IAM Identity Center?", "output": "You can add any AWS account managed usingAWS Organizations (https://aws.amazon.com/organizations/)to IAM Identity Center. You need to enableall features (https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_org_support-all-features.html)in your organizations to manage your accounts single sign-on. [Source: https://aws.amazon.com/iam/identity-center/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Amazon SQS long polling?", "output": "Amazon SQS long polling is a way to retrieve messages from your Amazon SQS queues. While the regular short polling returns immediately, even if the message queue being polled is empty, long polling doesnt return a response until a message arrives in the message queue, or the long poll times out.Long polling makes it inexpensive to retrieve messages from your Amazon SQS queue as soon as the messages are available. Using long polling might reduce the cost of using SQS, because you can reduce the number of empty receives. For more information, seeAmazon SQS Long Polling (https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-long-polling.html)in the Amazon SQS Developer Guide. [Source: https://aws.amazon.com/sqs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What metadata is preserved when copying data between HDFS and Amazon EFS?", "output": "AWS DataSync copies file and folder timestamps and POSIX permissions and applies default values for user ID and group ID. You can learn more and see the complete list of copied metadata in ourdocumentation (https://docs.aws.amazon.com/datasync/latest/userguide/metadata-copied.html). [Source: https://aws.amazon.com/datasync/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How is AWS Amplify related to the AWS Mobile SDKs for iOS and Android?", "output": "Amplify iOS and Amplify Android are the recommended ways to build iOS and Android apps that leverage AWS services, whether or not you have configured them using the Amplify CLI. Get startedhere. If your app is already built using the previous AWS Mobile SDKs for iOS and Android, documentation is availablehere. [Source: https://aws.amazon.com/amplify/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can users verify that notification messages are sent from Amazon SNS?", "output": "To ensure the authenticity of the notifications, Amazon SNS will sign all notification deliveries using a cryptographically secure, asymmetric mechanism (private-public key pair based on certificates). Amazon SNS will publish its certificate to a well-known location (e.g.http://sns.us-east-1.amazonaws.com/SimpleNotificationService.pemfor the US East region) and sign messages with the private key of that certificate. Developers/applications can obtain the certificate and validate the signature in the notifications with the certificate\u2019s public key, to ensure that the notification was indeed sent out by Amazon SNS. For further details on certificate locations, please refer to the Amazon SNS details page. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If my account has the same agreement accepted in the Account agreements tab and the Organization agreements tab, which one applies?", "output": "The organization agreement will apply because according to its terms, it applies instead of the account agreement when both are active. If the organization agreement is terminated, and if you have an account agreement of the same type in place (under theAccount agreementstab), the account agreement will apply to that account.Note: Terminating the organization agreement does not terminate the account agreement. [Source: https://aws.amazon.com/artifact/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I tell that an instance is hibernated?", "output": "You can tell that an instance is hibernated by looking at the state reason. It should be \u2018Client.UserInitiatedHibernate\u2019. This is visible on the console under \u201cInstances - Details\u201d view or in the DescribeInstances API response as the \u201creason\u201d field. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I create IAM users?", "output": "You can use the IAM console, IAM command line interface (CLI), or IAM API to provision IAM users. By default, IAM users have no access to AWS services until permissions are granted. [Source: https://aws.amazon.com/elasticbeanstalk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What's the target use case?", "output": "Parallel Query is a good fit for analytical workloads requiring fresh data and good query performance, even on large tables. Workloads of this type are often operational in nature. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I activate gateways that are connected to AWS via AWS PrivateLink?", "output": "PrivateLink enabled gateways can be activated through the AWS Console if your web browser has access to both the internet and your private network, or via the CLI in the region that they are based. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What IP ranges would my end users need to allow list to access my SFTP servers endpoint type that is PUBLIC?", "output": "If you are using the PUBLIC endpoint type, your users will need to allow list the AWS IP address rangespublished here (https://ip-ranges.amazonaws.com/ip-ranges.json). Refer to the documentation for details on staying up to date withAWS IP Address Ranges (https://docs.aws.amazon.com/general/latest/gr/aws-ip-ranges.html). [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I configure Amazon Chime to use another identity provider (such as Microsoft Active Directory or Okta SSO)?", "output": "Steps to configure identity providers are laid out inConnect to Your Active DirectoryandConnect to OKTA SSO. [Source: https://aws.amazon.com/chime/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I access my Amazon EFS file system concurrently from my on-premises datacenter servers as well as EC2 instances?", "output": "Yes. You can access your Amazon EFS file system concurrently from servers in your on-premises datacenter as well as EC2 instances in your Amazon VPC. Amazon EFS provides the same file system access semantics, such as strong data consistency and file locking, across all EC2 instances and on-premises servers accessing a file system. [Source: https://aws.amazon.com/efs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the CloudTrail Processing Library?", "output": "The CloudTrail Processing Library is a Java library that makes it easier to build an application that reads and processes CloudTrail log files. You can download the CloudTrail Processing Library fromGitHub (https://github.com/aws/aws-cloudtrail-processing-library). [Source: https://aws.amazon.com/cloudtrail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I avoid using the public internet to replicate my data to AWS?", "output": "Yes, withAWS DRSyou can control the data replication path using private connectivity options such as a VPN, AWS Direct Connect, VPC peering, or another private connection. Learn more about using aprivate IP for data replication (https://docs.aws.amazon.com/drs/latest/userguide/data-routing.html#use-private-ip). [Source: https://aws.amazon.com/disaster-recovery/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started with S3 CloudWatch Metrics?", "output": "You can use the AWS Management Console to enable the generation of one-minute CloudWatch request metrics for your S3 bucket or configure filters for the metrics using a prefix or object tag, or access point. Alternatively, you can call the S3 PUT Bucket Metrics API to enable and configure publication of S3 storage metrics.\u00a0CloudWatch Request Metrics will be available in CloudWatch within 15 minutes after they are enabled. CloudWatch Storage Metrics are enabled by default for all buckets, and reported once per day. Learn more aboutCloudWatch metrics for Amazon S3. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens when I lock a file?", "output": "When you lock a file, nobody else can upload a new version of that file, until you unlock the file. If someone else needs access to the file, they can request that you unlock it, and you\u2019ll be notified of the request. If you are using Amazon WorkDocs Drive on your WorkSpace, changes made to your files will not be synced until the file is unlocked. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does AWS X-Ray log events to AWS CloudTrail?", "output": "Yes. X-Ray logs all API calls as management events. It also logs calls on traces as data events, including on PutTraceSegments and GetTimeSeriesServiceStatistics among other APIs. Data events are not logged by default. To log data events, you must configure your CloudTrail trail or event data store to collect them. [Source: https://aws.amazon.com/xray/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is AWS DataSync?", "output": "AWS DataSync is an online data movement and discovery service that simplifies and accelerates data migrations to AWS as well as moving data to and from on-premises storage, edge locations, other cloud providers, and AWS Storage services.AWS DataSync Discovery helps you simplify migration planning and accelerate your data migration to AWS by giving you visibility into your on-premises storage performance and utilization, and providing recommendations for migrating your data to AWS Storage services. DataSync Discovery enables you to better understand your on-premises storage performance and capacity usage through automated data collection and analysis, enabling you to quickly identify data to be migrated and use generated recommendations to select AWS Storage services that align to your performance and capacity needs.For online data transfers, AWS DataSync simplifies, automates, and accelerates copying large amounts of data to and from on-premises storage, edge locations, other cloud providers, and AWS Storage services. DataSync can copy data to and from Network File System (NFS) shares, Server Message Block (SMB) shares, Hadoop Distributed File Systems (HDFS), self-managed object storage, object storage in other clouds such as Google Cloud Storage and Wasabi Cloud Storage (see thefull list of support clouds (https://docs.aws.amazon.com/datasync/latest/userguide/transferring-other-cloud-storage.html)), Azure Files, Azure Blob Storage (including Azure Data Lake Storage Gen2),Amazon S3 compatible storage on Snow, Amazon Simple Storage Service (Amazon S3 (https://aws.amazon.com/s3/)), Amazon Elastic File System (Amazon EFS (https://aws.amazon.com/efs/)) file systems,Amazon FSx for Windows File Server (https://aws.amazon.com/fsx/windows/)file systems,Amazon FSx for Lustre (https://aws.amazon.com/fsx/lustre/)file systems,Amazon FSx for OpenZFS (https://aws.amazon.com/fsx/openzfs/)file systems, andAmazon FSx for NetApp ONTAP (https://aws.amazon.com/fsx/netapp-ontap/)file systems. [Source: https://aws.amazon.com/datasync/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use Amazon S3 to store application data, like images?", "output": "Yes. You can use Amazon S3 for application storage. The easiest way to do this is by including the AWS SDK as part of your application\u2019s deployable file. For example, you can include the AWS SDK for Java as part of your application's WAR file. [Source: https://aws.amazon.com/elasticbeanstalk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Are there limits to the number of templates or stacks?", "output": "For more information on the maximum number of AWS CloudFormation stacks that you can create, see Stacks inAWS CloudFormation quotas (https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cloudformation-limits.html?pg=fq&sec=lr). Complete our request for a higher limithere (https://aws.amazon.com/contact-us/cloudformation-request/), and we will respond to your request within two business days. [Source: https://aws.amazon.com/cloudformation/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I share input data in S3 between clusters?", "output": "Yes, you are able to read the same data in S3 from two concurrent clusters. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get charged if I change storage size or hardware bundle during a month?", "output": "For example, if you increase the volume on the 10th of a month on an AlwaysOn Power WorkSpace with 175 GB, and 100 GB for root and user volumes respectively, you are charged $78.00 for the Power WorkSpace and $11.60 for 20 days of additional 175 GB at $0.10/GB-month (in us-east-1). Similarly, switching a bundle\u2014for example, from Value to Standard\u2014on the 15th of a month results in 15 days of Value WorkSpaces charge ($12.50 in US-East-1) and 15 days of Standard WorkSpaces charge ($17.50 in US-East-1). [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Amazon EFS Backup work?", "output": "Amazon EFS is natively integrated with AWS Backup. You can use the EFS console, API, and AWS Command Line Interface (AWS CLI) to enable automatic backups, which uses a default backup plan with the AWS Backup recommended settings. During the initial backup, a copy of the entire file system is made in the backup vault. All subsequent backups of that file system are incremental in nature, i.e. only files and directories that have been changed, added, or removed are copied. With each incremental backup, AWS Backup retains the necessary reference data to allow a full restore. In the event of data loss, you can perform a full or partial restore of your file system using the AWS Backup console or the CLI.\u00a0 \u00a0 [Source: https://aws.amazon.com/efs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "I already use AWS Config rules for my resources post-provisioning. How do I run those same rules in proactive mode?", "output": "You can use the existing PutConfigRule API or the AWS Config console to enable proactive mode on an AWS Config rule in your account. [Source: https://aws.amazon.com/config/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Where do I get AWS IoT Device Tester for FreeRTOS?", "output": "You can get AWS IoT Device Tester for FreeRTOShere (https://aws.amazon.com/freertos/device-tester/). [Source: https://aws.amazon.com/freertos/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is the flexible execution class always available?", "output": "Yes. You can always choose the flexible execution class to run your AWS Glue jobs. However, the ability of AWS Glue to execute these jobs is based on the availability of non-dedicated AWS capacity and the number of workers selected for your job. It is possible that, during peak times, AWS Glue may not have adequate capacity for your job. In that case, your job will not start. You can specify a timeout value after which AWS Glue will cancel the job. The longer the timeout value, the greater the chance that your job will be executed. [Source: https://aws.amazon.com/glue/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Are there restrictions on the names of Amazon SQS message queues?", "output": "You can use alphanumeric characters, hyphens (-), and underscores (_). [Source: https://aws.amazon.com/sqs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does my application need to reside in the same VPC as the CloudHSM Cluster?", "output": "No, but the server or instance on which your application and the HSM client are running must have network (IP) reachability to all HSMs in the cluster. You can establish network connectivity from your application to the HSM in many ways, including operating your application in the same VPC, with VPC peering, with a VPN connection, or with Direct Connect. Please see theVPC Peering Guide (https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.html)andVPC User Guide (http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide)for more details. [Source: https://aws.amazon.com/cloudhsm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does the S3 Glacier Deep Archive storage class differ from the S3 Glacier Instant Retrieval, and S3 Glacier Flexible Retrieval storage classes?", "output": "S3 Glacier Deep Archive expands our data archiving offerings, enabling you to select the optimal storage class based on storage and retrieval costs, and retrieval times. Choose the S3 Glacier Instant Retrieval storage class when you need milliseconds access to low cost archive data. For archive data that does not require immediate access but needs the flexibility to retrieve large sets of data at no cost, such as backup or disaster recovery use cases, choose S3 Glacier Flexible Retrieval, with retrieval in minutes or free bulk retrievals in 5-12 hours. S3 Glacier Deep Archive, in contrast, is designed for colder data that is very unlikely to be accessed, but still requires long-term, durable storage. S3 Glacier Deep Archive is up to 75% less expensive than S3 Glacier Flexible Retrieval and provides retrieval within 12 hours using the Standard retrieval tier. Standard retrievals typically start within 9 hours when initiated using S3 Batch Operations. You may also reduce retrieval costs by selecting Bulk retrieval, which will return data within 48 hours. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When I use Kinesis Data Streams, how secure is my data?", "output": "Amazon Kinesis is secure by default. Only the account and data stream owners have access to the Kinesis resources they create. Kinesis supports user authentication to control access to data. You can use IAM policies to selectively grant permissions to users and groups of users. You can securely put and get your data from Kinesis through SSL endpoints using the HTTPS protocol. If you need extra security, you can use server-side encryption with AWS Key Management Service (AWS KMS) keys to encrypt data stored in your data stream. AWS KMS allows you to use AWS-generated KMS keys for encryption, or if you prefer, you can bring your own KMS key into AWS KMS. Lastly, you can use your own encryption libraries to encrypt data on the client side before putting the data into Kinesis. [Source: https://aws.amazon.com/kinesis/data-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When do I use AWS Security Hub and AWS Config conformance packs?", "output": "If a compliance standard, such as PCI DSS, is already present in Security Hub, then the fully managed Security Hub service is an easier way to operationalize it. You can investigate findings through Security Hubs integration with Amazon Detective, and you can build automated or semiautomated remediation actions using the Security Hub integration with Amazon EventBridge. However, if you want to assemble your own compliance or security standard, which can include security, operational, or cost optimization checks, AWS Config conformance packs are the way to go. AWS Config conformance packs simplify management of AWS Config rules by packaging a group of AWS Config rules and associated remediation actions into a single entity. This packaging simplifies deployment of rules and remediation actions across an organization. It also enables aggregated reporting, as compliance summaries can be reported at the pack level. You can start with the AWS Config conformance pack samples we provide and customize as you see fit. [Source: https://aws.amazon.com/config/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is there a time limit for how long my code initialization can run with Lambda SnapStart?", "output": "The maximum allowed initialization duration for Lambda SnapStart will match the execution timeout duration you have configured for your function. The maximum configurable execution timeout limit for a function is 15 minutes. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I enable slow logs on Amazon OpenSearch Service?", "output": "Slows logs can be enabled via the click of a button from the Console or via our CLI and APIs. For more details please refer to ourdocumentation (https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-createupdatedomains.html). [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How is album art supported for audio files?", "output": "Album art is supported in MP4 files containing AAC audio, in MP3 files, and in FLAC files. Album art is not supported for OGA, OGG, WAV, WebM or MPEG-2 TS outputs. You can specify whether album art from the source file is passed through to the output, removed, or whether new album art should replace it or be appended to it. [Source: https://aws.amazon.com/elastictranscoder/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is AWS Outposts rack GxP Compatible?", "output": "Yes, AWS Outposts rack is GxP compatible. AWS Outposts rack extends AWS services to AWS-managed infrastructure that is physically located at a customer site. Outposts rack capacity can be accessed locally over a local gateway that is mapped to the customers local network, in addition to having a connection path back to the AWS Region. You can learn more about using the AWS Cloud, including Outposts rack, for GxP systemshere (https://aws.amazon.com/compliance/gxp-part-11-annex-11/). GxP-regulated life sciences organizations using AWS services are responsible for designing and verifying their GxP compliance. [Source: https://aws.amazon.com/outposts/rack/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What if I already have a custom pricing agreement for CloudFront, can I subscribe to the CloudFront Security Savings Bundle too?", "output": "You may only be subscribed to one or the other. Please contact your AWS Account Manager if you have questions about your custom pricing agreement. [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use RDS Extended Support with any minor version?", "output": "No,Amazon RDS Extended Support (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/extended-support.html)is only available on certain minor versions. SeeAurora User Guide (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.VersionPolicy.html#Aurora.VersionPolicy.MinorVersions)for details. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does metric storage retention work for Prometheus metrics?", "output": "Prometheus metrics are automatically ingested as CloudWatch custom metrics. The retention period is 15 months per metric data point with automatic roll up (<60secs available for 3 hours, one min available for 15 days, 5 min available for 63 days, one hour available for 15 months). To learn more, see thedocumentation on CloudWatch metrics retention (https://aws.amazon.com/about-aws/whats-new/2016/11/cloudwatch-extends-metrics-retention-and-new-user-interface/). [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I run my existing ETL jobs with AWS Glue?", "output": "Yes. You can run your existing Scala or Python code on AWS Glue. Simply upload the code toAmazon S3and create one or more jobs that use that code. You can reuse the same code across multiple jobs by pointing them to the same code location on Amazon S3. [Source: https://aws.amazon.com/glue/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I choose to only protect some of my resources with AWS Shield Advanced?", "output": "Yes, AWS Shield Advanced allows you the flexibility to choose the resources that you'd like to protect. You will only be charged for AWS Shield Advanced Data Transfer on these protected resources. [Source: https://aws.amazon.com/shield/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Neptune Database improve my databases fault tolerance to disk failures?", "output": "A Neptune Database cluster can only be created in an Amazon VPC that has at least two subnets in at least two Availability Zones. By distributing your cluster instances across at least two Availability Zones, Neptune helps ensure that there are instances available in your database cluster in the unlikely event of an Availability Zone failure. The cluster volume for your Neptune Database cluster always spans three Availability Zones to provide durable storage with less possibility of data loss. Neptune is designed to transparently handle the loss of up to two copies of data without affecting database write availability and up to three copies without affecting read availability. Neptune storage is also self-healing. Data blocks and disks are continuously scanned for errors and repaired automatically. [Source: https://aws.amazon.com/neptune/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What use cases are best suited to run on S3 on Outposts?", "output": "S3 on Outposts\u00a0is ideal for customers with data residency requirements or those in regulated industries that need to securely store and process customer data that needs to remain on premises or in locations where there is no AWS region. Additionally, customers can use S3 on Outposts to run data intensive workloads to process data locally and store on-premises. S3 on Outposts will also help if you have applications that need to communicate with other on-premises systems or control on-site equipment, such as within a factory, hospital, or research facility. [Source: https://aws.amazon.com/outposts/rack/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I develop and add my own resource or module to the AWS CloudFormation Registry?", "output": "You can refer to thislink (https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/resource-types.html)to develop and add your own resource or module to the AWS CloudFormation Registry. You can choose to publish it privately or to the Public Registry. [Source: https://aws.amazon.com/cloudformation/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I set up continuous deployment on CloudFront?", "output": "You can set up continuous deployment by associating a staging distribution to a primary distribution through CloudFront console, SDK, Command Line Interface (CLI), or CloudFormation template. You can then define rules to split traffic by configuring the client header or dialing up a percentage of traffic to test with the staging distribution. Once set up, you can update the staging configuration with desired changes. CloudFront will manage the split of traffic to users and provide associated analytics to help you decide whether to continue deployment or rollback. Once testing with staging distributions is validated, you can merge changes to the main distribution.Please visit thedocumentation (https://docs.aws.amazon.com/cloudfront/latest/DeveloperGuide/test-configuration-changes.html)to learn more about the feature. [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon allow its trademarks or logo to be used as a certificate badge, site seal, or trust logo?", "output": "No. Seals and badges of this type can be copied to sites that do not use the ACM service, and used inappropriately to establish trust under false pretenses. To protect our customers and the reputation of Amazon, we do not allow our logo to be used in this manner. [Source: https://aws.amazon.com/certificate-manager/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Are there limits on the number of organizations and users I can create when using Amazon WorkMail?", "output": "No, there are no limits on the number of organizations and users you can create. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does the new version of Amazon CloudSearch use Apache Solr?", "output": "Yes. The latest version of Amazon CloudSearch has been modified to use Apache Solr as the underlying text search engine. Amazon CloudSearch now provides several popular search engine features available with Apache Solr in addition to the managed search service experience that makes it easy to set up, operate, and scale a search domain. [Source: https://aws.amazon.com/cloudsearch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do my end users FTPS clients verify the identity of my FTPS server?", "output": "When you enable FTPS access, you will need to supply a certificate from Amazon Certificate Manager (ACM). This certificate is used by your end user clients to verify the identity of your FTPS server. Refer to the ACM documentation onrequesting new certificates (https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-request-public.html)orimporting existing certificates into ACM (https://docs.aws.amazon.com/acm/latest/userguide/import-certificate.html). [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I provide my end users access to more than one Amazon S3 bucket?", "output": "Yes. The bucket(s) your user can access is determined by the AWS IAM Role, and the optional scope-down policy you assign for that user. You can only use a single bucket as the home directory for the user. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I connect to my read replicas?", "output": "You can connect to a read replica just as you would connect to a primary cache node. If you have multiple read replicas, it is up to your application to determine how read traffic will be distributed amongst them. Here are more details:Redis (cluster mode disabled) OSS clusters, use the individual node endpoints for read operations. (In the API/CLI these are referred to as read endpoints.)RedisOSS (cluster mode enabled) clusters, use the cluster's configuration endpoint for all operations. You can still read from individual node endpoints. (In the API and CLI these are referred to as read endpoints.) [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does the Schema Registry maintain high availability for my applications?", "output": "The Schema Registry storage and control plane is designed for high availability and is backed by theAWS Glue Service Level Agreement. The serializers and deserializers use best-practice caching techniques to maximize schema availability within clients. [Source: https://aws.amazon.com/glue/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I run queries from Redshift for the data stored in the AWS Data Lake?", "output": "<p>Amazon Redshift Spectrum is a feature of Amazon Redshift that lets you run queries against your data lake in Amazon S3, with no data loading or ETL required. When you issue an SQL query, it goes to the Amazon Redshift endpoint, which generates and optimizes a query plan. Amazon Redshift determines what data is local and what is in Amazon S3, generates a plan to minimize the amount of S3 data that must be read, and requests Amazon Redshift Spectrum workers out of a shared resource pool to read and process data from Amazon S3.</p> [Source: https://aws.amazon.com/redshift/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the key benefits of GuardDuty?", "output": "GuardDuty makes it easier to continuously monitor your AWS accounts, workloads, and runtime activity. GuardDuty is designed to operate completely independently from your resources and have no performance or availability impact to your workloads. The service is fully managed with integrated threat intelligence, machine learning (ML) anomaly detection, and malware scanning. GuardDuty delivers detailed and actionable alerts that are designed to be integrated with existing event management and workflow systems. There are no upfront costs and you pay only for the events analyzed, with no additional software to deploy or threat intelligence feed subscriptions required. [Source: https://aws.amazon.com/guardduty/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can ACM simplify DNS validation for Amazon Route 53 DNS customers?", "output": "Yes. For customers who are using Amazon Route 53 DNS to manage DNS records, theACM console (https://console.aws.amazon.com/acm/home)can add records to your DNS configuration for you when you request a certificate. Your Route 53 DNS hosted zone for your domain must be configured in the same AWS account as the one you are making the request from, and you must have sufficient permissions to make a change to your Amazon Route 53 configuration. For further instructions, refer to theACM User Guide (https://docs.aws.amazon.com/acm/latest/userguide/acm-overview.html). [Source: https://aws.amazon.com/certificate-manager/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which engine versions support data tiering?", "output": "ElastiCache supports data tiering for ElastiCache for Redis OSS versions 6.2 and above. [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why should I use S3 Multi-Region Access Points?", "output": "S3 Multi-Region Access Points accelerate and simplify storage for your multi-region applications. By dynamically routing S3 requests made to a replicated data set, S3 Multi-Region Access Points reduce request latency, so that applications run up to 60% faster. S3 Multi-Region Access Points can also help you build resilient, multi-region and multi-account applications that are more protected against accidental or unauthorized data deletion. With S3 Multi-Region Access Points, you are able to take advantage of the global infrastructure of AWS while maintaining a simple region-agnostic architecture for your applications. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is an S3 table bucket?", "output": "A table bucket is purpose-built for storing tables using the Apache Iceberg format. UseAmazon S3 Tablesto create table buckets and set up table-level permissions in just a few steps. S3 table buckets are specifically optimized for analytics and machine learning workloads. With built-in support for Apache Iceberg, you can query tabular data in S3 with popular query engines including Amazon Athena, Amazon Redshift, and Apache Spark. Use S3 table buckets to store tabular data such as daily purchase transactions, streaming sensor data, or ad impressions as an Iceberg table in Amazon S3, and then interact with that data using analytics capabilities. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do I have to enable GuardDutyEKS Protection in each AWS Region individually?", "output": "Yes, GuardDuty is a regional service, and thus GuardDutyEKS Protection must be enabled in each AWS Region separately. [Source: https://aws.amazon.com/guardduty/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are Office 365 Licensing requirements?", "output": "Users will need a Microsoft Office 365 \u2018Work\u2019 or \u2018School\u2019 account with license for Office Online. Please refer to this link for further details on Licenses. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I control access to my data when using Mountpoint for Amazon S3?", "output": "When using Mountpoint for Amazon S3, you can control access to your data using Amazon S3\u2019s existing access control mechanisms, including bucket policies and AWS Identity and Access Management (IAM) policies. Mountpoint for Amazon S3 translates file system operations like read and write into object API requests made to your S3 bucket. Afterwards, Amazon S3 evaluates all the relevant policies, such as those on the user and bucket, to decide whether to authorize the request. Mountpoint for Amazon S3 does not introduce new access control mechanisms. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I terminate an NZNDB Addendum using AWS Artifact Agreements?", "output": "You can use AWS Artifact Agreements to terminate an NZNDB Addendum at any time.To terminate an account NZNDB Addendum, you can use the Account agreements tab in AWS Artifact and click on the Terminate the AWS New Zealand Notifiable Data Breach Addendum for this Account button.To terminate an organizations NZNDB Addendum, you can use the Organization agreements tab in AWS Artifact and click on the Terminate AWS New Zealand Notifiable Data Breach Addendum for this Organization button. [Source: https://aws.amazon.com/artifact/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why can you only choose a sampling percentage for successful delivery attempts and not sample failed delivery attempts?", "output": "Based on feedback we received from customers, we found that most developers are interested in knowing all the delivery attempt failures for their applications \u2013 and prefer to only store sample successful deliveries rather than logging all of them. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are AWS IoT Greengrass components?", "output": "AWS IoT Greengrass components are building blocks that enable easy creation of complex workflows such as machine learning inference, local processing, messaging, and data management. AWS IoT Greengrass also offers prebuilt components such as Stream Manager that supports data export to local and cloud targets. These components help accelerate application development so you don't have to worry about understanding device protocols, managing credentials, or interacting with external APIs, and you can interact with AWS services and third-party applications without writing code. In addition, you can also build your own components on top of AWS IoT Greengrass. All components are designed to enable ease of use, as they can configured and managed through the AWS Greengrass console. These components enable you to reuse common business logic from one AWS IoT Greengrass device to another, as you can easily discover, import, configure, and deploy components at the edge. [Source: https://aws.amazon.com/greengrass/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I back up my attached disk?", "output": "You can back up your disk by taking a disk snapshot. You can also backup your entire instance and any attached disks by taking an instance snapshot. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What client operating systems and browsers are supported?", "output": "Amazon AppStream 2.0 can stream your applications to HTML5-compatible browsers, including the latest versions of Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Microsoft Edge, on desktop devices, including Windows, Mac, Chromebooks, and Linux PCs. The AppStream 2.0 client for Windows and macOS let your users use 4 monitors, 4K monitors with your applications on AppStream 2.0. Windows client also supports USB peripherals such as 3D mouse. [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use stop or Hibernation interruption behaviors with Spot Fleet?", "output": "Yes, stop-start and hibernate-resume are supported with Spot Fleet with \u201cmaintain\u201d fleet option enabled. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What specific queries improve under Parallel Query?", "output": "Most queries over large data sets that are not already in the buffer pool can expect to benefit. The initial version of Parallel Query can push down and scale out of the processing of more than 200 SQL functions, equijoins, and projections. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the difference between CloudShell and the AWS Cloud9 terminal?", "output": "AWS Cloud9 is an integrated development environment (IDE) that gives users access to a terminal when using a Cloud9 environment that requires an EC2 instance in your account. CloudShell is a standalone, general purpose tool that you can use to run commands on AWS. When using Cloud9, you are billed for the EC2 instance that runs your Cloud9 environment. CloudShell can be used at no additional cost; you pay only for the AWS resources needed to run scripts and commands. In both cases you are billed for data transfer at standarddata transfer rates (https://aws.amazon.com/ec2/pricing/on-demand/#Data_Transfer). [Source: https://aws.amazon.com/cloudshell/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I prevent specific users from accessing my search domain?", "output": "Amazon CloudSearch supports IAM integration for the configuration service and all search domain services. You can grant users full access to Amazon CloudSearch, restrict their access to specific domains, and allow or deny access to specific actions. [Source: https://aws.amazon.com/cloudsearch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I stop an in-flight deployment?", "output": "Yes. When you stop an in-flight deployment, the AWS CodeDeploy service will instruct the agent on each instance to stop executing additional scripts. To get your application back to a consistent state, you can either redeploy the revision, or deploy another revision. [Source: https://aws.amazon.com/codedeploy/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do Amplify features work with AWS cloud services?", "output": "Amplify features are organized based on the use cases you need to integrate with your app, such as offline data, multi factor authentication, analytics, and others. When you configure these features using the Amplify CLI or the Amplify Studio, the necessary AWS cloud services are provisioned for you. The configuration is persisted in CloudFormation templates that can be checked into source control and shared with other developers. When you add these features to your app via the Amplify libraries, the library makes the necessary calls to AWS services. For example, 'amplify add analytics' will configure Amazon Pinpoint. Then, when you use the Analytics APIs from the Amplify library in your app, the necessary calls will be made to Pinpoint. [Source: https://aws.amazon.com/amplify/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are Throughput Optimized HDD (st1) and Cold HDD (sc1) volume types?", "output": "ST1 volumes are backed by hard disk drives (HDDs) and are ideal for frequently accessed, throughput intensive workloads with large datasets and large I/O sizes, such as MapReduce, Kafka, log processing, data warehouse, and ETL workloads. These volumes deliver performance in terms of throughput, measured in MB/s, and include the ability to burst up to 250 MB/s per TB, with a baseline throughput of 40 MB/s per TB and a maximum throughput of 500 MB/s per volume. ST1 is designed to deliver the expected throughput performance 99% of the time and has enough I/O credits to support a full-volume scan at the burst rate. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does AWS use my Amazon WorkMail email content?", "output": "You own your content in Amazon WorkMail, and you retain full ownership and control of your Amazon WorkMail email. We will not view, use, or move the contents of your Amazon WorkMail account unless authorized by you. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I schedule time on an antenna in one location (e.g. Oregon) while I am working from another location (e.g. Dubbo)?", "output": "Yes, AWS Ground Station is a global network of antenna systems that are available to users around the world. In fact, it will be common for many users to schedule time on antennas at every location in the global network. [Source: https://aws.amazon.com/ground-station/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does enabling S3 Object Lock on existing buckets impact new objects uploaded to the buckets?", "output": "After enabling S3 Object Lock on existing buckets, you have the option to set a default S3 Object Lock retention mode and period for all new objects uploaded to the bucket. On the S3 console, you can do this by using thePropertiestab for a selected bucket and enabling default retention mode and retention period for all new objects uploaded to the bucket. Alternatively, you can choose to not configure any bucket-level Object Lock settings, which will keep the new objects in the buckets unlocked. You can then lock individual objects by editing your S3 Object Lock settings in theObject Propertiestab or use S3 Batch Operations to lock objects in bulk. For more information see the documentation ondefault retention settings. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does ACM copy certificates across AWS Regions?", "output": "No. The private key of each ACM certificate is stored in the Region in which you request the certificate. For example, when you obtain a new certificate in the US East (N. Virginia) Region, ACM stores the private key in the N. Virginia Region. ACM certificates are only copied across Regions if the certificate is associated with a CloudFront distribution. In that case, CloudFront distributes the ACM certificate to the geographic locations configured for your distribution. [Source: https://aws.amazon.com/certificate-manager/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What if my data doesnt contain the precise answer Amazon Kendra is looking for?", "output": "When your data doesnt contain a precise answer to a question, Amazon Kendra returns a list of the most-relevant documents ranked by its deep learning models. [Source: https://aws.amazon.com/kendra/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I run localization tests? How do I change the language of the device?", "output": "Yes, you can provide a locale (for example, en_US) to override the default locale setting on a device. [Source: https://aws.amazon.com/device-farm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the benefits of running a managed search service like Amazon CloudSearch over running my own search service on EC2?", "output": "Amazon CloudSearch provides several benefits over running your own self-managed search service including easy configuration, auto scaling for data and traffic, self-healing clusters, and high availability with Multi-AZ. With a few clicks in the AWS Management Console, you can create a search domain and upload the data you want to make searchable, and Amazon CloudSearch automatically provisions the required resources and deploys a highly tuned search index. [Source: https://aws.amazon.com/cloudsearch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon EMR support third-party software packages?", "output": "Yes.\u00a0You can use Bootstrap Actions to install third-party software packages on your cluster. You can also upload statically compiled executables using the Hadoop distributed cache mechanism. EMR 6.x supports Hadoop 3, which allows the YARN NodeManager to launch containers either directly on the EMR cluster host or inside a Docker container. Please see ourdocumentationto learn more. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I join existing EC2 for Windows Server instances seamlessly to a domain?", "output": "You cannot use the seamless domain join feature from the AWS Management Console for existing EC2 for Windows Server and EC2 for Linux instances, but you can join existing instances to a domain using the EC2 API or by using PowerShell on the instance. To learn more, see thedocumentation (https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-join-aws-domain.html). [Source: https://aws.amazon.com/directoryservice/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are my options to encrypt data at rest?", "output": "You can choose to encrypt files stored your bucket using Amazon S3 Server-Side Encryption (SSE-S3) or Amazon KMS (SSE-KMS).For files stored in EFS, you can choose AWS or customer managed CMK for encryption of files at rest. Refer to the documentation for moredetails on options for at rest encryption of file data and metadata using Amazon EFS (https://docs.aws.amazon.com/efs/latest/ug/encryption-at-rest.html). [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is Amazon Rekognition a HIPAA Eligible Service?", "output": "Amazon Rekognition is a HIPAA Eligible Service covered under the AWS Business Associate Addendum (AWS BAA). If you have an AWS BAA in place, Amazon Rekognition will use, disclose, and maintain your Protected Health Information (PHI) only as permitted by the terms of your AWS BAA. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What file operations will I see in File Gateway audit logs?", "output": "You will see details about the following operations logged for files and directories: open, delete, read, write, rename, change of permissions, and file operation success. User information for each operation, including timestamp, Active Directory domain, user name, and client IP address, is also logged. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is AWS DataSync PCI compliant?", "output": "Yes. AWS DataSync isPCI-DSS (https://aws.amazon.com/compliance/pci-dss-level-1-faqs/)compliant, which means you can use it to transfer payment information. You can download the PCI Compliance Package inAWS Artifact (https://aws.amazon.com/artifact/)to learn more about how to achieve PCI Compliance on AWS. [Source: https://aws.amazon.com/datasync/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What use cases do CloudTrail Lake pre-curated dashboards support?", "output": "CloudTrail Lake offers a suite of pre-curated dashboards that cater to diverse use cases spanning security, compliance, operations, and resource management. These ready-to-use dashboards are tailored for specific scenarios, providing immediate value across various aspects of cloud governance:For security monitoring, dashboards like the \"Security Monitoring Dashboard\" help track critical security events, including access denied events, failed login attempts, and destructive actions.To support compliance efforts, the \"IAM Activity Dashboard\" provides visibility into changes to IAM entities, helping identify unintended IAM actions and potential compliance issues.Cloud operations teams can utilize the \"Error Analysis Dashboard\" to identify and troubleshoot service throttling errors and other operational issues across services.For resource management, the \"Resource Changes Dashboard\" provides visibility into trends in provisioning, deletion, and modifications across AWS resources, including changes made through CloudFormation and manually.Organizations can benefit from the \"Organizations Activity Dashboard\",which provides insights into account management, access patterns, and policy changes.Service-specific dashboards for EC2, Lambda, DynamoDB, and S3 offer detailed visibility into both management and data plane activities for these services. [Source: https://aws.amazon.com/cloudtrail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I copy object data to and from Amazon S3 buckets on AWS Outposts?", "output": "Yes. You can copy objects between Amazon S3 on AWS Outposts and Amazon S3 buckets in AWS Regions. AWS DataSync copies objects together with object metadata and object tags. For DataSync to access your Amazon S3 on Outposts buckets,deploy a DataSync EC2 agent on your Outpost (https://docs.aws.amazon.com/datasync/latest/userguide/deploy-agents.html#outposts-agent).When using DataSync with Amazon S3 on Outposts, you can only transfer data to and from Amazon S3 buckets in AWS Regions. You can learn more about supported sources and destinations for DataSync tasks in ourdocumentation (https://docs.aws.amazon.com/datasync/latest/userguide/working-with-locations.html). [Source: https://aws.amazon.com/datasync/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Neptune Analytics support high availability?", "output": "Yes, Neptune Analytics offers Multi-AZ deployments with enhanced availability and durability. By default, it provisions a hot standby in a separate Availability Zone. With a hot standby, the failover time is in seconds. Without a standby, the service provisions new underlying compute capacity within minutes. [Source: https://aws.amazon.com/neptune/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do you authenticate to Amazon WorkDocs Drive on your PC?", "output": "You need to be Amazon WorkDocs Drive user (trial, paid, or bundled) to be able to use Amazon WorkDocs Drive. For domain-joined PC, your directory credentials (Simple Active Directory, Connected Active Directory, or Managed Active Directory) will authenticate you with Amazon WorkDocs Drive. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How long does it take before my test starts?", "output": "Tests are immediately queued for execution and usually start within minutes. If one or more devices are not available, test execution for those devices will remain queued until they become available. Testing on the other devices in your test run will continue. [Source: https://aws.amazon.com/device-farm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do Lightsail instances perform?", "output": "Lightsail instances are specifically engineered by AWS for web servers, developer environments, and small database use cases. Such workloads don't use the full CPU often or consistently, but occasionally need a performance burst. Lightsail uses burstable performance instances that provide a baseline level of CPU performance with the additional ability to burst above the baseline. This design enables you to get the performance you need, when you need it, while protecting you from the variable performance or other common side effects that you might typically experience from over-subscription in other environments. For more information on burstable performance, go here.\nIf you need highly configurable environments and instances with consistently high CPU performance for applications such as video encoding or HPC applications, we recommend you use Amazon EC2. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Who should use AWS Elastic Beanstalk?", "output": "Those who want to deploy and manage their applications within minutes in the AWS Cloud. You don\u2019t need experience with\u00a0cloud computing\u00a0to get started. AWS Elastic Beanstalk supports Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker web applications. [Source: https://aws.amazon.com/elasticbeanstalk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "I am an ISP, how do I manage embedded POPs in my network?", "output": "You can use the embedded POP portal to manage embedded POPs deployed within your network. The embedded POP portal is integrated with the AWS Interconnect Portal and provides a unified interface to easily self-service a variety of tasks associated with the entire lifecycle of these POPs. This includes requesting new appliances, tracking request progress, monitoring performance statistics, and requesting support. You canaccess the portal (https://console.interconnect.amazon/epop/home)by authenticating with single sign on (SSO) using your PeeringDB account. [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I add WorkDocs comments when editing office files?", "output": "You cannot add WorkDocs comments when editing Office files using collaborative editing at this point in time. Once you exit the editing session you can view the document in preview mode and add or reply to comments. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a backup plan?", "output": "A backup plan is a policy expression that defines when and how you want to back up your AWS resources, such as DynamoDB tables or EFS file systems. You assign resources to backup plans and AWS Backup will then automatically make and retain backups for those resources according to the backup plan. Backup plans are composed of one or more backup rules. Each backup rule is composed of 1) a backup schedule, which includes the backup frequency (Recovery Point Objective [RPO]) and backup window; 2) a lifecycle rule that specifies when to transition a backup from one storage tier to another and when to expire the recovery point; 3) the backup vault in which to place the created recovery points; and 4) the tags to be added to backups upon creation. For example, a backup plan might have a daily backup rule and a monthly backup rule. The daily rule backs up resources every day at midnight and retains the backups for one month. The monthly rule takes a backup once a month on the beginning of every month and retains the backups for one year. [Source: https://aws.amazon.com/backup/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use AWS WAF to protect web sites not hosted in AWS?", "output": "Yes, AWS WAF is integrated with Amazon CloudFront, which supports custom origins outside of AWS. [Source: https://aws.amazon.com/waf/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I onboard an integration to CloudTrail Lake as an available source?", "output": "To get started with your integration you can review thePartner Onboarding Guide (https://docs.aws.amazon.com/awscloudtrail/latest/partner-onboarding/cloudtrail-lake-partner-onboarding.html). Engage with your partner development team or partner solutions architect to connect you with the CloudTrail Lake team for a deeper dive or further questions. [Source: https://aws.amazon.com/cloudtrail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I enable encryption for my Amazon EFS file system?", "output": "You can enable encryption at rest in the EFS console by using the CLI or SDKs. When creaking a new file system in the EFS console, select \u201cCreate File System\u201d and then select the checkbox to enable encryption.\nData can be encrypted in transit between your Amazon EFS file system and its clients by using the Amazon EFS mount helper.\nEncryption of data at rest and data in transit can be configured together or separately to help meet your unique security requirements.\nFor more details, see the user documentation on Encryption. [Source: https://aws.amazon.com/efs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If I am a new user to GuardDuty, is GuardDuty Lambda Protection enabled by default for my accounts?", "output": "Yes. Any new accounts that activate GuardDuty through the console or API will also have Lambda Protection turned on by default. New GuardDuty accounts created using the AWS Organizations auto-enable feature will not have Lambda Protection turned on unless the auto-enable for Lambda option is turned on. [Source: https://aws.amazon.com/guardduty/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the Migration Hub home Region?", "output": "Before using most features in Migration Hub (except Refactor Spaces), you need to select a Migration Hub home Region from theMigration Hub Settings (https://console.aws.amazon.com/migrationhub/settings)page or by using theMigration Hub Config API (https://docs.aws.amazon.com/migrationhub-home-region/latest/APIReference/Welcome.html).The data stored in the Migration Hub home Region provides a single repository of discovery and migration planning information for your entire portfolio and a single view of migrations into multiple AWS Regions. You can migrate into any Region supported by your migration tools and the migration status will appear in your selected Migration Hub home Region. Seethe documentation (https://docs.aws.amazon.com/migrationhub/latest/ug/home-region.html)to learn more about the Migration Hub home region.Once set, the Migration Hub home Region cannot be changed. [Source: https://aws.amazon.com/migration-hub/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I copy and paste between my Amazon WorkSpaces and my client computer?", "output": "You can copy and paste text, but not files, between Amazon WorkSpaces and your client computer. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the benefits of using AWS Certificate Manager (ACM)?", "output": "ACM makes it easier to enable SSL/TLS for a website or application on the AWS platform. ACM eliminates many of the manual processes previously associated with using and managing SSL/TLS certificates. ACM can also help you avoid downtime due to misconfigured, revoked, or expired certificates by managing renewals. You get SSL/TLS protection and easy certificate management. Enabling SSL/TLS for Internet-facing sites can help improve the search rankings for your site and help you meet regulatory compliance requirements for encrypting data in transit.When you use ACM to manage certificates, certificate private keys are securely protected and stored using strong encryption and key management best practices. ACM lets you use the AWS Management Console, AWS CLI, or ACM APIs to centrally manage all of the SSL/TLS ACM certificates in an AWS Region. ACM is integrated with other AWS services, so you can request an SSL/TLS certificate and provision it with your Elastic Load Balancing load balancer or Amazon CloudFront distribution from the AWS Management Console, through AWS CLI commands, or with API calls. [Source: https://aws.amazon.com/certificate-manager/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Volume Gateway?", "output": "Volume Gateway provides an iSCSI target, which enables you to create block storage volumes and mount them as iSCSI devices from your on-premises or EC2 application servers. The Volume Gateway runs in either a cached or stored mode.In the cached mode, your primary data is written to S3, while retaining your frequently accessed data locally in a cache for low-latency access.In the stored mode, your primary data is stored locally and your entire dataset is available for low-latency access while asynchronously backed up to AWS.In either mode, you can take point-in-time snapshots of your volumes, which are stored as Amazon EBS Snapshots in AWS, enabling you to make space-efficient versioned copies of your volumes for data protection, recovery, migration and various other copy data needs. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the FIPS endpoints for AWS Storage Gateway?", "output": "For a list of the FIPS endpoints available for AWS Storage Gateway, refer to theAWS Storage Gateway endpoints reference guide (https://docs.aws.amazon.com/general/latest/gr/sg.html)or theAWS GovCloud (US) user guide (https://docs.aws.amazon.com/govcloud-us/latest/UserGuide/using-govcloud-endpoints.html). [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Android: Is there a default Google account on the devices?", "output": "No, devices do not have an active Google account. [Source: https://aws.amazon.com/device-farm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I access compliance and security reports?", "output": "To access a comprehensive list of documents relevant to compliance and security in the AWS Cloud, seeAWS Artifact (https://aws.amazon.com/artifact/). [Source: https://aws.amazon.com/directoryservice/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why should I use server-side encryption instead of client-side encryption?", "output": "You might choose server-side encryption over client-side encryption for any of the following reason:It is hard to enforce client-side encryption.They want a second layer of security on top of client-side encryption.It is hard to implement client-side key management schemes. [Source: https://aws.amazon.com/kinesis/data-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I use PrivateLink with File Gateway?", "output": "To use File Gateway on-premises with PrivateLink and private virtual interfaces (VIFs) to access your Amazon S3 buckets, you will need to set up an Amazon EC2 based proxy server. In order to access Amazon S3 over a private network, you need to use S3's gateway endpoints, and these endpoints are not directly accessible from on-premises environments. The proxy server will provide access through the VPC endpoint for S3, making it accessible to an on-premises File Gateway. We recommend using an EC2 instance family that is optimized for network bandwidth. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I launch C4 instances as Amazon EBS-optimized instances?", "output": "Each C4 instance type is EBS-optimized by default. C4 instances 500 Mbps to 4,000 Mbps to EBS above and beyond the general-purpose network throughput provided to the instance. Since this feature is always enabled on C4 instances, launching a C4 instance explicitly as EBS-optimized will not affect the instance's behavior. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When should I use Step Functions vs. Amazon Simple Workflow Service (SWF)?", "output": "You should consider using Step Functions for all your new applications, since it provides a more productive and agile approach to coordinating application components using visual workflows. If you require external signals to intervene in your processes or you would like to launch child processes that return a result to a parent, then you should considerAmazon Simple Workflow Service (Amazon SWF). (https://aws.amazon.com/swf/)With SWF, instead of writing state machines in declarative JSON, you can write a decider program to separate activity steps from decision steps. This provides you complete control over your orchestration logic, but increases the complexity of developing applications. You may write decider programs in the programming language of your choice, or you may use the Flow framework to use programming constructs that structure asynchronous interactions for you. [Source: https://aws.amazon.com/step-functions/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens during failover and how long does it take?", "output": "Failover is handled automatically by Amazon Aurora so your applications can resume database operations as quickly as possible without manual administrative intervention.If you have an Aurora Replica in the same or a different AZ when failing over, Aurora flips the canonical name record (CNAME) for your DB Instance to point at the healthy replica, which is promoted to become the new primary. Start-to-finish, failover typically completes within 30 seconds. For improved resiliency and faster failovers, consider usingAmazon RDS Proxy (https://aws.amazon.com/rds/proxy/)which automatically connects to the failover DB instance while preserving application connections. Proxy makes failovers transparent to your applications and reduces failover times by up to 66%.If you are running Aurora Serverless v1 and the DB instance or AZ become unavailable, Aurora will automatically recreate the DB instance in a different AZ. Aurora Serverless v2 works like provisioned for failover and other high availability features. For more information, seeAurora Serverless v2 and high availability. (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.how-it-works.html#aurora-serverless.ha).If you do not have an Aurora Replica (i.e., single instance) and are not running Aurora Serverless, Aurora will attempt to create a new DB Instance in the same Availability Zone as the original instance. This replacement of the original instance is done on a best-effort basis and may not succeed, for example, if there is an issue that is broadly affecting the Availability Zone.Your application should retry database connections in the event of connection loss. Disaster recovery across regions is a manual process, where you promote a secondary region to take read/write workloads. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Who can access the management console for my Amazon AppStream 2.0 application?", "output": "You can use AWS Identity and Access Management (IAM) to add users to your AWS account and grant them access to view and manage your Amazon AppStream 2.0 application. For more information, see What is IAM? in theIAM User Guide (https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html). [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which regions does CodeBuild support?", "output": "SeeRegional Products and Services (https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)for details. [Source: https://aws.amazon.com/codebuild/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon AppStream 2.0 offer persistent storage so that I can save and access files between sessions?", "output": "Yes. Amazon AppStream 2.0 offers multiple options for persistent file storage to allow users to store and retrieve files between their application streaming sessions. You can use a home folder backed by Amazon S3, Google Drive for G Suite, or Microsoft OneDrive for Business. Each of these are accessed from the my files tab within an active AppStream 2.0 streaming session, and content can be saved or opened directly from the File menu in most apps.Home foldersare AppStream 2.0's native persistent storage option. Users can access a home folder on their streaming instance and save content in their folder. Files are stored in an S3 bucket which is automatically created in your AWS account. To learn more, visitEnable and Administer Home Folders for Your AppStream 2.0 Users (https://docs.aws.amazon.com/appstream2/latest/developerguide/home-folders.html).For Windows OS based AppStream 2.0 stacks, you can enableGoogle Drive for G Suite, and users can link their G Suite account to access files on Google Drive. Changes are automatically synced with Google Drive. To learn more, visitEnable and Administer Google Drive for Your AppStream 2.0 Users (https://docs.aws.amazon.com/appstream2/latest/developerguide/google-drive.html).For Windows OS based AppStream 2.0 stacks, you can enableMicrosoft OneDrive for Business, and users can link their OneDrive for Business account to access their files on OneDrive. Changes are automatically synced with OneDrive for Business. To learn more, visitEnable and Administer OneDrive for Your AppStream 2.0 Users (https://docs.aws.amazon.com/appstream2/latest/developerguide/onedrive.html). [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "I don\u2019t want to have Windows automatically update WorkSpaces Personal. How can I control updates and ensure they are tested in advance?", "output": "A: You have full control over the Windows update configuration in your WorkSpaces, and can use Active Directory Group Policy to configure this to meet your exact requirements. If you would like to have advance notice of patches so you can plan appropriately we recommend you refer toMicrosoft Security Bulletin Advance Notificationfor more information. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I monitor consumer lag?", "output": "Topic-level consumer lag metrics are available as part of the default set of metrics that Amazon MSK publishes to CloudWatch for all clusters. No additional setup is required to get these metrics. [Source: https://aws.amazon.com/msk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I see who made changes to the office file and when?", "output": "During a collaborative editing session, any changes made can be seen by all participants in real time. A flag indicator with the user\u2019s initials will track changes made by the user in real time and be visible to all other users. Changes to a document are also tracked in the Activity Feed; you can search for all activities related to a file using the file name. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I share my snapshots with another AWS account?", "output": "Yes. Aurora gives you the ability to create snapshots of your databases, which you can use later to restore a database. You can share a snapshot with a different AWS account, and the owner of the recipient account can use your snapshot to restore a DB that contains your data. You can even choose to make your snapshots public  that is, anybody can restore a DB containing your (public) data.You can use this feature to share data between your various environments (production, dev/test, staging, etc.) that have different AWS accounts, as well as keep backups of all your data secure in a separate account in case your main AWS account is ever compromised. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is continuous delivery?", "output": "Continuous delivery is a software development practice where code changes are automatically built, tested, and prepared for a release to production. AWS CodePipeline is a service that helps you practice continuous delivery. Learn more about continuous deliveryhere (https://aws.amazon.com/devops/continuous-delivery/). [Source: https://aws.amazon.com/codepipeline/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I determine whether my website, program, or application is subject to COPPA?", "output": "For information about the requirements of COPPA and guidance for determining whether your website, program, or other application is subject to COPPA, please refer directly to the resources provided and maintained by theUnited States Federal Trade Commission (https://www.ftc.gov/tips-advice/business-center/guidance/complying-coppa-frequently-asked-questions). This site also contains information regarding how to determine whether a service is directed or targeted, in whole or in part, to children under age 13. [Source: https://aws.amazon.com/comprehend/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I prepare for a Contact?", "output": "Before scheduling a contact, use the Amazon EC2 AMI to launch the required instances to communicate with your satellite, and configure an EC2 instance or Amazon S3 Bucket to receive downlinked data. [Source: https://aws.amazon.com/ground-station/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I notify AWS Transfer Family when a message is ready for delivery to my trading partners endpoint?", "output": "Once your data is ready for delivery, you will need to invoke a service provided API, associate a connector to notify us that it is ready to be delivered, and provide us the recipients information. This will notify the service to send the message to your trading partners endpoint. Refer to the documentation onconnectors to send messages to your trading partner over AS2. (https://docs.aws.amazon.com/transfer/latest/userguide/create-b2b-server.html) [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When should I use Amazon Neptune and Amazon Cloud Directory?", "output": "Neptune is a fast, reliable, fully-managed graph database service that makes it easy to build and run applications that work with highly connected datasets. The core of Neptune is a purpose-built, high-performance graph database engine optimized for storing billions of relationships and querying the graph with milliseconds latency. Neptune supports popular graph models Property Graph and W3C's RDF, and their respective query languages Apache TinkerPop Gremlin and SPARQL, allowing you to easily build queries that efficiently navigate highly connected datasets. [Source: https://aws.amazon.com/cloud-directory/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "My tests generate and save additional log files. Will I see them in my AWS Device Farm reports?", "output": "If you write data to logcat (Android) or the device log (iOS), those log entries will be included in the report. AWS Device Farm does not collect any non-standard logs or other artifacts, although you may transfer files via your test script using the device's or device host's Internet connection. [Source: https://aws.amazon.com/device-farm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which AMIs are supported on instances that use the Nitro Hypervisor?", "output": "EBS backed HVM AMIs with support for ENA networking and booting from NVMe storage can be used with instances that run under theNitroHypervisor. The latest Amazon Linux AMI and Windows AMIs provided by Amazon are supported, as are the latest AMI of Ubuntu, Debian, Red Hat Enterprise Linux, SUSE Enterprise Linux, CentOS, and FreeBSD. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I test Amazon SES responses without sending email to real recipients?", "output": "You can use the Amazon SES mailbox simulator to test your sending rate and to test your ability to handle events such as bounces and complaints, without sending email to actual recipients. Messages that you send to the mailbox simulator don't count against your bounce and complaint metrics or your daily sending quota. However, we do charge you for each message you send to the mailbox simulator, just as if they were messages you sent to actual customers. \nFor more information about the Amazon SES mailbox simulator, see Testing Amazon SES Email Sending in the Amazon SES Developer Guide. [Source: https://aws.amazon.com/ses/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What streaming protocol does Amazon AppStream 2.0 use?", "output": "Amazon AppStream 2.0 uses Amazon DCV to stream your applications to your users. Amazon DCV is a proprietary protocol used to stream high-quality, application video over varying network conditions. It streams video and audio encoded using standard H.264 over HTTPS. The protocol also captures user input and sends it over HTTPS back to the applications being streamed from the cloud. Network conditions are constantly measured during this process and information is sent back to the encoder on the server. The server dynamically responds by altering the video and audio encoding in real time to produce a high-quality stream for a wide variety of applications and network conditions. [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is Neptune Analytics ACID compliant?", "output": "Yes, Neptune Analytics is ACID compliant with strong consistency. [Source: https://aws.amazon.com/neptune/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens to the EBS volumes once I terminate my cluster?", "output": "Amazon EMR will delete the volumes once the EMR cluster is terminated. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Are there exchange limits for Convertible RIs?", "output": "No, there are no exchange limits for Convertible RIs. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are Amazon EC2 X2gd instances?", "output": "Amazon EC2 X2gd instances are the next generation of memory-optimized instances powered by AWS-designed Arm-based AWS Graviton2 processors. X2gd instances deliver up to 55% better price performance compared to x86-based X1 instances and offer the lowest cost per GiB of memory in Amazon EC2.\u00a0They are the first of the X instances to be built on the AWS Nitro System, which is a combination of dedicated hardware and Nitro hypervisor. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Specifically, which License Included Managed AWS Windows AMIs are affected and when does this take effect?", "output": "July 1st, 2019 [Source: https://aws.amazon.com/windows/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I run my Arm-based applications on AWS Fargate?", "output": "Yes. When using Amazon ECS,\u00a0AWS Fargate allows you to run your Arm-based applications by using Arm-compatible container images or multi-architecture container images in\u00a0Amazon Elastic Container Registry\u00a0(Amazon ECR). You can simply specify the CPU Architecture as Arm64\u00a0in your Amazon ECS Task Definition to target AWS Fargate powered by Arm-based\u00a0AWS Graviton Processors.\u00a0Use Amazon EC2 to run Arm workloads on Amazon EKS, which are not supported on AWS Fargate today. [Source: https://aws.amazon.com/fargate/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I start using Amazon EFS?", "output": "To use Amazon EFS, you must have an AWS account. If you don\u2019t already have one, you can sign up for an AWS account, and instantly get access to the\u00a0AWS Free Tier .\nOnce you have created an AWS account, refer to the EFS Getting started \u00a0guide to begin using EFS. You can create a file system through the console, the AWS Command Line Interface (CLI) and the EFS API (and various language-specific SDKs). [Source: https://aws.amazon.com/efs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I resume my WorkSpace Personal session after it stops?", "output": "A: By logging into WorkSpaces from the Amazon WorkSpaces client application, the service will automatically restart your WorkSpace. When you first attempt to log in, the client application will notify you that your WorkSpace was previously stopped, and that your new session will start once your WorkSpace has resumed. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the minimum resolution for the data that Amazon CloudWatch receives and aggregates?", "output": "The minimum resolution supported by CloudWatch is one-second data points, which is a high-resolution metric, or you can store metrics at one-minute granularity. Sometimes metrics are received by Cloudwatch at varying intervals, such as three-minute or five-minute intervals. If you do not specify that a metric is high resolution, by setting the StorageResolution field in the PutMetricData API request, then by default CloudWatch will aggregate and store the metrics at one-minute resolution.Depending on the age of data requested, metrics will be available at the resolutions defined in the retention schedules above. For example, if you request for one-minute data for a day from 10 days ago, you will receive the 1440 data points. However, if you request for one-minute data from five months back, the UI will automatically change the granularity to one-hour and the GetMetricStatistics API will not return any output. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What other AWS services are required to use S3 Access Grants?", "output": "If you intend to use S3 Access Grants for directory identities, you will need to set up AWS IAM Identity Center first. AWS IAM Identity Center helps you create or connect your workforce identities, whether the identities are created and stored in Identity Center, or in an external third-party Identity Provider. Refer to theIdentity Center documentationfor the setup process. Once you have set up the Identity Center instance, you can connect the instance to S3 Access Grants. Thereafter, S3 Access Grants relies on Identity Center to retrieve user attributes such as group membership to evaluate requests and make authorization decisions. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I estimate and control spend on GuardDuty Malware Protection?", "output": "Each new GuardDuty account, in each Region, receives a 30-day free trial of GuardDuty, including the Malware Protection feature (only for EBS data volume scans that are initiated by GuardDuty; there is not a free trial for Malware Protection for Amazon S3). Existing GuardDuty accounts receive a 30-day trial of Malware Protection at no additional charge the first time it is enabled in an account. During the trial period, you can estimate the post-trialcosts estimate on the GuardDuty console (https://docs.aws.amazon.com/guardduty/latest/ug/monitoring_costs.html)usage page. If you are a GuardDuty administrator, you will see the estimated costs for your member accounts. After 30 days, you can view actual costs of this feature in the AWS Billing console.Pricing formalware scanning of EBS volumes is based on the GB of data scanned in a volume. You can apply customizations usingscan options (https://docs.aws.amazon.com/guardduty/latest/ug/what-is-guardduty.html)from the console to mark some AmazonEC2 instances,using tags (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html), to be included or excluded from scanning, thus controlling the cost. In addition, GuardDuty will only scan an AmazonEC2 instance once every 24 hours. If GuardDuty generates multiple AmazonEC2 findings for an Amazon EC2 instance within 24 hours, a scan will only occur for the first relevant AmazonEC2 finding. If AmazonEC2 findings continue, for an instance, 24 hours after the last malware scan, a new malware scan will be initiated for that instance.Pricing for malware scanning of storage objects in S3 buckets is based on the GB of data scanned, as well as the number of files scanned in a designated S3 bucket that is configured for malware scanning. GuardDuty will only scan for newly-uploaded files into configured buckets, and will not scan existing files or files in buckets not designated for malware scanning. [Source: https://aws.amazon.com/guardduty/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Who should use CloudTrail?", "output": "Use CloudTrail if you need to audit activity, monitor security, or troubleshoot operational issues. [Source: https://aws.amazon.com/cloudtrail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are I/O operations in Aurora and how are they calculated?", "output": "I/O operations are performed by the Aurora database engine against its SSD-based virtualized storage layer. Every database page read operation counts as one I/O.The Aurora database engine issues reads against the storage layer to fetch database pages not present in memory in the cache:If your query traffic can be totally served from memory or the cache, you will not be charged for retrieving any data pages from memory.If your query traffic cannot be served entirely from memory, you will be charged for any data pages that need to be retrieved from storage.Each database page is 16 KB in Amazon Aurora MySQL-Compatible Edition and 8 KB in Aurora PostgreSQL-Compatible Edition.Aurora was designed to remove unnecessary I/O operations (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.StorageReliability.html)to reduce costs and ensure resources are available for serving read/write traffic. Write I/O operations are only consumed when persisting redo log records in Aurora MySQL-Compatible Edition or write ahead log records in Aurora PostgreSQL-Compatible Edition to the storage layer for the purpose of making writes durable.Write I/O operations are counted in 4 KB units. For example, a log record that is 1,024 bytes counts as one write I/O operation. However, if the log record is larger than 4 KB, more than one write I/O operation is needed to persist it.Concurrent write operations whose log records are less than 4 KB might be batched together by the Aurora database engine in order to optimize I/O consumption. Unlike traditional database engines, Aurora never flushes dirty data pages to storage.You can see how many I/O requests your Aurora instance is consuming by checking the AWS Management Console. To find your I/O consumption, go to the Amazon RDS section of the console, look at your list of instances, select your Aurora instances, then look for the VolumeReadIOPs and VolumeWriteIOPs metrics in the monitoring section.For more information on the pricing of I/O operations, visit theAurora pricing page (https://aws.amazon.com/rds/aurora/pricing/). You are charged for read and write I/O operations when you configure your database clusters to the Aurora Standard configuration. You are not charged for read and write I/O operations when you configure your database clusters to Amazon Aurora I/O-Optimized. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I know which user uploaded a file to EFS?", "output": "For new files, the POSIX user id associated with the user uploading the file will be set as the owner of the file inyour EFS file system. Additionally, you can use Amazon CloudWatch to track your users activity for file creation,update, delete, and read operations. Visit thedocumentation (https://docs.aws.amazon.com/transfer/latest/userguide/monitoring.html)to learn more on how to enable Amazon CloudWatchlogging. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What broker instance sizes can I provision on an MSK cluster?", "output": "For provisioned clusters, you can choose EC2 T3.small instances or instances within the EC2 M7g and M5 instance families. For serverless clusters, brokers are completely abstracted.MSK also offers Standard and Express Broker types. [Source: https://aws.amazon.com/msk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will I be able to use the new features on my existing search domains created with the 2011-01-01 version of Amazon CloudSearch?", "output": "No. Existing search domains created with the 2011-01-01 version of Amazon CloudSearch will not have access to the features available in the new version. To access the new features you will have to create a new search domain using the 2013-01-01 version of Amazon CloudSearch. [Source: https://aws.amazon.com/cloudsearch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What kinds of applications are available in the AWS Serverless Application Repository?", "output": "The AWS Serverless Application Repository includes applications for Alexa Skills, chatbots, data processing, IoT, real time stream processing, web and mobile back-ends, social media trend analysis, image resizing, and more from publishers on AWS. [Source: https://aws.amazon.com/serverless/serverlessrepo/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a record?", "output": "A record is the unit of data stored in an Amazon Kinesis data stream. A record is composed of a sequence number, partition key, and data blob. Data blob is the data of interest your data producer adds to a data stream. The maximum size of a data blob (the data payload before Base64-encoding) is 1 megabyte (MB). [Source: https://aws.amazon.com/kinesis/data-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which DMS feature should I use for homogeneous database migrations?", "output": "For homogeneous migrations, we recommend using DMS built-in native tooling for supported engines, due to its familiarity and seamless migration. You do not need to provision or monitor the migration, and you only pay for the hours used during the migration. To check supported engines, go toDMS documentation page (https://docs.aws.amazon.com/dms/latest/userguide/data-migrations.html).For heterogeneous migrations or continuous data replications with data fluctuations, we recommend using AWS DMS Serverless as it automatically monitors and scales resources to meet demand without manual intervention or over provisioning resources, saving you time and cost. On-demand instances, on the other hand, are good for predictable, stable data transfers, as they can be rightsized for performance and cost. SeeAWS DMS Serverless documentation (https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Serverless.html)for supported engines. [Source: https://aws.amazon.com/dms/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the AppStream 2.0 Client?", "output": "The AppStream 2.0 client is a native application that is designed for users who require additional functionality not available from web browsers during their AppStream 2.0 streaming sessions. The AppStream 2.0 support Windows and macOS client applications. The client lets users use multiple monitors and USB peripherals such as 3D mice with their applications. The client also supports keyboard shortcuts, such as Alt + Tab, clipboard shortcuts, and function keys. [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does the pricing for AWS Config rules include the costs for Lambda functions?", "output": "You can choose from a set of managed rules provided by AWS or you can author your own rules, written as Lambda functions. Managed rules are fully maintained by AWS and you do not pay any additional Lambda charges to run them. You can enable managed rules, provide any required parameters, and pay a single rate for each active AWS Config rule in a given month. Custom rules give you full control as they are applied as Lambda functions in your account. In addition to monthly charges for an active rule, standardLambda free tier (https://aws.amazon.com/free/)* and function application rates apply to custom AWS Config rules.*AWS Free Tier is not available in the AWS China (Beijing) Region or the AWS China (Ningxia) Region. [Source: https://aws.amazon.com/config/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the Kinesis Video Streams management console?", "output": "The Kinesis Video Streams management console enables you to create, update, manage, and monitor your video streams. It console can also playback your media streams live or on an on-demand basis, as long as the content in the streams is in the supported media type. Using the player controls, you can view the live stream, skip forwards or backwards 10 seconds, use the date and time picker to rewind to a point in the past when you have set the corresponding retention period for the video stream. The Kinesis Video Streams management console's video playback capabilities are offered as a quick diagnostic tool for development and test scenarios for developers as they build solutions using Kinesis Video Streams. [Source: https://aws.amazon.com/kinesis/video-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the compliance standards supported by Step Functions?", "output": "Step Functions conforms to HIPAA, FedRAMP, SOC, GDPR, and other common compliance standards. See theAWS Cloud Security (https://aws.amazon.com/compliance/services-in-scope/)site to get a detailed list of supported compliance standards. [Source: https://aws.amazon.com/step-functions/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I remove unused permissions?", "output": "You might have IAM users, roles, and permissions that you no longer require in your AWS account. We recommend that you remove them with the goal of achieving least-privilege access. For IAM users, you can review password and access key last used information. For roles, you can review role last used information. This information is available through the IAM console, APIs, and SDKs. Last used information helps you identify users and roles that are no longer in use and safe to remove. You also can refine permissions by reviewing service and last accessed information to identify unused permissions. For more information, seeRefining permissions in AWS using last accessed information (https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_access-advisor.html).If you enable the unused access analyzer as a paid feature, IAM Access Analyzer continuously analyzes your accounts to identify unused access and creates a centralized dashboard with findings. The dashboard helps security teams review findings centrally and prioritize accounts based on the volume of findings. Security teams can use the dashboard to review findings centrally and prioritize which accounts to review based on the volume of findings. The findings highlight unused roles, unused access keys for IAM users, and unused passwords for IAM users. For active IAM roles and users, the findings provide visibility into unused services and actions. that simplifies inspecting unused access to guide you toward least privilege. With this feature, you pay per IAM role or IAM user analyzed per month. [Source: https://aws.amazon.com/iam/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon DocumentDB have a free tier and can you get started for free?", "output": "Yes, you can try Amazon DocumentDB for free using the 1-month free trial. If you have not used Amazon DocumentDB before, you are eligible for a one month free trial. Your organization gets 750 hours per month of t3.medium instance usage, 30 million IOs, 5 GB of storage, and 5 GB of backup storage for free for 30 days. Once your one month free trial expires or your usage exceeds the free allowance, you can shut down your cluster to avoid any charges, or keep it running at ourstandard on-demand rates (https://aws.amazon.com/documentdb/pricing/). To learn more, refer to theDocumentDB free trial page (https://aws.amazon.com/documentdb/free-trial/). [Source: https://aws.amazon.com/documentdb/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do A1 instances support the AWS Nitro System?", "output": "Yes, A1 instances are powered by theAWS Nitro System, a combination of dedicated hardware and Nitro hypervisor. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I know if I qualify for an SLA Service Credit?", "output": "You are eligible for an SLA credit for either Amazon EC2 or Amazon EBS (whichever was Unavailable, or both if both were Unavailable) if the Region that you are operating in has an Monthly Uptime Percentage of less than 99.99% during any monthly billing cycle. For full details on all of the terms and conditions of the SLA, as well as details on how to submit a claim, see theAmazon Compute Service Level Agreement. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I create a read replica in another Region as my primary?", "output": "No, your read replica can only be provisioned in the same or different AZ of the same Region as your cache node primary.You can, however, use theGlobal Datastore (https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Redis-Global-Datastore.html)to work with fully managed, fast, reliable, and security-focused replication across AWS Regions. Using this feature, you can create cross-Region read replica clusters for ElastiCache to enable low-latency reads and disaster recovery across AWS Regions. [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I have heterogeneous clients when using Auto Discovery?", "output": "Yes, the same ElastiCache cluster can be connected through a client capable of Auto Discovery and the traditional Memcached client at the same time. ElastiCache remains 100% Memcached compliant. [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a resources configuration?", "output": "Configuration of a resource is defined by the data included in the Configuration Item (CI) of AWS Config. The initial release of AWS Config rules makes the CI for a resource available to relevant rules. AWS Config rules can use this information along with any other relevant information such as other attached resources and business hours to evaluate compliance of a resources configuration. [Source: https://aws.amazon.com/config/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What versions of iOS and Android are supported?", "output": "iOS 14.0+ and Android 8.0+ are supported. [Source: https://aws.amazon.com/console/faq-console/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What does it cost?", "output": "Refer to theAmazon Translate pricing page (https://aws.amazon.com/translate/pricing/)to learn more. [Source: https://aws.amazon.com/translate/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How is Celebrity Recognition different for video analysis?", "output": "With Rekognition Video, you can detect and recognize when and where well known persons appear in a video. The time-coded output includes the name and unique id of the celebrity, bounding box coordinates, confidence score, and URLs pointing to related content for the celebrity, for example, the celebrity's IMDB link. The celebrity is also detected even if sometimes the face becomes occluded in the video. This feature allows you to index and search digital video libraries for use cases related to your specific marketing and media needs. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I install custom libraries to use in my notebook code?", "output": "All Spark queries run on your EMR cluster, so you need to install all runtime libraries that your Spark application uses on the cluster. You can easily install notebook-scoped libraries within a notebook cell. You can also install Jupyter Notebook kernels and Python libraries on a cluster master node either within a notebook cell or while connected using SSH to the master node of the cluster. For more information, seedocumentation. Additionally, you can use a bootstrap action or a custom AMI to install required libraries when you create a cluster. For more information, seeCreate Bootstrap Actions to Install Additional SoftwareandUsing a Custom AMIin the Amazon EMR Management Guide. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How far behind the primary will my replicas be?", "output": "Since Amazon DocumentDB replicas share the same data volume as the primary instance, there is virtually no replication lag. We typically observe lag times in the 10s of milliseconds. [Source: https://aws.amazon.com/documentdb/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How many domains and subdomains can I add to my certificate?", "output": "You can add up to 10 domains or subdomains per certificate. Lightsail does not currently support wild card domains. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will my users' application settings persist across stacks?", "output": "Yes. Your users' application settings persist across stacks. [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the settings for placing my watermark over the active video region rather than over the matte?", "output": "To place your watermark so that it is always over the active video content, use relative size for the MaxWidth and MaxHeight settings, and set the Target to be Content. For example, to fix the watermark size to 10% of the active output video size, set both MaxWidth and MaxHeight to 10%. [Source: https://aws.amazon.com/elastictranscoder/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use the AWS Management Console with VM Import/Export?", "output": "No. VM Import/Export commands are available via EC2 CLI and API. You can also use theAWS Management Portal for vCenterto import VMs into Amazon EC2. Once imported, the resulting instances are available for use via the AWS Management Console. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why should customers choose EC2 M5 Instances over EC2 M4 Instances?", "output": "Compared with EC2 M4 Instances, the new EC2 M5 Instances deliver customers greater compute and storage performance, larger instance sizes for less cost, consistency and security. The biggest benefit of EC2 M5 Instances is based on its usage of the latest generation of Intel Xeon Scalable processors (Skylake-SP or Cascade Lake), which deliver up to 20% improvement in price/performance compared to M4. With AVX-512 support in M5 vs. the older AVX2 in M4, customers will gain 2x higher performance in workloads requiring floating point operations. M5 instances offer up to 25 Gbps of network bandwidth and up to 10 Gbps of dedicated bandwidth to Amazon EBS. M5 instances also feature significantly higher networking and Amazon EBS performance on smaller instance sizes with EBS burst capability. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "In addition to Video resolution what else can affect the quality of the Video APIs ?", "output": "Besides video resolution, the quality and representative faces part of the face collections to search has major impact. Using multiple face instances per person with variations like beard, glasses, poses (profile and frontal) will significantly improve the performance. Typically very fast moving people may experience low recall. In addition, blurred videos may also experience lower quality. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I track status of my file transfers?", "output": "You can monitor the current status of your file transfer operations using the ListFileTransferResults API command. In addition, SFTP connectors emit detailed logs in Amazon CloudWatch, including status of your file transfers, operation type (send or retrieve), timestamp, file path, and error description (if any) to help you maintain data lineage. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Today I use an AWS Partner ISV solution to analyze my logs from CloudWatch. What does CloudWatch Logs Insights change for me?", "output": "CloudWatch Logs already supports integration options with other AWS Services such as Amazon Kinesis, Amazon Kinesis Data Firehose, Amazon Elasticsearch and AWS Partner ISV solutions such as Splunk, Sumo Logic, and DataDog, among others, to provide you with choice and flexibility across all environments, for your custom log processing, enrichment, analytics, and visualization needs. In addition, the query capabilities of CloudWatch Logs Insights are available for programmatic access through the AWS SDK, to facilitate AWS ISV Partners to build deeper integrations, advanced analytics, and additional value on top of CloudWatch Logs Insights. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I share my directory with other AWS accounts in the new AWS Region?", "output": "Yes, with multi-region replication you have the flexibility to share your directory with other AWS accounts per Region. Directory sharing configurations are not automatically replicated from the primary region. To learn how to share your directory with other AWS accounts, see thedocumentation (https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_directory_sharing.html). [Source: https://aws.amazon.com/directoryservice/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a hardware root of trust, and why might I want one?", "output": "Hardware roots of trust provide tamper-protected trusted execution environments where a true random number generator can produce the private keys used for encryption functions. These hardware secure elements are resistant to malware tampering and are physically tied to a given IoT device, establishing a strong root of trust upon which software can be deployed safely. [Source: https://aws.amazon.com/greengrass/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What popular graph query languages does Amazon Neptune Analytics support?", "output": "You can use openCypher, an open-source project that makes it easy to use the Cypher language for graph processing, invoking the Neptune Analytics algorithms, and for vector similarity search. [Source: https://aws.amazon.com/neptune/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Cognito identity pools receive or store confidential information about my users from the identity providers?", "output": "No. Cognito Identity does not receive any confidential information (such as email address, friends list, etc.) from the identity providers. [Source: https://aws.amazon.com/cognito/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is S3 Transfer Acceleration HIPAA eligible?", "output": "Yes, AWS has expanded itsHIPAA compliance programto include S3 Transfer Acceleration as a HIPAA eligible service. If you have an executed Business Associate Agreement (BAA) with AWS, you can use S3 Transfer Acceleration to make fast, easy, and secure transfers of files, including protected health information (PHI) over long distances between your client and your Amazon S3 bucket. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which AWS services are supported by Amazon AppFlow?", "output": "Supported AWS services include Amazon S3, Amazon RedShift, Amazon Connector Customer Profiles, Amazon Lookout for Metrics, and Amazon Honeycode, and were continuing to add more all the time. [Source: https://aws.amazon.com/appflow/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will customers need to modify their applications and workloads to be able to run on the M6g instances?", "output": "The changes required are dependent on the application. Customers running applications built on open source software will find that the Arm ecosystem is well developed and already likely supports their applications. Most Linux distributions as well as containers (Docker, Kubernetes, Amazon ECS, Amazon EKS, Amazon ECR) support the Arm architecture. Customers will find Arm versions of commonly used software packages available for installation through the same mechanisms that they currently use. Applications that are based on interpreted languages (such as Java, Node, Python) not reliant on native CPU instruction sets should run with minimal to no changes. Applications developed using compiled languages (C, C++, GoLang) will need to be re-compiled to generate Arm binaries. The Arm architecture is well supported in these popular programming languages and modern code usually requires a simple \u2018Make\u2019 command. Refer to theGetting Started guide on GitHubfor more details. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon API Gateway provide logging support?", "output": "Yes. Amazon API Gateway integrates with Amazon CloudWatch Logs. You can optionally enable logging for each stage in your API. For each method in your REST APIs, you can set the verbosity of the logging, and if full request and response data should be logged. [Source: https://aws.amazon.com/api-gateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I enable an AWS service integration?", "output": "To get started using an AWS service integrated with AWS Organization, navigate in the AWS Management Console to that service and enable the integration. [Source: https://aws.amazon.com/organizations/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is AWS IoT Device Tester for FreeRTOS required for qualification and listing in the AWS Partner Device Catalog?", "output": "Yes, you can learn more about how to get listedhere (https://aws.amazon.com/partners/programs/dqp/). [Source: https://aws.amazon.com/freertos/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which container image types are supported?", "output": "You can deploy third-party Linux base images (e.g. Alpine or Debian) to Lambda in addition to the Lambda provided images. AWS Lambda will support all images based on the following image manifest formats: Docker Image Manifest V2 Schema 2 (used with Docker version 1.10 and newer) or Open Container Initiative (OCI) Spec (v1.0 and up). Lambda supports images with a size of up to 10GB. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If my account is not part of an organization, can I still use AWS Artifact Organization Agreements?", "output": "No, AWS Artifact Organization Agreements is only available for accounts using AWS Organizations. If you would like to create or join an organization, follow the instructions inCreating and Managing an AWS Organizations (https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_org.html). [Source: https://aws.amazon.com/artifact/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Tape Gateway?", "output": "Tape Gateway is a cloud-based Virtual Tape Library (VTL). It presents your backup application with a VTL interface, consisting of a media changer and tape drives. You can create virtual tapes in your virtual tape library using the AWS Management Console. Your backup application can read data from or write data to virtual tapes by mounting them to virtual tape drives using the virtual media changer. Virtual tapes are discovered by your backup application using its standard media inventory procedure. Virtual tapes are available for immediate access and are backed by Amazon S3. You can also archive tapes. Archived tapes are stored in Amazon S3 Glacier or Amazon S3 Glacier Deep Archive. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will my data be secure and private?", "output": "All Amazon Personalize models are unique to the customers data set, and are not shared across other AWS accounts or with Amazon Retail, Amazon Prime, or any other business unit. No data is used to train or propagate models for other customers; the customers model inputs and outputs are entirely owned by the account. Every interaction customers have with Amazon Personalize is protected by encryption. Any user, items, or interactions data processed by Amazon Personalize can be further encrypted with customer keys through AWS Key Management Service, and encrypted at rest and in transit in the AWS Region where the customer is using the service. Administrators can also control access to Amazon Personalize through anAWS Identity and Access Management (https://aws.amazon.com/iam/)(IAM) permissions policy, ensuring that sensitive information is kept secure and confidential. [Source: https://aws.amazon.com/personalize/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get my data into Amazon S3?", "output": "Amazon EMR provides several ways to get data onto a cluster. The most common way is to upload the data to Amazon S3 and use the built-in features of Amazon EMR to load the data onto your cluster. You can use the Distributed Cache feature of Hadoop to transfer files from a distributed file system to the local file system. For more details, seedocumentation. Alternatively, if you are migrating data from on premises to the cloud, you can use one of theCloud Data Migrationservices from AWS. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When should I specify a different Custom Image for my Spark drivers and Spark executors?", "output": "You can specify separate images for your Spark drivers and executors when you want include different dependencies or libraries. Removing libraries that are not required in both images can result in a smaller image size and thus reduce job start time. You can specify a single image for both drivers and executors (spark.kubernetes.container.image) or specify a different image for drivers (spark.kubernetes.driver.container.image) and executors (spark.kubernetes.executor.container.image). [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon OpenSearch Service provide automated snapshots?", "output": "Yes. By default, Amazon OpenSearch Service automatically creates hourly snapshots of each Amazon OpenSearch Service domain and retains them for 14 days. [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I increase the size of my Amazon WorkSpaces Personal storage volumes?", "output": "A: Yes. You can increase the size of the root and user volumes attached to your WorkSpaces Personal at any time. For more information, seeour documentation on Modifying WorkSpaces. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I route my AWS Storage Gateway internet traffic through a local proxy server?", "output": "Yes. Volume and Tape Gateways support configuration of a Socket Secure version 5 (SOCKS5) proxy between your on-premises gateway and AWS. File Gateway supports configuration of a HyperText Transfer Protocol (HTTP) proxy. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the pricing structure between various regions?", "output": "You can transfer data between Amazon SQS and Amazon EC2 or AWS Lambda free of charge within a single region.When you transfer data between Amazon SQS and Amazon EC2 or AWS Lambda in different regions, you will be charged the normal data transfer rate. For more information, seeAmazon SQS Pricing (https://aws.amazon.com/sqs/pricing/). [Source: https://aws.amazon.com/sqs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I share my AWS Cloud9 environment with other people?", "output": "You can share your AWS Cloud9 environment by clicking theSharebutton in the top right of your IDE. You are prompted for the AWS Identity and Access Management (IAM) user name and the desired access levels for the person you want to collaborate with. Once you enter these details, the environment is available to both the participants for real-time collaboration on IDE features and command line sessions. [Source: https://aws.amazon.com/cloud9/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the advantages of Automatic Dashboards?", "output": "Automatic Dashboards are pre-built with AWS service recommended best practices, remain resource aware, and dynamically update to reflect the latest state of important performance metrics. You can now filter and troubleshoot to a specific view without adding additional code to reflect the latest state of your AWS resources. Once you have identified the root cause of a performance issue, you can quickly act by going directly to the AWS resource. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I manage and control access to my Amazon Kinesis data stream?", "output": "Kinesis Data Streams integrates with AWS Identity and Access Management (IAM), a service that helps you securely control access to your AWS services and resources for your users. For example, you can create a policy that allows only a specific user or group to add data to your data stream. You can also attach a resource-based policy to your data stream or registered consumer to control access at the resource level. For more information about access management and control of your data stream, seeControlling Access to Amazon Kinesis Data Streams Resources using IAM (https://docs.aws.amazon.com/kinesis/latest/dev/kinesis-using-iam.html). [Source: https://aws.amazon.com/kinesis/data-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I modify how I monitor specific clusters in Amazon EKS or Amazon ECS?", "output": "GuardDuty Runtime Monitoring allows you to selectively configure whichAmazon EKS clusters (https://docs.aws.amazon.com/guardduty/latest/ug/gdu-runtime-approaches-agent-deployment-eks-clusters.html)orAmazon ECS clusters (https://docs.aws.amazon.com/guardduty/latest/ug/managing-gdu-agent-ecs-automated.html#ecs-fargate-manage-agent-multiple-accounts)are to be monitored for threat detection. With cluster-level configurability, you can selectively monitor specific clusters for threat detection or continue using account-level configurability to monitor all EKS or ECS clusters, respectively, in a given account and Region. [Source: https://aws.amazon.com/guardduty/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I apply custom authorization with Storage Browser for S3?", "output": "To apply custom authorization, you configure your application to provide Storage Browser with STS tokens authorizing the user to work with S3 datasets they are permitted to access. In the session policy for each STS token, you must include the end-user\u2019s access levels for each S3 dataset they are authorized to access. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do I have to move to the new SDK to upgrade to OpenSearch 1.0?", "output": "No. From a backward compatibility perspective, we will ensure that your existing setup continues to work with OpenSearch 1.0. However, we recommend that you eventually move to the latest SDK for a cleaner and up-to-date experience, as mentioned above. [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I make an AWS Lambda function respond to updates in an Amazon DynamoDB table?", "output": "You can trigger a Lambda function on DynamoDB table updates by subscribing your Lambda function to the DynamoDB Stream associated with the table. You can associate a DynamoDB Stream with a Lambda function using the Amazon DynamoDB console, the AWS Lambda console, or Lambda\u2019s registerEventSource API. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I upload documents to my search domain?", "output": "You upload documents to your domain using the AWS Management Console, AWS SDKs, or AWS CLI. [Source: https://aws.amazon.com/cloudsearch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do you support encrypted search results?", "output": "Yes. We support HTTPS for all Amazon CloudSearch requests. [Source: https://aws.amazon.com/cloudsearch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use Amazon DocumentDB snapshots outside of the service?", "output": "No. Amazon DocumentDB snapshots can only be used inside of the service. [Source: https://aws.amazon.com/documentdb/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I have my own identity provider to support user sign-up and sign-in?", "output": "Yes, you can easily and securely add sign-up and sign-in functionality to your apps with Amazon Cognito. Your users can sign-up and sign-in using email, phone number, or user name. You can also implement enhanced security features, such as email verification, phone number verification, and multi-factor authentication. Cognito enables you to customize workflows by, for example, adding application-specific logic to user registration for fraud detection and user validation through AWS Lambda. To learn more, visit our docs. [Source: https://aws.amazon.com/cognito/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do I have to rewrite my application to use the AmazonSQSBufferedAsyncClient for Java?", "output": "No. The AmazonSQSBufferedAsyncClient for Java is implemented as a drop-in replacement for the existing AmazonSQSAsyncClient.If you update your application to use the latest AWS SDK and change your client to use the AmazonSQSBufferedAsyncClient for Java instead of the AmazonSQSAsyncClient, your application will receive the added benefits of automatic batching and prefetching. [Source: https://aws.amazon.com/sqs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does ACM provide public Organizational Validation (OV) or Extended Validation (EV) certificates?", "output": "No. [Source: https://aws.amazon.com/certificate-manager/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What does your AWS Migration Hub Refactor Spaces Service Level Agreement guarantee?", "output": "Our SLA guarantees a Monthly Uptime Percentage of at least 99.9% for AWS Migration Hub Refactor Spaces within a Region. [Source: https://aws.amazon.com/migration-hub/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I terminate my cluster when my steps are finished?", "output": "Yes. You can terminate your cluster automatically when all your steps finish by turning the auto-terminate flag on. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "After I enable the CloudTrail Lake feature, how long do I need to wait to begin writing queries?", "output": "You can begin querying the activities that occur after enabling the feature almost immediately. [Source: https://aws.amazon.com/cloudtrail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I find a list of Amazon public datasets stored in Amazon EBS Snapshots?", "output": "You can use the AWS Management Console to find public datasets stored as Amazon Snapshots. Log into the console, select the Amazon EC2 Service, select Snapshots and then filter onPublic Snapshots (https://console.aws.amazon.com/ec2/v2/home#Snapshots:visibility=public;sort=startTime). All information on public datasets is available in ourAWS Public Datasets (https://aws.amazon.com/public-datasets/)resource center. [Source: https://aws.amazon.com/ebs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What can I do with AWS Lambda functions and Amazon SNS?", "output": "By subscribing AWS Lambda functions to Amazon SNS topics, you can perform custom message handling. You can invoke an AWS Lambda function to provide custom message delivery handling by first publishing a message to an AWS Lambda function, have your Lambda function modify a message (e.g. localize language) and then filter and route those messages to other topics and endpoints. Apps and services that already send Amazon SNS notifications, such as Amazon CloudWatch, can now immediately take advantage of AWS Lambda without having to provision or manage infrastructure for custom message handling. You can also use delivery to an AWS Lambda function as a way to publish to other AWS services such as Amazon Kinesis or Amazon S3. You can subscribe an AWS Lambda function to the Amazon SNS topic, and then have the Lambda function in turn write to another service. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If we sign-up for Consolidated Billing, can we get the AWS Free Tier for each account?", "output": "No, customers that use Consolidated Billing to consolidate payment across multiple accounts will only have access to one Free Tier per Organization. [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a member account?", "output": "A member account is an AWS account, other than the management account, that is part of an organization. If you are an administrator of an organization, you can create member accounts in the organization and invite existing accounts to join the organization. You also can apply policies to member accounts. A member account can belong to only one organization at a time. [Source: https://aws.amazon.com/organizations/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do I need to increase Amazon SES sending limits to use Amazon WorkMail?", "output": "No. This is not needed to use with Amazon WorkMail. The SES limits only apply when you are using Amazon SES using the Amazon SES API for sending bulk email from your AWS account. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can Amazon SNS use the same AWS Lambda functions that I use with other services (e.g. Amazon S3)?", "output": "You can use the same AWS Lambda functions that you use with other services as long as the same function can parse the event formats from Amazon SNS in addition to the event format of the other services. For the SNS event format please read ourblog. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I use Application Signals with Lambda?", "output": "You can enable Application Signals for your function with a single click in the \u201cMonitoring and operational tools\u201d section under Configuration tab in the Lambda console. After enabling Application Signals, you can view pre-built dashboards, service map, and more, and analyze the performance and health of you serverless applications in the CloudWatch console. To learn more, visit the Lambda developer guide and Application Signals developer guide. Visit CloudWatch pricing page to learn more about how you are charged for using Application Signals with your Lambda functions. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I get started with using Optimize CPUs for EC2 Instances?", "output": "For more information on how to get started with Optimize CPUs and supported instance types, please visit the Optimize CPUs documentation pagehere. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Amazon SWF help in coordinating tasks reliably in my application?", "output": "Amazon SWF provides useful guarantees around task assignment. It ensures that a task is never duplicated and is assigned only once. Thus, even though you may have multiple workers for a particular activity type (or a number of instances of a decider), Amazon SWF will give a specific task to only one worker (or one decider instance). Additionally, Amazon SWF keeps at most one decision task outstanding at a time for a workflow execution. Thus, you can run multiple decider instances without worrying about two instances operating on the same execution simultaneously. These facilities enable you to coordinate your workflow without worrying about duplicate, lost, or conflicting tasks. [Source: https://aws.amazon.com/swf/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I create auto scaling policies for my Amazon AppStream 2.0 fleet?", "output": "You can create automatic scaling policies from the Fleets tab in theAppStream 2.0 console (https://console.aws.amazon.com/appstream2), or by using the AWS SDK. [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is AWS DMS homogeneous data migration serverless?", "output": "Yes, AWS DMS built-in native tooling for homogeneous data migration is serverless. It does not use replication instances and will automatically monitor and scale migration resources as needed to provide a seamless migration. [Source: https://aws.amazon.com/dms/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How long does it take CloudTrail to deliver an event for an API call?", "output": "Typically, CloudTrail delivers an event within 5 minutes of the API call. For more information on how CloudTrail works, seehere (https://docs.aws.amazon.com/awscloudtrail/latest/userguide/how-cloudtrail-works.html). [Source: https://aws.amazon.com/cloudtrail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I enable Fast Snapshot Restore (FSR)?", "output": "To use the feature, invoke the new enable-fast-snapshot-restores API on a snapshot within the availability zone (AZ) where initialized volumes are to be restored.The FSR-enabled snapshot may be in any one of the following states: enabling, optimizing, enabled, disabling, disabled. State transitions are published as CloudWatch events and the FSR state can be checked via the describe-fast-snapshot-restores API.Enabling FSR on a snapshot does not change any existing snapshot API interactions, and existing workflows will not need to change. FSR can be enabled or disabled on account-owned snapshots only. FSR cannot be applied to shared snapshots. You can view the list of your FSR-enabled snapshots via API or the console. [Source: https://aws.amazon.com/ebs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I customize the default behavior of Account Takeover Prevention?", "output": "When ATP determines that a users credential has been compromised, it generates alabel (https://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-labels.html)to indicate a match. By default, AWS WAF automatically blocks login attempts that are determined to be malicious or anomalous (for example, abnormal levels of failed login attempts, repeat offenders, and login attempts from bots). You can change how AWS WAF responds to matches by writing AWS WAF rules that act on the label. [Source: https://aws.amazon.com/waf/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is AWS responsible for in EKS clusters using Amazon EKS Auto Mode?", "output": "\n\n\n Using Amazon EKS Auto Mode, AWS expands its responsibility compared to customer-managed AWS infrastructure in EKS clusters. In addition to operating the Kubernetes cluster control plane, with EKS Auto Mode enabled AWS also takes responsibility for securing, configuring, and managing the AWS infrastructure in EKS clusters your applications need to run. To do so, AWS infrastructure resources (like EC2 instances) in EKS clusters using EKS Auto Mode have limitations compared to their customer-managed counterparts. For example, you cannot connect remotely via SSH or SSM, modify the instance IAM role, replace the root volume, or attach additional elastic network interfaces to EC2 instances managed by EKS Auto Mode, as doing so would limit the ability for AWS to secure and manage them. \n\n\n [Source: https://aws.amazon.com/eks/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How is CloudWatch Lambda Insights priced?", "output": "CloudWatch Lambda Insights automatically collects custom metrics from performance events ingested as CloudWatch logs from your Lambda functions. More details on pricing is available on theCloudWatch pricing page (https://aws.amazon.com/cloudwatch/pricing/). [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I write to an Apache Hudi data set?", "output": "Changes to Apache Hudi data sets are made using Apache Spark. With Apache Spark, Apache Hudi data sets are operated on using the Spark DataSource API, enabling you to read and write data. DataFrame containing newly added data or updates to existing data can be written using the same DataSource API\". You can also use the Hudi DeltaStreamer utility. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the JVM environment that Lambda uses for executing my function?", "output": "Lambda provides the Amazon Linux build of openjdk 1.8. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does AWS offer short codes and long codes for purchase?", "output": "Yes. You can reserve a dedicated short code, long codes, and other origination ID types. You can request origination IDs via\u00a0 the AWS End User Messaging console. For more information, seeRequest a Phone Number. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When is gRPC communication used through Amazon CloudFront?", "output": "Amazon CloudFront communicates over gRPC when the following conditions are met:HTTP/2 is enabled on your distributionPOST requests and gRPC are enabled on a cache behaviorA client sends a content-type header with the value of application/grpc over an HTTP/2 connection [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are IAM users and should I still be using them?", "output": "IAM users are identities with long-term credentials. You might be using IAM users forworkforce users (https://aws.amazon.com/single-sign-on/faqs/#General). In this case, AWS recommends using an identity provider and federating into AWS by assuming roles. You also can use roles to grant cross-account access to services and features such as AWS Lambda functions. In some scenarios, you might require IAM users withaccess keys (https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html)that have long-term credentials with access to your AWS account. For these scenarios, AWS recommends using IAMaccess last used information (https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_finding-unused.html)to rotate credentials often and remove credentials that are not being used. For more information, seeOverview of AWS identity management: Users (https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction_identity-management.html). [Source: https://aws.amazon.com/iam/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Are there any new APIs to further assist in reading old data?", "output": "Yes. There are API enhancements to ListShards, GetRecords, and SubscribeToShard APIs. You can use the new filtering option with the TimeStamp parameter available in the ListShards API to efficiently retrieve the shard map and improve the performance of reading old data. The TimeStamp filter lets applications discover and enumerate shards from the point in time you wish to reprocess data and eliminate the need to start at the trim horizon. GetRecords and SubscribeToShards have a new field, ChildShards, which allows you to quickly discover the children shards when an application finishes reading data from a closed shard, instead of having to traverse the shard map again. The fast discovery of shards makes efficient use of the consuming applications compute resources for any sized stream, irrespective of the data retention period. [Source: https://aws.amazon.com/kinesis/data-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon OpenSearch Service support Amazon VPC?", "output": "Yes, Amazon OpenSearch Service is integrated with Amazon VPC. When choosing VPC access, IP addresses from your VPC are attached to your Amazon OpenSearch Service domain and all network traffic stays within the AWS network and is not accessible to the Internet. Moreover, you can use security groups and IAM policies to restrict access to your Amazon OpenSearch Service domains. [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I set up alarms on the Amazon API Gateway metrics?", "output": "Yes, Amazon API Gateway sends logging information and metrics to Amazon CloudWatch. You can utilize the Amazon CloudWatch console to set up custom alarms. [Source: https://aws.amazon.com/api-gateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I use AWS Elemental MediaLive with my other workflow vendors?", "output": "AWS Elemental MediaLive provides a robust and flexible API that ecosystem partners such as content management systems (CMS) and packagers can integrate with. AWS Elemental MediaLive runs within customers AWS accounts, so other services, components or software that runs or interfaces with customer-maintained VPCs are also easily incorporated in video workflows. [Source: https://aws.amazon.com/medialive/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon Cloud Directory provide any sample schemas?", "output": "Yes, currently Amazon Cloud Directory provides the following sample schemas: [Source: https://aws.amazon.com/cloud-directory/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When should I run my jobs in EKS vs. Fargate vs. ECS?", "output": "You should run your jobs on Fargate when you want AWS Batch to handle provisioning of compute completely abstracted from ECS infrastructure. You should run your jobs on ECS if you need access to particular instance configurations (particular processors, GPUs, or architecture) or for very-large scale workloads. If you have chosen Kubernetes as your container orchestration technology, you can standardize your batch workloads using Batch integration with EKS.\nDepending on your use case, currently Fargate jobs will start faster in the case of initial scale-out of work, as there is no need to wait for EC2 instance or pods to launch. However, for larger workloads EKS or ECS may be faster as Batch reuses instances and container images to run subsequent jobs. [Source: https://aws.amazon.com/batch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What does the Delivery Status feature of Amazon SNS do?", "output": "The Delivery Status feature lets you collect information on success rates, failure rates and dwell times of your push notifications for the supported mobile notification platforms. The currently supported platforms include Apple (APNS), Google (FCM), Windows (WNS and MPNS), Amazon (ADM), and Baidu. The status information is captured in the Amazon CloudWatch log groups created by Amazon SNS on your behalf. Additionally, you can create actionable metrics in Amazon CloudWatch and trigger alarms based on the patterns you are interested in. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I use version control with my notebook? Can I use repositories like GitHub?", "output": "You can associateGit-based repositories with your Amazon EMR Studio notebooksto save your notebooks in a version controlled environment. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the maximum file size for apps and tests?", "output": "AWS Device Farm supports files up to 4 GB. [Source: https://aws.amazon.com/device-farm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I share my snapshots with another AWS account?", "output": "Yes. Amazon DocumentDB gives you the ability tocreate snapshots of your cluster (https://docs.aws.amazon.com/documentdb/latest/developerguide/backup_restore-create_manual_cluster_snapshot.html), which you can use later to restore a cluster. You canshare a snapshot (https://docs.aws.amazon.com/documentdb/latest/developerguide/backup_restore-share_cluster_snapshots.html)with a different AWS account, and the owner of the recipient account can use your snapshot to restore a cluster that contains your data. You can even choose to make your snapshots public  that is, anybody can restore a cluster containing your (public) data. You can use this feature to share data between your various environments (production, dev/test, staging, etc.) that have different AWS accounts, as well as keep backups of all your data secure in a separate account in case your main AWS account is ever compromised. [Source: https://aws.amazon.com/documentdb/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I share my SQL queries or data models in SageMaker?", "output": "SageMaker provides Projects, a collaborative digital workspace that helps teams organize and manage their data analytics work. Think of it like a shared folder where you can store SQL queries, data models, code, and other resources in one secure location. By creating a Project, you establish a centralized environment where team members can be invited, given specific access permissions, and seamlessly work together. Within this space, you can distribute query books, which house your queries and data models, grant access to data sources like Amazon S3 and Amazon Redshift, and provide shared computing resources. The platform supports version control through Git integration, allowing your team to track changes, collaborate on code, and maintain a clear history of your SQL analytics work. This approach ensures that all team members can view, edit, and run queries while maintaining security and consistency across your SQL analytics workloads. [Source: https://aws.amazon.com/redshift/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Amazon ECS support autoscaling of applications?", "output": "Applications and microservices deployed to Amazon ECS leverage the\u00a0Application Auto Scaling\u00a0service to automatically scale based on observed metrics data. Amazon ECS\u00a0measures service utilization\u00a0based on CPU and memory resources consumed by the tasks that belong to a service and publishes CloudWatch metrics, namely, ECSServiceAverageCPUUtilization and ECSServiceAverageMemoryUtilization, with this data. Application Auto Scaling can then use these\u00a0predefined metrics\u00a0in conjunction with scaling policies to proportionally scale the number of tasks in a service. Additionally, there are use cases where a service\u2019s average CPU and memory usage alone are not reliable indicators of when and to what degree to execute a scaling action. For this, Application Auto Scaling also supports scaling a service based on a\u00a0custom metric specification\u00a0that represents a CloudWatch metric of our choosing, which may be better suited. This includes metrics that track other application aspects such as number of HTTP requests received, number of messages retrieved from a queue/topic, and number of database transactions. You can now use CloudWatch metrics or\u00a0Prometheus metrics\u00a0of your choosing.\nTo learn more, please visit:\u00a0Autoscaling Amazon ECS services based on custom CloudWatch and Prometheus metrics [Source: https://aws.amazon.com/ecs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the prerequisites to hibernate an instance?", "output": "To use hibernation, the root volume must be an encrypted EBS volume. The instance needs to be configured to receive the ACPID signal for hibernation (or use the Amazon published AMIs that are configured for hibernation). Additionally, your instance should have sufficient space available on your EBS root volume to write data from memory. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use Microsoft Office 365 with user accounts managed in AWS Managed Microsoft AD?", "output": "Yes. You can synchronize identities from AWS Managed Microsoft AD to Azure AD using Azure AD Connect and use Microsoft Active Directory Federation Services (AD FS) for Windows 2016 with AWS Managed Microsoft AD to authenticate Office 365 users. For step-by-step instructions, seeHow to Enable Your Users to Access Office 365 with AWS Microsoft Active Directory Credentials. (https://aws.amazon.com/blogs/security/how-to-enable-your-users-to-access-office-365-with-aws-microsoft-active-directory-credentials/) [Source: https://aws.amazon.com/directoryservice/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I modify my Spot Fleet request?", "output": "Yes, you can modify the target capacity of your Spot Fleet request. You may need to cancel the request and submit a new one to change other request configuration parameters. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use VoIP Push Notifications and other Push Notifications in the same iOS app?", "output": "Yes, you can have an iOS application that is registered to receive both types of push notifications. However, you will need to obtain the VoIP push notification certificate from Apple in addition to the regular push notification certificate and create a new Platform Application in Amazon SNS and choose Apple VoIP Push as the platform type. For more information, please refer to ourdocumentation. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is WorkSpaces Multi-Region Resilience?", "output": "A: Amazon WorkSpaces Multi-Region Resilience provides automated, redundant virtual desktop infrastructure in a secondary WorkSpaces Region and streamlines the process of redirecting users to the secondary Region when the primary Region is unreachable due to outages. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started with EMR Serverless?", "output": "You can use EMR Studio, AWS CLI, or APIs to submit jobs, track job status, and build your data pipelines to run on EMR Serverless. To get started with EMR Studio, sign into the AWS Management Console, navigate to Amazon EMR under the Analytics category, and select Amazon EMR Serverless. Follow the directions in theAWS Management Console,navigate to Amazon EMR under the Analytics category, and select Amazon EMR Serverless.\u00a0Follow the directions in theGetting startedguide\u00a0\u00a0to create your EMR Serverless application and submit jobs. You can refer to theInteracting with your application on the AWS CLIpage to launch your applications and submit jobs using CLI. You can also find EMR Serverless examples and sample code in ourGitHub repository. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do other users need third-party applications to view or provide feedback on files?", "output": "No, other users can view files and provide feedback directly within Amazon WorkDocs without needing the third-party application that was used to create the document for the file types that are supported for preview (Microsoft Office files (documents, spreadsheets, and presentations), PDFs, web pages, images, and text files). [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do I have to use both the Data Catalog and AWS Glue ETL to use the service?", "output": "No. While we do believe that using both the Data Catalog and ETL provides a complete ETL experience, you can use either one of them independently without using the other. [Source: https://aws.amazon.com/glue/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use tags to obtain usage and cost details for Amazon AppStream 2.0 on my AWS monthly billing report?", "output": "Yes. When you set tags to appear on your monthly Cost Allocation Report, your AWS monthly bill will also include those tags. You can then easily track costs according to your needs. To do this, first assign tags to your Amazon AppStream 2.0 resources by following the steps inTagging Your AppStream 2.0 Resources (https://docs.aws.amazon.com/appstream2/latest/developerguide/tagging-basic.html). Next, select the tag keys to include in your cost allocation report by following the steps inSetting Up Your Monthly Cost Allocation Report (https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/configurecostallocreport.html). [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is AWS Transfer Family FISMA compliant?", "output": "AWS East/West and GovCloud (US) Regions are FISMA compliant. When AWS Transfer Family is authorized for FedRAMP, it will be FISMA compliant within the respective regions. This compliance is demonstrated through FedRAMP Authorization of these two regions to FedRAMP Moderate and FedRAMP High. We demonstrate compliance through annual assessments and documenting compliance with in-scope NIST SP 800-53 controls within our System Security Plans. Templates are available on Artifact along with our customer responsibility matrix (CRM) which demonstrates at a detailed level or responsibility to meet these NIST controls as required by FedRAMP. Artifact is available through the management console accessible by an AWS account for both East/West and GovCloud. If you have any further questions on this topic, please consult theconsole (https://console.aws.amazon.com/artifact). [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What types of credentials can I use with Amazon Redshift Data API?", "output": "<p>The Data API supports both IAM credentials and using a secret key from AWS Secrets Manager. The Data API federates AWS Identity and Access Management (IAM) credentials so you can use identity providers like Okta or Azure Active Directory or database credentials stored in Secrets Manager without passing database credentials in API calls.</p> [Source: https://aws.amazon.com/redshift/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does GuardDuty Malware Protection support multi-account management?", "output": "Yes, GuardDuty has a multiple account management feature, allowing you to associate and manage multiple AWS accounts from a single administrator account. GuardDuty has multi-account management through AWS Organizations integration. This integration helps security and compliance teams ensure full coverage of GuardDuty, including Malware Protection, across all accounts in an organization. [Source: https://aws.amazon.com/guardduty/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use my own image for CloudShell?", "output": "No, using your own image is not currently supported. [Source: https://aws.amazon.com/cloudshell/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What additional security features are available with the new version of Amazon CloudSearch?", "output": "With the latest release, Amazon CloudSearch now provides IAM integration for the configuration service and all search domain services. You can control access to specific Amazon CloudSearch actions and require request authentication for all requests. Requests are authenticated using Signature Version 4 signing. [Source: https://aws.amazon.com/cloudsearch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which settings remain persistent between sessions?", "output": "You can enable persistent application and Windows settings for your users on AppStream 2.0. Your users' plugins, toolbar settings, browser favorites, application connection profiles, and other settings will be saved and applied each time they start a streaming session. Your users' settings are stored in an S3 bucket you control in your AWS account. [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is my data encrypted while being transferred and stored?", "output": "Yes. All data transferred between the source and destination is encrypted via Transport Layer Security (TLS), which replaced Secure Sockets Layer (SSL). Data is never persisted in AWS DataSync itself. The service supports usingdefault encryption for S3 buckets (https://docs.aws.amazon.com/AmazonS3/latest/dev/bucket-encryption.html),Amazon EFS file system encryption of data at rest (https://docs.aws.amazon.com/efs/latest/ug/encryption.html), andAmazon FSx encryption at rest and in transit (https://docs.aws.amazon.com/fsx/latest/WindowsGuide/encryption.html). [Source: https://aws.amazon.com/datasync/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Field-Level Encryption?", "output": "Field-Level Encryption is a feature of CloudFront that allows you to securely upload user-submitted data such as credit card numbers to your origin servers. Using this functionality, you can further encrypt sensitive data in an HTTPS form using field-specific encryption keys (which you supply) before a PUT/ POST request is forwarded to your origin. This ensures that sensitive data can only be decrypted and viewed by certain components or services in your application stack. To learn more about field-level encryption, seeField-Level Encryption (https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/field-level-encryption.html)in our documentation. [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why is FIPS 140-2 Level 3 important?", "output": "FIPS 140-2 Level 3 is a requirement of certain use cases, including document signing, payments, or operating as a public Certificate Authority for SSL certificates. [Source: https://aws.amazon.com/cloudhsm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do I need to scale the replication when my ingress throughput changes?", "output": "No, MSK Replicator automatically deploys, provisions, and scales the underlying replication infrastructure to support changes in your ingress throughput. [Source: https://aws.amazon.com/msk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How will developers access Amazon Transcribe?", "output": "The easiest way to get started is to submit a job using the console to transcribe an audio file. You can also call the service directly from the AWS Command Line Interface, or use one of the supported SDKs of your choice to integrate with your applications. Either way, you can start using Amazon Transcribe to generate automated transcripts for your audio files with just a few lines of code. [Source: https://aws.amazon.com/transcribe/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Where is AWS Migration Hub available?", "output": "AWS Migration Hub is available worldwide for tracking the progress of application migrations, regardless of where the application currently resides. Refer to the AWS Region Table for availability of Migration Hub tools for inventory collection, planning and recommendation, and modernization capabilities. [Source: https://aws.amazon.com/migration-hub/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I explore FreeRTOS without buying hardware?", "output": "You can explore FreeRTOS code and functionality on a Windows machine by downloading the libraries and samples ported to run on Windows. This is a set of files referred to as the FreeRTOS simulator for Windows (Windows Simulator). Get startedhere (https://docs.aws.amazon.com/freertos/latest/userguide/getting_started_windows.html). [Source: https://aws.amazon.com/freertos/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are lifecycle hooks?", "output": "Lifecycle hooks let you take action before an instance goes into service or before it gets terminated. This can be especially useful if you are not baking your software environment into an Amazon Machine Image (AMI). For example, launch hooks can perform software configuration on an instance to ensure that it\u2019s fully prepared to handle traffic before Amazon EC2 Auto Scaling proceeds to connect it to your load balancer. One way to do this is by connecting the launch hook to an AWS Lambda function that invokes RunCommand on the instance. Terminate hooks can be useful for collecting important data from an instance before it goes away. For example, you could use a terminate hook to preserve your fleet\u2019s log files by copying them to an Amazon S3 bucket when instances go out of service.\nVisit lifecycle hooks in our Amazon EC2 Auto Scaling User Guide for more information. [Source: https://aws.amazon.com/ec2/autoscaling/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I know when a volume was created from an FSR-enabled snapshot?", "output": "When using FSR, a new EBS-specific attribute (fastRestored) is added in the DescribeVolumes API to denote the status at create time. When a volume is created from an FSR-enabled snapshot without sufficient volume-create credits, the create will succeed but the volume will not be initialized. [Source: https://aws.amazon.com/ebs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens if a scaling activity causes me to reach my Amazon EC2 limit of instances?", "output": "Amazon EC2 Auto Scaling cannot scale past the Amazon EC2 limit of instances that you can run. If you need more Amazon EC2 instances, complete the Amazon EC2 instance request form. [Source: https://aws.amazon.com/ec2/autoscaling/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Are Amazon WorkMail groups billable/eligible for pricing/charged?", "output": "Amazon WorkMail will not charge for Groups separately and customers can create multiple groups. Only Enabled Users are charged. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do I have to modify my client app to use SNS Mobile Push?", "output": "SNS does not require you to modify your client app. Baidu Cloud Push requires Baidu-specific components to be added to your client code in order to work properly, whether or not you choose to use SNS. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Amazon CloudFront enable origin redundancy?", "output": "For every origin that you add to a CloudFront distribution, you canassign a backup origin (https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/high_availability_origin_failover.html)that can be used to automatically serve your traffic if the primary origin is unavailable. You can choose a combination of HTTP 4xx/5xx status codes that, when returned from the primary origin, trigger the failover to the backup origin. The two origins can be any combination of AWS and non-AWS origins. [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use managed workflows to dynamically route files to user-specific Amazon S3 folders?", "output": "Yes. You can utilize username as a variable in workflows copy steps, enabling you to dynamically route files to user-specific folders in Amazon S3. This removes the need to hardcode destination folder location when copying files and automates creation of user-specific folders in Amazon S3, allowing you to scale your file automation workflows. Read thedocumentation (https://docs.aws.amazon.com/transfer/latest/userguide/transfer-workflows.html)to learn more. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If I previously signed an offline BAA with AWS, can I use AWS Artifact Agreements to designate additional accounts as HIPAA Accounts under that offline BAA?", "output": "No. You can use AWS Artifact Agreements to accept an online BAA for a single account or for all accounts within your organization in AWS Organizations. These will be subject to the terms of the applicable online BAA, however,notyour offline BAA.If you want to designate additional HIPAA Accounts under your offline BAA, you can do so by following the process described in your offline BAA (e.g., sending an email to aws-hipaa@amazon.com). Once confirmed by AWS, the Artifact Agreements interface will change for the newly designated account to reflect that it has been designated as a HIPAA Account under your offline BAA. [Source: https://aws.amazon.com/artifact/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Mountpoint for Amazon S3?", "output": "Mountpoint for Amazon S3 is an open source file client that you can use to mount an S3 bucket on your compute instance and access it as a local file system. Mountpoint for Amazon S3 translates local file system operations to REST API calls on objects stored in Amazon S3. With Mountpoint for Amazon S3, you can achieve high single-instance throughput to finish jobs faster. Mountpoint for Amazon S3 is backed by AWS Support. Customers with access to AWS Enterprise Support get 24x7 technical support from Amazon support engineers and architectural guidance delivered in the context of their use cases. Mountpoint for Amazon S3 works with the Linux operating system and AWS compute services such as Amazon Elastic Compute Cloud (EC2). Learn more on theMountpoint for Amazon S3 pageor theuser guide. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens if my Spot Fleet request tries to launch Spot instances but exceeds my regional Spot request limit?", "output": "If your Spot Fleet request exceeds your regional Spot instance request limit, individual Spot instance requests will fail with a \"Spot request limit exceeded request status\". Your Spot Fleet request\u2019s history will show any Spot request limit errors that the Fleet request received. Visit theMonitoring Your Spot Fleetsection of the Amazon EC2 User Guide to learn how to describe your Spot Fleet request's history. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I package and deploy an AWS Lambda function in Go?", "output": "Upload your Go executable artifact as a ZIP file through the AWS CLI or Lambda console and select the go1.x runtime. With Lambda, you can use Go's native tools to build and package your code. For more details, read our documentation.\u00a0 [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When I download a file, are all comments and replies preserved and included?", "output": "When you download a file, all public comments and their replies are included and they maintain their formatting. Comments marked as private are not downloaded. Documents with private comments are marked with an annotation that there are private comments which are only viewable via the WorkDocs web or mobile application. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Amazon FSx for Windows File Server?", "output": "Amazon FSx for Windows File Server provides fully managed, highly reliable, and scalable file storage that is accessible over the industry-standard Service Message Block (SMB) protocol. It is built on Windows Server, delivering a wide range of administrative features such as user quotas, end-user file restore, and Microsoft Active Directory (AD) integration.To support a wide spectrum of workloads, Amazon FSx provides high levels of throughput and IOPS, and consistent sub-millisecond latencies.Amazon FSx is accessible from Windows, Linux, and MacOS compute instances and devices. Thousands of compute instances and devices can access a file system concurrently.Amazon FSx File Gateway (https://aws.amazon.com/storagegateway/file/fsx/)provides low-latency, on-premises access to fully managed file shares in the cloud. [Source: https://aws.amazon.com/fsx/windows/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I get started?", "output": "Contact us (mailto:aws-freertos-emp@amazon.com)to get started. [Source: https://aws.amazon.com/freertos/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I leverage three AZ deployment for my VPC domain?", "output": "The number of AZs your domain is deployed to corresponds to the number of subnets you have configured for your VPC domain. You need to configure at least three subnets in your VPC domain to enable three AZ deployment. For more details on configuring VPC, refer ourdocumentation (https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-managedomains.html). [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I use AWS DataSync to migrate data to AWS?", "output": "You can use AWS DataSync to migrate data located on premises, at the edge, or in other clouds to Amazon S3, Amazon EFS, Amazon FSx for Windows File Server, Amazon FSx for Lustre, Amazon FSx for OpenZFS, and Amazon FSx for NetApp ONTAP. Configure DataSync to make an initial copy of your entire dataset, and schedule subsequent incremental transfers of changing data until the final cut-over from on-premises to AWS. DataSync includes encryption and integrity validation to help make sure your data arrives securely, intact, and ready to use. To minimize impact on workloads that rely on your network connection, you can schedule your migration to run during off-hours, or limit the amount of network bandwidth that DataSync uses by configuring the built-in bandwidth throttle.DataSync preserves metadata between storage systems that have similar metadata structures, enabling a smooth transition of end users and applications to using your target AWS Storage service.Read the storage blog, \"Migrating storage with AWS DataSync (https://aws.amazon.com/blogs/storage/migrating-storage-with-aws-datasync/),\" to learn more about migration best practices and tips. [Source: https://aws.amazon.com/datasync/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How will I be charged for using AWS Lambda functions?", "output": "AWS Lambda is priced on a pay-per-use basis. Please see the AWS Lambda pricing page for details. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I control what permissions my users get when they use IAM Identity Center to access their accounts?", "output": "When granting access to your users, you can limit the users permissions by picking a permission set. Permission sets are a collection of permissions that you can create in IAM Identity Center, modelling them based on AWS managed policies for job functions or any AWS managed policies. AWS managed policies for job functions are designed to closely align to common job functions in the IT industry. If required, you can also fully customize the permission set to meet your security requirements. IAM Identity Center applies these permissions to the selected accounts automatically. As you change the permission sets, IAM Identity Center enables you to apply the changes to the relevant accounts easily. When your users access the accounts through the AWS access portal, these permissions restrict what they can do within those accounts. You can also grant multiple permission sets to your users. When they access the account through the user portal, they can pick which permission set they want to assume for that session. [Source: https://aws.amazon.com/iam/identity-center/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I store photos from my Camera Roll in Amazon WorkDocs when using an iOS device?", "output": "To store photos from your Camera Roll, open your Photos app, select your photos, tap the share button, and select WorkDocs. To learn more, please see the documentation as follows: [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I set my subscription to auto-renew?", "output": "Providers have the option to enable auto-renewal on individual offers. As a subscriber, you can choose to set your subscription to auto-renew on the offers that have the auto-renewal functionality enabled. Auto-renewal is available for public and private offers that do not have payment schedules. [Source: https://aws.amazon.com/data-exchange/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I debug a query that continues to fail in each iteration?", "output": "In the event of a processing failure, you can utilize the same tools they currently do when debugging Hadoop Jobs. Including the Amazon EMR web console, which helps identify and access error logs. More details on debugging an EMR job can be foundhere. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use individual AWS services without using SageMaker?", "output": "Yes. You can continue to independently use individual AWS services such as SageMaker AI (formerly SageMaker), Amazon EMR for big data processing, AWS Glue, and Amazon Redshift for data warehousing based on your specific business requirements. There is no impact to how you currently use your individual services today.SageMaker offers an additional benefit by providing a unified, user-friendly interface that enables access to these services. This approach helps you more effectively innovate with your data, increase collaboration across teams, and enhance overall productivity. [Source: https://aws.amazon.com/sagemaker/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I try Amazon DocumentDB?", "output": "To try Amazon DocumentDB, please see theGetting Started (https://aws.amazon.com/documentdb/getting-started/)guide. [Source: https://aws.amazon.com/documentdb/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How quickly are logs available?", "output": "Logs, alarms, error rates and other metrics are stored in Amazon CloudWatch and are available near real time. [Source: https://aws.amazon.com/api-gateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When using an IMAP client application, will I be able to see all my email folders?", "output": "Yes, any folder which contains email will be visible and accessible using an IMAP client application. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is in-memory caching and how does it help my applications?", "output": "The in-memory caching provided by ElastiCache can be used to significantly improve latency and throughput for many read-heavy application workloads (such as social networking, gaming, media sharing, and Q&A portals) or compute-intensive workloads (such as a recommendation engine). In-memory caching improves application performance by storing critical pieces of data in memory for low-latency access. Cached information can include the results of I/O-intensive database queries or the results of computationally intensive calculations. [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use the lookup-events CLI command even if I dont have a trail configured?", "output": "Yes, you can visit theCloudTrail console (https://console.aws.amazon.com/cloudtrail/)or use the CloudTrail API/CLI and begin viewing the past 90 days of account activity. [Source: https://aws.amazon.com/cloudtrail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What types of Windows Push Notifications does Amazon SNS support?", "output": "SNS supports all types of push notifications types offered by Microsoft WNS and MPNS, including toast, tile, badge and raw notifications. Use the TYPE message attribute to specify which notification type you wish to use. When you use default payloads to send the same message to all mobile platforms, SNS will select toast notifications by default for Windows platforms. It is required to specify a notification type for Windows platforms when you use platform-specific payloads. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can an Amazon Lex bot respond using Alexa\u2019s voice?", "output": "Currently we do not support the Alexa voice for Amazon Lex responses. However, there are 7 other voices from which to choose. [Source: https://aws.amazon.com/lex/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When will Amazon Rekognition send me a notification?", "output": "Amazon Rekognition starts processing the video stream post motion detection. You can configure the duration for processing this video stream (up to 120 seconds per event). As soon as Amazon Rekognition detects the object of interest in the video stream, Rekognition will send you a notification. This notification includes the type of object detected, the bounding box, a zoomed in image of the object detected, and a time stamp. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the benefit if Spot hibernates my instance on interruption?", "output": "With hibernate, Spot instances will pause and resume around any interruptions so your workloads can pick up from exactly where they left off. You can use hibernation when your instance(s) need to retain instance state across shutdown-startup cycles, i.e. when your applications running on Spot depend on contextual, business, or session data stored in RAM. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon DocumentDB support ACID transactions?", "output": "Yes. With the launch of support for MongoDB 4.0 compatibility, Amazon DocumentDB supports the ability to performatomicity, consistency, isolation, durability (ACID) transactions (https://docs.aws.amazon.com/athena/latest/ug/acid-transactions.html)across multiple documents, statements, collections, and databases. [Source: https://aws.amazon.com/documentdb/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens if I exceed the AWS Support escalations to the FreeRTOS engineering team?", "output": "You can escalate four (for single product subscriptions) and six (for multiple product subscriptions) AWS Support cases per year at no additional charge. After that, you may incur charges (evaluated case by case) in addition to the AWS Support fees. In case of charges, AWS will request your confirmation to proceed and charge at a rate of $3,100 per Software Development Engineer per week (without proration). [Source: https://aws.amazon.com/freertos/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Are there any restrictions on what data can be made available on AWS Data Exchange?", "output": "Yes.Publishing guidelinesfor listing products on AWS Data Exchange andTerms and Conditions for AWS Marketplace Providersrestrict certain categories of data. Unless a provider is enrolled in the Extended Provider Program, data products listed on AWS Data Exchange may not include information that can be used to identify any person, except information that is already legally available to the public, such as newspaper articles, open court records, public company filings, or public online profiles. For more information about the Extended Provider Program, pleasecontact AWS Support. [Source: https://aws.amazon.com/data-exchange/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the cost implications of moving to a supported Microsoft Operating System or SQL Server version?", "output": "License Included: There is no additional licensing costs to move to a newer version of the software when using Amazon's License Included options, for example: [Source: https://aws.amazon.com/windows/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can a user select the AWS region for a specific Amazon Chime meeting?", "output": "No. Amazon Chime selects a region for each meeting, from the meeting regions selected by the host\u2019s organization, to minimize latency and optimize the meeting experience for the participants. [Source: https://aws.amazon.com/chime/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Are Amazon EBS volume and snapshot ID lengths changing in 2018?", "output": "Yes, please visit the EC2 FAQs page for more details. [Source: https://aws.amazon.com/ebs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I view and manage my S3 Access Grants permission grants?", "output": "You can use either the S3 Access Grants console experience in the AWS Management Console or SDK and CLI APIs for you to view and manage your S3 Access Grants permissions. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a capacity mode?", "output": "The capacity mode of Kinesis Data Streams determines how capacity is managed and usage is charged for a data stream. You can choose between provisioned and on-demand modes. In provisioned mode, you specify the number of shards for the data stream. The total capacity of a data stream is the sum of the capacities of its shards. You can increase or decrease the number of shards in a data stream as needed, and you pay for the number of shards at an hourly rate. In on-demand mode, AWS manages the shards to provide the necessary throughput. You pay only for the actual throughput used, and Kinesis Data Streams automatically accommodates your workload throughput needs as they ramp up or down. All Kinesis Data Streams write and read APIs, along with optional features such as Extended Retention and Enhanced Fan-Out, are supported in both capacity modes. [Source: https://aws.amazon.com/kinesis/data-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I manage metrics to be included in my CloudWatch Metric Stream?", "output": "Yes. It is possible to choose to send all metrics by default, or create filter rules to include and exclude groups of metrics defined by namespace, e.g. AWS/EC2. Metric Streams automatically detects new metrics matching filter rules and includes metric updates in the stream. When resources are terminated, Metric Streams will automatically stop sending updates for the inactive metrics. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will the cluster have any down time when logging is turned on or off?", "output": "No. There will not be any down-time. Every time the log status is updated, we will deploy a new cluster in the background and replace the existing cluster with the new one. This process will not cause any down time. However, since a new cluster is deployed the update to the log status will not be instantaneous. [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I test an Amazon Lex bot?", "output": "You can test your Amazon Lex bot via the test window on the console. Any business logic implemented in AWS Lambda can be tested via this console as well. All supported browsers allow for testing text with your Amazon Lex bot; voice can be tested from a Chrome browser. [Source: https://aws.amazon.com/lex/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I transition VMware backups to a cold storage tier?", "output": "Yes, based on your organizational needs, you can configure lifecycle policies in AWS Backup to automatically transition your VMware backups from warm storage to low-cost cold storage. Backups that are transitioned to cold storage have a minimum 90 days of storage, and backups deleted before 90 days incur a pro-rated charge equal to the storage charge for the remaining days. [Source: https://aws.amazon.com/backup/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What metadata is preserved when either copying data between an NFS share or Amazon EFS file system and Amazon FSx for Lustre, or between two Amazon FSx for Lustre file systems?", "output": "AWS DataSync copies file and folder timestamps and POSIX permissions, including user ID, group ID, and permissions. You can learn more and see the complete list of copied metadata in ourdocumentation (https://docs.aws.amazon.com/datasync/latest/userguide/metadata-copied.html). [Source: https://aws.amazon.com/datasync/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What types of media analysis segments can Amazon Rekognition Video detect?", "output": "Amazon Rekognition Video can detect the following types of segments or entities for media analysis: [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does AWS Backup for S3 work?", "output": "With AWS Backup, you can define a central backup policy to manage backup and restore for your application across AWS services for compute, storage, and database services.Once you define your backup policy and assign S3 resources, AWS Backup automates the creation of S3 backups, and stores those backups in an encrypted storage vault that you designate. Create continuous point-in-time backups or periodic backups of S3 buckets, including object data, object tags, access control lists (ACLs), and user-defined metadata. The first backup is a full snapshot, while subsequent backups are incremental. If there is a data disruption event, choose a backup from the backup vault and restore an S3 bucket (or individual S3 objects) to a new or existing S3 bucket. The centralized policies in AWS Backup also help you define access controls and automate backup access management across all your accounts within your AWS Organizations. [Source: https://aws.amazon.com/backup/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Lake Formation simplify external or business-to-business data sharing?", "output": "Lake Formation integrates with AWS Data Exchange so you can share data with external businesses without moving or copying the data. [Source: https://aws.amazon.com/lake-formation/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can Amazon Personalize help me to recommend actions for my users?", "output": "With the Amazon Personalize Next-Best-Action (aws-next-best-action) recipe, you can determine the next best action to recommend to each individual user based on their preferences, interests and history in real-time. You can recommend actions such as an add-on service, joining a customer loyalty program, subscribing to a newsletter, etc. that encourage conversion. This allows you to improve each users experience by nudging them to take certain actions across their user journey that will help in promoting long-term brand engagement. It also enables you to improvereturn on marketing investment by recommending actions that have a high degree of relevance to the user, thereby resulting in increased revenue and loyalty.Learn more. (https://aws.amazon.com/blogs/machine-learning/build-brand-loyalty-by-recommending-actions-to-your-users-with-amazon-personalize-next-best-action/) [Source: https://aws.amazon.com/personalize/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "I have numerous executions running at any time, but a handful of them often fail or stall. How can I detect and troubleshoot these problematic executions?", "output": "Amazon SWF lets you search for executions through its Management Console and visibility APIs. You can search by various criteria, including the time intervals during which executions started or completed, current state (i.e. open or closed), and standard failure modes (e.g. timed out, terminated). To group workflow executions together, you can use upto 5 tags to associate custom text with workflow executions when you start them. In the AWS Management Console, you can use tags when searching workflow executions.To find executions that may be stalled, you can start with a time-based search to hone in on executions that are running longer than expected. Next, you can inspect them to see task level details and determine if certain tasks have been running too long or have failed, or whether the decider has simply not initiated tasks. This can help you pinpoint the problem at a task-level. [Source: https://aws.amazon.com/swf/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What use cases does Amazon FSx for Lustre support?", "output": "Use Amazon FSx for Lustre for workloads where speed matters, such as machine learning, high performance computing (HPC) , video processing, financial modeling, genome sequencing, and electronic design automation (EDA). [Source: https://aws.amazon.com/fsx/lustre/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I create a new document, worksheet, or presentation?", "output": "Choose the New menu option in the top task bar. In the dialog box, choose the file type you want to create and type the file name. Choose Save to save the file in WorkDocs, then choose Edit to open and edit the file. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I connect to my read replicas?", "output": "You can connect to a read replica just as you would connect to a primary cache node. If you have multiple read replicas, it is up to your application to determine how read traffic will be distributed amongst them. Here are more details:Valkey or Redis (cluster mode disabled) OSS clusters, use the individual node endpoints for read operations. (In the API/CLI these are referred to as read endpoints.)Valkey or RedisOSS (cluster mode enabled) clusters, use the cluster's configuration endpoint for all operations. You can still read from individual node endpoints. (In the API and CLI these are referred to as read endpoints.) [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the main features of FreeRTOS EMP?", "output": "FeatureDescriptionWhy is it important?Feature stabilityGet FreeRTOS libraries that maintain the same set of features for yearsSave upgrade costs by using a stable FreeRTOS codebase for your product lifecycleAPI stabilityGet FreeRTOS libraries that have stable APIs for yearsSave upgrade costs by using a stable FreeRTOS codebase for your product lifecycleCritical fixesReceive security patches and critical bug* fixes on your chosen FreeRTOS librariesSecurity patches help keep your IoT devices secure for the product lifecycleNotification of patchesReceive timely notification of upcoming patchesTimely awareness of security patches helps you proactively plan the deployment of patchesFlexible subscription planExtend maintenance by a year or longerContinue to renew your annual subscription to keep the same version for the entire device lifecycle, or for a shorter period to buy time before upgrading to the latest FreeRTOS version* A critical bug is a defect determined by AWS to impact the functionality of the affected library and has no reasonable workaround.AWS will provide technical support to FreeRTOS EMP customers viaAWS Support (https://aws.amazon.com/premiumsupport/). AWS Support is not included in FreeRTOS EMP subscriptions. You can track issues (for example, issues related to AWS accounts, billing, or bugs) or get access to technical experts (on issues such as patch integration) based on your AWS Supportplan (https://aws.amazon.com/premiumsupport/plans/). [Source: https://aws.amazon.com/freertos/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I share a file with others?", "output": "Users can share files inside or outside their organization by sharing a link or inviting anyone using a valid email address. They can create a shareable link for any file on Amazon WorkDocs by clicking \u201cShare a link\u201d. When sharing a link, users can make their link public to anyone or restrict access to only users on their Amazon WorkDocs site. They can also specify an expiration date, set a four-digit password for access, and disable a shared link at any time. Administrators control if public links can be created, can limit which users create links, and can disable all existing public links at any time. This makes it easy to embed links to files in documents and web pages. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the various storage options available on R5b instances?", "output": "R5b instances are EBS-optimized by default and offer up to 60,000 Mbps of dedicated EBS bandwidth and 260K IOPS for both encrypted and unencrypted EBS volumes. R5b instances only support Non-Volatile Memory Express (NVMe) interface to access EBS storage volumes. R5b is supported by all volume types, with the exception of io2 volumes. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is AWS Auto Scaling?", "output": "AWS Auto Scaling is a new AWS service that helps you optimize the performance of your applications while lowering infrastructure costs by easily and safely scaling multiple AWS resources. It simplifies the scaling experience by allowing you to scale collections of related resources that support your application with just a few clicks. AWS Auto Scaling helps you configure consistent and congruent scaling policies across the full infrastructure stack backing your application. AWS Auto Scaling will automatically scale resources as needed to align to your selected scaling strategy, so you maintain performance and pay only for the resources you actually need. [Source: https://aws.amazon.com/autoscaling/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are WebSockets?", "output": "WebSocket is a real-time communication protocol that provides bidirectional communication between a client and a server over a long-held TCP connection. By using a persistent open connection, the client and the server can send real-time data to each other without the client having to frequently reinitiate connections checking for new data to exchange. WebSocket connections are often used in chat applications, collaboration platforms, multiplayer games, and financial trading platforms. Refer to our documentation to learn more aboutusing the WebSocket protocol (https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-working-with.websockets.html)with Amazon CloudFront. [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use IPv6 addresses for my Amazon WorkSpaces bundles?", "output": "A: Yes. You can use IPv6 addresses for Value, Standard, Performance, Power, PowerPro,\u00a0GeneralPurpose, GraphicsPro, Graphics.g4dn, and GraphicsPro.g4dn bundles. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are Amazon EC2 A1 instances?", "output": "Amazon EC2 A1 instances are general purpose instances powered by the first-generation AWS Graviton Processors that are custom designed by AWS. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Where are the edge network locations used by Amazon CloudFront located?", "output": "Amazon CloudFront uses a global network of edge locations and regional edge caches for content delivery. You can see a full list of Amazon CloudFront locationshere (https://aws.amazon.com/cloudfront/details/). [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are Accelerated Computing instances?", "output": "The Accelerated Computing instance category includes instance families that\u00a0use hardware accelerators, or co-processors, to perform some functions, such as floating-point number calculation and graphics processing, more efficiently than is possible in software running on CPUs. Amazon EC2 provides a broad choice of accelerators including GPUs, purpose built AI chips AWS Trainium and AWS Inferentia, FPGAs and more. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What does \"claim your domain\" mean?", "output": "With Amazon Chime, you can ensure that all users that sign up to use Amazon Chime with an email address in your corporate domain(s) are automatically added to your Amazon Chime account. This makes it easier for you to keep track of and manage your Amazon Chime users and their subscriptions, and allows you to pay for the service centrally. [Source: https://aws.amazon.com/chime/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I set up Amazon S3 Event Notifications to send notifications when S3 Lifecycle transitions or expires objects?", "output": "Yes, you can set upAmazon S3 Event Notificationsto notify you when S3 Lifecycle transitions or expires objects. For example, you can send S3 Event Notifications to an Amazon SNS topic, Amazon SQS queue, or AWS Lambda function when S3 Lifecycle moves objects to a different S3 storage class or expires objects. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the difference between Single-AZ and Multi-AZ file systems?", "output": "Single-AZ file systems are composed of a single Windows file server instance and a set of storage volumes within a single Availability Zone (AZ). With Single-AZ file systems, data is automatically replicated to protect it from the failure of a single component in most cases. Amazon FSx continuously monitors for hardware failures, and automatically recovers from failure events by replacing the failed infrastructure component.Multi-AZ file systems are composed of a high-availability cluster of Windows file servers spread across two AZs (a preferred AZ and a standby AZ), leveraging Windows Server Failover Clustering (WSFC) technology and a set of storage volumes on each of the two AZs. Data is replicated synchronously within each individual AZ and between the two AZs. Relative to Single-AZ deployment, Multi-AZ deployments provide enhanced durability by further replicating data across AZs, and enhanced availability during planned system maintenance and unplanned service disruption by failing over automatically to the standby AZ. This allows you to continue accessing your data, and helps to protect your data against instance failure and AZ disruption. [Source: https://aws.amazon.com/fsx/windows/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What kind of prediction tasks can I do with Neptune ML?", "output": "Neptune ML provides node classification, multi-class classification, node regression, edge classification, single-class classification, edge regression, and link (edge) prediction. For more details, visit theNeptune User Guide (https://docs.aws.amazon.com/neptune/latest/userguide/machine-learning.html). [Source: https://aws.amazon.com/neptune/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will all Microsoft Exchange Server objects synchronize to the Amazon WorkMail global address book?", "output": "Amazon WorkMail will synchronize users, groups, resources, and contacts that reside in Microsoft Exchange Server. Amazon WorkMail will not synchronize dynamic groups or address lists. When your Microsoft Exchange global address book contains these objects, they won't be available in Amazon WorkMail. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I reserve a transcoder for my exclusive use?", "output": "Amazon Elastic Transcoder provides a shared transcoding service and does not enable a transcoder to be reserved or allocated to an individual customer. [Source: https://aws.amazon.com/elastictranscoder/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Who owns Polly recordings?", "output": "As between you and AWS, your Polly output belongs to you. If you input text into Polly that belongs to a third party, we require that you have the rights to do so. For more information, please see ourCustomer Agreement (https://aws.amazon.com/agreement/)and how it handles Your Content [Source: https://aws.amazon.com/polly/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does the free tier apply to customers subscribed to CloudFront Security Savings bundle?", "output": "Customers subscribed to CloudFront Security Savings bundle will also benefit from the free tier. If you feel the need to lower your commitment to the CloudFront Security Savings bundle in light of the free tier, please reach out to customer service and we will evaluate your request for changes. We will provide more details about this in the coming days. Please stay tuned.For additional questions, please refer tohttps://aws.amazon.com/free/free-tier-faqs/ (https://aws.amazon.com/free/free-tier-faqs/). [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I claim my domain?", "output": "You can claim your domain by following the steps laid out inClaim a Domain. [Source: https://aws.amazon.com/chime/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use service managed option for password authentication?", "output": "No. Storing passwords within the service for authentication is currently not supported. If you need password authentication, use Active Directory by selecting a directory in AWS Directory Service, or follow the architecture described in this blog onEnabling Password Authentication using Secrets Manager (https://aws.amazon.com/blogs/storage/enable-password-authentication-for-aws-transfer-family-using-aws-secrets-manager-updated/). [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What Amazon CloudFront events can be used to trigger my functions?", "output": "Your functions will automatically trigger in response to the following Amazon CloudFront events:\n\nViewer Request - This event occurs when an end-user or a device on the Internet makes an HTTP(S) request to CloudFront, and the request arrives at the edge location closest to that user.\nViewer Response - This event occurs when the CloudFront server at the edge is ready to respond to the end user or the device that made the request.\nOrigin Request - This event occurs when the CloudFront edge server does not already have the requested object in its cache, and the viewer request is ready to be sent to your backend origin web server (e.g. Amazon EC2, or Application Load Balancer, or Amazon S3).\nOrigin Response - This event occurs when the CloudFront server at the edge receives a response from your backend origin web server.\n [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which software authenticators does the AWS Console Mobile App support for MFA?", "output": "The AWS Console Mobile App supports software authenticators such as Google Authenticator, Microsoft Authenticator, and LastPass Authenticator. Clickhere (https://aws.amazon.com/iam/features/mfa/)for a full list of supported software authenticators. [Source: https://aws.amazon.com/console/faq-console/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What types of files can I preview or comment on with Amazon WorkDocs?", "output": "You can preview and comment on Microsoft Office files (documents, spreadsheets, and presentations), PDFs, web pages, images, and text files directly in the Amazon WorkDocs web client. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started with AWS Glue Flex flexible execution class jobs?", "output": "The flexible execution class is available for AWS Glue Spark jobs. To use the flexible execution class, you change the default setting of the execution class parameter from STANDARD to FLEX. You can do this through AWS Glue Studio or a command line interface (CLI). Read theAWS Glue Documentationfor more information. [Source: https://aws.amazon.com/glue/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Amazon Aurora PostgreSQL Limitless Database?", "output": "Aurora PostgreSQL Limitless Database provides automated horizontal scaling to process millions of write transactions per second and manages petabytes of data while maintaining thesimplicity of operating inside a single database. You can focus on building high-scale applications without having to build and maintain complex solutions for scaling your data across multiple database instances to support your workloads. Aurora PostgreSQL Limitless Database scales based on your application workload and you pay only for what your application consumes. To learn more, visit theAurora PostgreSQL Limitless Database User Guide (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/limitless.html). [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When does each monthly billing cycle begin?", "output": "The billing system follows Coordinated Universal Time (UTC). The calendar month begins at midnight UTC on the first day of every month. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use SDKs to build bots?", "output": "You can build bots using SDKs: Java, JavaScript, Python, CLI, .NET, Ruby on Rails, PHP, Go, and CPP. [Source: https://aws.amazon.com/lex/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is all web traffic served over HTTPS?", "output": "AWS Amplify web hosting generates a free HTTPS on all sites and will enable it automatically on all Route53-managed domains. The SSL certificate is generated by Amazon Certificate Manager and has wildcard domain support. ACM handles the complexity of creating and managing public SSL/TLS certificates for your AWS based websites and applications. With the wildcard option, the main domain and all subdomains can be covered by a single certificate. [Source: https://aws.amazon.com/amplify/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why did AWS begin using data plane events for Data API instead of CloudTrail management events?", "output": "AWS CloudTrail (https://aws.amazon.com/pm/cloudtrail/)captures AWS API activity as management events or data events. CloudTrail management events (also known as \"control plane operations\") show management operations that are performed on resources in your AWS account, such as create, update, and delete a resource. CloudTrail data events (also known as \"data plane operations\") show the resource operations performed on or within a resource in your AWS account.Data API performs data plane operations since it performs queries on data within your Aurora database. Therefore, we will be logging Data API activity as data events as this is the correct categorization of the events. Charges will only be incurred for CloudTrail data events if you enable data events logging. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If I attach an empty SCP to an AWS account, does that mean that I allow all AWS service actions in that AWS account?", "output": "No. SCPs behave the same way as IAM policies: an empty IAM policy is equivalent to a default DENY. Attaching an empty SCP to an account is equivalent to attaching a policy that explicitly denies all actions. [Source: https://aws.amazon.com/organizations/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a nested application?", "output": "A nested serverless application is a component that is deployed as part of another serverless application. As serverless architectures grow, common patterns emerge in which the same components are defined in multiple application templates. You can now separate out common patterns as dedicated applications and then nest them as part of new or existing application templates. [Source: https://aws.amazon.com/serverless/serverlessrepo/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I upgrade my plan?", "output": "Yes. You can take a snapshot of your instance, and use the API to launch a new, larger size instance. You can launch new instances from snapshot using the Lightsail console or the CLI. Find instructions on how to use the CLI here. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What capabilities does Amazon S3 provide to protect my data against accidental or malicious deletes?", "output": "S3 Object Versioning, S3 Replication, and S3 Object Lock are all optional features that you can use to add additional data protection, beyond the durability that S3 automatically provides. In addition, you can use a backup application to back up all or part of the data in your S3 buckets. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I test a Managed Rule?", "output": "AWS WAF allows you to configure a count action for a Managed Rule, which counts the number of web requests that are matched by the rules inside the Managed Rule. You can look at the number of counted web requests to estimate how many of your web requests would be blocked if you enable the Managed Rule. [Source: https://aws.amazon.com/waf/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use Hadoop 1?", "output": "No, Impala requires Hadoop 2, and will not run on a cluster with an AMI running Hadoop 1.x. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can Amazon Rekognition detect protective equipment locations and return bounding boxes?", "output": "Yes, Amazon Rekognition \u201cDetectProtectiveEquipment\u201d API can detect the location of protective equipment such as face covers, hand covers, and head covers on persons in images. You get the coordinates of the bounding box rectangle for each item of protective equipment detected, as well as a confidence score. For more details on the API response, please refer todocumentation. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens if a function receives invocations above the configured level of Provisioned Concurrency?", "output": "If the concurrency of a function reaches the configured level, subsequent invocations of the function have the latency and scale characteristics of regular Lambda functions. You can restrict your function to only scale up to the configured level. Doing so prevents the function from exceeding the configured level of Provisioned Concurrency. This is a mechanism to prevent undesired variability in your application when demand exceeds the anticipated amount. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the key concepts of Apache Kafka?", "output": "Apache Kafka stores records in topics. Data producers write records to topics and consumers read records from topics. Each record in Apache Kafka consists of a key, a value, a timestamp, and sometimes header metadata. Apache Kafka partitions topics and replicates these partitions across multiple nodes called brokers. Apache Kafka runs as a cluster on one or more brokers, and brokers are located in multiple AWS Availability Zones to create a highly available cluster. Apache Kafka relies onApache ZooKeeper (https://zookeeper.apache.org/)orApache Kafka Raft (https://docs.aws.amazon.com/msk/latest/developerguide/kraft-intro.html)(KRaft) to maintain cluster metadata. [Source: https://aws.amazon.com/msk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I know when AWS Secrets Manager rotates a database credential?", "output": "You can configure Amazon CloudWatch Events to receive a notification when AWS Secrets Manager rotates a secret. You can also see when Secrets Manager last rotated a secret using the Secrets Manager console or APIs. [Source: https://aws.amazon.com/secrets-manager/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon AppStream 2.0 offer GPU-accelerated instances?", "output": "Yes. Amazon AppStream 2.0 offers Graphics Design, Graphics Pro, Graphics G4Graphics and G5 instance families.Graphics Design instances are ideal for delivering applications such as Adobe Premiere Pro, Autodesk Revit, and Siemens NX that rely on hardware acceleration of DirectX, OpenGL, or OpenCL. Powered by AMD FirePro S7150x2 Server GPUs and equipped with AMD Multiuser GPU technology, instances start from 2 vCPU, 7.5 GiB system memory, and 1 GiB graphics memory, to 16 vCPUs, 61 GiB system memory, and 8 GiB graphics memory.Graphics G5 instances are based on the EC2 G5 family. Amazon EC2 G5 instances feature NVIDIA A10G Tensor Core GPUs and 2nd generation AMD EPYC processors, delivering up to 3x higher performance for graphics-intensive applications and machine learning inference, and up to 3.3x higher performance for training simple to moderately complex machine learning models compared to Amazon EC2 G4dn instances. AppStream 2.0 offers seven different instance sizes for Graphics G5, ranging from xlarge with 4 vCPUs and 16 GB of system memory to 24xlarge with 96 vCPUs and 384 GB of system memory.Graphics g4dn instances are based on theEC2 G4 family (https://aws.amazon.com/ec2/instance-types/g4/). Amazon EC2 g4dn instances deliver the industrys most cost-effective and versatile GPU instance for running graphics-intensive applications on AWS. G4dn instances provide the latest generation NVIDIA T4 GPUs, AWS custom Intel Cascade Lake CUs, up to 100 Gbps of networking throughput, and up to 1.8 TB of local NVMe storage. These instances are ideal for streaming graphics intensive applications that rely on NVIDIA GPU libraries such as CUDA using AppStream 2.0. AppStream 2.0 offers six different g4dn instance sizes, ranging from 4 vCPUs and 16 GiB of memory to 64 vCPUs and 256 GiB of memoryThe Graphics Pro instance family offers three different instance types to support the most demanding graphics applications. Powered by NVIDIA Tesla M60 GPUs with 2048 parallel processing cores, there are three Graphics Pro instances types starting from 16 vCPUs, 122 GiB system memory, and 8 GiB graphics memory, to 64 vCPUs, 488 GiB system memory, and 32 GiB graphics memory. These instance types are ideal for graphic workloads that need a massive amount of parallel processing power for 3D rendering, visualization, and video encoding, including applications such as Petrel from Schlumberger Software, Landmark's DecisionSpace, or MotionDSP's Ikena. For more information on available instance types and pricing, seeAmazon AppStream 2.0 pricing (https://aws.amazon.com/appstream2/pricing/). [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What type of data reduction does AWS Storage Gateway perform?", "output": "Volume and Tape Gateways perform compression of data in-transit and at-rest which can reduce both data transfer and storage charges. The AWS Storage Gateway only uploads data that has changed, minimizing the amount of data sent over the Internet. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I designate my account as a HIPAA Account under a BAA using AWS Artifact Agreements?", "output": "When you accept an online BAA within theAccount agreementstab in AWS Artifact, the account you used to sign in to AWS is automatically designated as a HIPAA Account under that online account BAA. If you are amanagement account inAWS Organizations (https://console.aws.amazon.com/organizations/)and accept an online BAA under theOrganization agreementstab in AWS Artifact, all accounts within your organization are automatically designated as HIPAA Accounts. Member accounts that are later added to that organization will be automatically designated as HIPAA Accounts as well. [Source: https://aws.amazon.com/artifact/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I configure my application to use AWS Lambda ephemeral storage?", "output": "You can configure each Lambda function with its own ephemeral storage between 512MB and 10,240MB, in 1MB increments by using the AWS Lambda console, AWS Lambda API, or AWS CloudFormation template during function creation or update. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a resource schema?", "output": "A resource schema defines a resource type in a structured and consistent format. This schema is also used to validate the definition of a resource type. The schema includes all the supported parameters and attributes for a given resource type, as well as the required permissions to create the resource with the least privileges possible. [Source: https://aws.amazon.com/cloudformation/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which Origin Shield Region should I use?", "output": "Amazon CloudFront offers Origin Shield in AWS Regions where CloudFront has aregional edge cache (https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/HowCloudFrontWorks.html#CloudFrontRegionaledgecaches). When you enable Origin Shield, you should choose the AWS Region for Origin Shield that has the lowest latency to your origin. You can use Origin Shield with origins that are in an AWS Region, and with origins that are not in AWS. For more information, seeChoosing the AWS Region (https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/origin-shield.html#choose-origin-shield-region)for Origin Shield in the Amazon CloudFront Developer Guide. [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is AWS CloudShell?", "output": "AWS CloudShell is a browser-based shell that makes it easier to securely manage, explore, and interact with your AWS resources. CloudShell is pre-authenticated with your console credentials. Common development and operations tools are pre-installed, so theres no need to install or configure software on your local machine. With CloudShell, you can quickly run scripts with the AWS Command Line Interface (AWS CLI), experiment with AWS service APIs using the AWS SDKs, or use a range of other tools to be more productive. [Source: https://aws.amazon.com/cloudshell/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which EC2 instances are available on Outposts rack?", "output": "EC2 instances built on the\u00a0AWS Nitro System, for general purpose, compute optimized, memory optimized, storage optimized, and GPU optimized with Intel Xeon Scalable processors are supported on AWS Outposts rack, and Graviton processors based EC2 instances are coming soon. [Source: https://aws.amazon.com/outposts/rack/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I scale the size and performance of my Amazon Redshift data warehouse cluster?", "output": "<p>Amazon Redshift Serverless automatically provisions data warehouse capacity and intelligently scales the underlying resources. Amazon Redshift Serverless adjusts capacity in seconds to deliver consistently high performance and simplified operations for even the most demanding and volatile workloads. With the Concurrency Scaling feature, you can support unlimited concurrent users and concurrent queries, with consistently fast query performance. When concurrency scaling is enabled, Amazon Redshift automatically adds cluster capacity when your cluster experiences increase in query queueing.<br><br>For manual scaling, If you would like to increase query performance or respond to CPU, memory, or I/O overutilization, you can increase the number of nodes within your data warehouse cluster using Elastic Resize through the <a href=\"https://aws.amazon.com/console/\">AWS Management Console</a> or the <a href=\"https://docs.aws.amazon.com/redshift/latest/APIReference/API_ModifyCluster.html\">ModifyCluster</a> API. When you modify your data warehouse cluster, your requested changes will be applied immediately. Metrics for compute utilization, storage utilization, and read/write traffic to your Redshift data warehouse cluster are available free of charge through the AWS Management Console or Amazon CloudWatch APIs. You can also add user-defined metrics through <a href=\"https://aws.amazon.com/cloudwatch/\">Amazon CloudWatch</a> custom metric functionality.<br><br>With Amazon Redshift Spectrum, you can run multiple Redshift clusters accessing the same data in Amazon S3. You can use different clusters for different use cases. For example, you can use one cluster for standard reporting and another for data science queries. Your marketing team can use their own clusters different from your operations team. Redshift Spectrum automatically distributes the execution of your query to several Redshift Spectrum workers out of a shared resource pool to read and process data from Amazon S3, and pulls results back into your Redshift cluster for any remaining processing.</p> [Source: https://aws.amazon.com/redshift/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is AWS Config?", "output": "AWS Config is a fully managed service that provides you with resource inventory, configuration history, and configuration change notifications for security and governance. With AWS Config, you can discover existing AWS resources, record configurations for third-party resources, export a complete inventory of your resources with all configuration details, and determine how a resource was configured at any point in time. These capabilities use compliance auditing, security analysis, resource change tracking, and troubleshooting. [Source: https://aws.amazon.com/config/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a Job Definition?", "output": "A Job Definition describes the job to be executed, parameters, environmental variables, compute requirements, and other information that is used to optimize the execution of a job. Job Definitions are defined in advance of submitting a job and can be shared with others. [Source: https://aws.amazon.com/batch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is email validation?", "output": "With email validation, an approval request email is sent to the registered domain owner for each domain name in the certificate request. The domain owner or an authorized representative (approver) can approve the certificate request by following the instructions in the email. The instructions direct the approver to navigate to the approval website and click the link in the email or paste the link from the email into a browser to navigate to the approval web site. The approver confirms the information associated with the certificate request, such as the domain name, certificate ID (ARN), and the AWS account ID initiating the request, and approves the request if the information is accurate. [Source: https://aws.amazon.com/certificate-manager/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do I have to migrate my data from Amazon S3 or existing Amazon Redshift data warehouse to use SageMaker for SQL analytics?", "output": "No, you don't need to migrate your data in order to use SageMaker for SQL analytics. You can directly discover and query data from multiple sources, including Amazon S3 (AWS Glue Data Catalog and Amazon S3 table buckets), Amazon Redshift (serverless and provisioned), and 13 additional federated data sources compatible with SQL engineering workflows.Amazon SageMaker Lakehouse seamlessly connects to your current data, so you can focus on insights instead of spending time moving information around. In just a few quick steps, you'll be able to explore your data, run queries, and uncover valuable business information without technical hassles. [Source: https://aws.amazon.com/redshift/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do Amazon SQS FIFO queues support multiple producers?", "output": "Yes. One or more producers can send messages to a FIFO queue. Messages are stored in the order that they were successfully received by Amazon SQS.If multiple producers send messages in parallel, without waiting for the success response from SendMessage or SendMessageBatch actions, the order between producers might not be preserved. The response of SendMessage or SendMessageBatch actions contains the final ordering sequence that FIFO queues use to place messages in the queue, so your multiple-parallel-producer code can determine the final order of messages in the queue. [Source: https://aws.amazon.com/sqs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I write custom detections in Amazon GuardDuty?", "output": "No, GuardDuty removes the heavy lifting and complexity of developing and maintaining your own custom rule sets. New detections are continually added based on customer feedback, along with research from AWS security engineers and the GuardDuty engineering team. However, customer-configured customizations include adding your ownthreat lists and trusted IP address list (https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_upload-lists.html). [Source: https://aws.amazon.com/guardduty/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "In which AWS Regions is automatic content redaction or PII redaction available?", "output": "Please refer to theAmazon Transcribe documentationfor information on the availability of automatic content redaction and PII redaction for batch and streaming APIs in the AWS Regions. [Source: https://aws.amazon.com/transcribe/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does SNS support direct addressing for SMS or Email?", "output": "At this time, direct addressing is only supported for mobile push endpoints (APNS, FCM, ADM, WNS, MPNS, Baidu) and SMS. Email messaging requires the use of topics. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I monitor the performance of my Amazon Redshift data warehouse cluster?", "output": "<p>Metrics for compute utilization, storage utilization, and read/write traffic to your Amazon Redshift data warehouse cluster are available free of charge through the <a href=\"https://aws.amazon.com/console/\">AWS Management Console</a> or <a href=\"https://aws.amazon.com/cloudwatch/\">Amazon CloudWatch</a> APIs. You can also add additional, user-defined metrics through Amazon CloudWatchs custom metric functionality. The AWS Management Console provides a monitoring dashboard that helps you monitor the health and performance of all your clusters. Amazon Redshift also provides information on query and cluster performance through the AWS Management Console. This information enables you to see which users and queries are consuming the most system resources to diagnose performance issues by viewing query plans and execution statistics. In addition, you can see the resource utilization on each of your compute nodes to ensure that you have data and queries that are well-balanced across all nodes.</p> [Source: https://aws.amazon.com/redshift/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does GuardDuty monitor all buckets in my account to help protect my AmazonS3 deployment?", "output": "Yes, S3 Protection monitors all AmazonS3 buckets in your environment by default. [Source: https://aws.amazon.com/guardduty/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I combine S3 Metadata tables with my own metadata?", "output": "Yes. You can create your own Iceberg tables in table buckets containing custom metadata, and then join them with the tables that S3 Metadata generates using simple SQL queries. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the difference between AWS IoT Greengrass and FreeRTOS?", "output": "AWS IoT Greengrass is software that lets you run local compute, messaging, data caching, sync, and machine learning inference capabilities for connected devices in a secure way. With AWS IoT Greengrass, connected devices can run AWS Lambda functions, Docker containers, or both, keep device data in sync, and communicate with other devices securelyeven when not connected to the Internet. Using AWS Lambda, AWS IoT Greengrass ensures your IoT devices can respond quickly to local events, use Lambda functions running on AWS IoT Greengrass Core to interact with local resources, operate with intermittent connections, stay updated with over the air updates, and minimize the cost of transmitting IoT data to the cloud.FreeRTOS is an open source, real-time operating system for microcontrollers that operates on the edge and does not generally support chipsets that could run AWS IoT Greengrass. These microcontroller devices are found on a variety of IoT endpoints such as fitness trackers, pacemakers, electricity meters, automotive transmissions, and sensor networks. FreeRTOS devices cannot run AWS IoT Greengrass Core but can connect, send, and receive messages to and from an AWS IoT Greengrass Core device for local processing at the edge.The hardware requirements and operating systems are different on both devices.FreeRTOSAWS IoT GreengrassSoftwareReal-time operating system, runs on a microcontrollerRuntime for Linux devices and SDK for AWS IoT Greengrass aware devicesHardware Requirements>64KBof RAM>96MB*of RAM (v2.0 edge runtime or higher)>128MBof RAM (v1.11 edge runtime or lower)CategoryEmbedded systems, IoT endpointsEdge devices, local gatewaysUse CasesMicrocontroller-based devicesIndustrial automation systems, wireless routers, video cameras, gateways*Based on an AWS study that used the following JDK: JDK version used for the tests: openjdk version \"1.8.0_275\", OpenJDK Runtime Environment (build 1.8.0_275-8u275-b01-0ubuntu1~18.04-b01), and OpenJDK 64-Bit Server VM (build 25.275-b01, mixed mode). Memory usage may be higher using different inputs. [Source: https://aws.amazon.com/greengrass/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How many images are needed to train a custom model?", "output": "The number of images required to train a custom model depends on the variability of the custom labels you want the model to predict and the quality of the training data. For example, a distinct logo overlaid on an image can be detected with 1-2 training images, while a more subtle logo required to be detected under many variations (scale, viewpoint, deformations) may need in the order of tens to hundreds of training examples with high quality annotations. If you already have a high number of labeled images, we recommend training a model with as many images as you have available. Please refer to the documentation for limits on maximum training dataset size. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What can developers now do that they could not before?", "output": "Until now, small developers did not have the capital to acquire massive compute resources and ensure they had the capacity they needed to handle unexpected spikes in load. Amazon EC2 helps developers use Amazon\u2019s own benefits of massive scale with no upfront investment or performance compromises. Developers are now free to innovate knowing that no matter how successful their businesses become, it will be inexpensive and simple to ensure they have the compute capacity they need to meet their business requirements. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What tools are available in SageMaker for analytics and AI jobs?", "output": "SageMaker provides a unified, web-based environment that brings together powerful tools for complete data and AI workflows. Built-in IDEs enable AI/ML development, allowing you to process large data volumes from various sources using frameworks and services like PySpark, AWS Glue, and Amazon EMR.For version control and workflow management, you can commit to Git and define workflows using Amazon MWAA. The integrated SQL query editor allows you to explore, analyze, and visualize data, with the ability to more easily save and share queries and create new datasets.Model development is streamlined through familiar SageMaker AI tools, including Amazon SageMaker notebooks, JumpStart, HyperPod, MLFlow, Pipelines, and Model Registry. Throughout these processes, Amazon Q Developer is seamlessly integrated across SageMaker tools, providing intelligent assistance in data discovery, preparation, pipeline creation, model building and training, and code deployment. [Source: https://aws.amazon.com/sagemaker/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are automatic snapshots?", "output": "Automatic snapshots are a way to schedule daily snapshots of your Linux/Unix instances in Amazon Lightsail. You can pick a time of the day, and Lightsail will automatically take a snapshot for you each day at the time you chose and always keep your seven most recent automatic snapshots. Enabling snapshots is free \u2013 you only pay for the actual storage used by your snapshots. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use the AWS Management Console with Amazon CloudFront?", "output": "Yes. You can use the AWS Management Console to configure and manage Amazon CloudFront though a simple, point-and-click web interface. The AWS Management Console supports most of Amazon CloudFronts features, letting you get Amazon CloudFronts low latency delivery without writing any code or installing any software. Access to the AWS Management Console is provided free of charge athttps://console.aws.amazon.com (https://console.aws.amazon.com/). [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What does \"five times the performance of MySQL\" mean?", "output": "Amazon Aurora delivers significant increases over MySQL performance by tightly integrating the database engine with an SSD-based virtualized storage layer purpose-built for database workloads, reducing writes to the storage system, minimizing lock contention, and eliminating delays created by database process threads.Our tests with SysBench on r3.8xlarge instances show that Amazon Aurora delivers over 500,000 SELECTs/sec and 100,000 UPDATEs/sec, five times higher than MySQL running the same benchmark on the same hardware. Detailed instructions on this benchmark and how to replicate it yourself are provided in theAmazon Aurora MySQL-Compatible Edition Performance Benchmarking Guide (https://d1.awsstatic.com/product-marketing/Aurora/RDS_Aurora_Performance_Assessment_Benchmarking_v1-2.pdf). [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do dense HDD-storage instances differ from Amazon EBS?", "output": "Amazon EBS offers simple, elastic, reliable (replicated), and persistent block level storage for Amazon EC2 while abstracting the details of the underlying storage media in use. Amazon EC2 instance instances with local HDD or NVMe storage provide directly attached, high performance storage building blocks that can be used for a variety of storage applications. Dense-storage instances are specifically targeted at customers who want high sequential read/write access to large data sets on local storage, e.g. for Hadoop distributed computing and massively parallel processing data warehousing. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started after I have signed up?", "output": "The best way to get started with CloudFormation is to work through the Getting Started Guide, which is included in our technical documentation. Within a few minutes, you will be able to deploy and use one of our sample templates that illustrate how to create the infrastructure needed to run applications such as such as WordPress. There are various other sources of CloudFormation training, from thirdsparty curriculum providers to tutorials and articles on the web. For more information, check out theCloudFormation Resources (https://aws.amazon.com/cloudformation/resources/). [Source: https://aws.amazon.com/cloudformation/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What operating systems does AWS CodeDeploy support?", "output": "AWS CodeDeploy supports a wide variety of operating systems. AWS CodeDeploy provides agents that have been tested on Amazon Linux, Red Hat Enterprise Linux, Ubuntu Server, and Microsoft Windows Server. If you want to use other operating systems, the AWS CodeDeploy agent is available as open source softwarehere (https://github.com/aws/aws-codedeploy-agent). For more information on operating system support, seeAWS CodeDeploy Documentation (https://docs.aws.amazon.com/codedeploy/latest/userguide/host-cleanup.html). [Source: https://aws.amazon.com/codedeploy/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will Amazon ECR automatically build images from a Dockerfile?", "output": "No. However, Amazon ECR integrates with a number of popular CI/CD solutions to provide this capability. See the\u00a0Amazon ECR Partners page\u00a0for more information. [Source: https://aws.amazon.com/ecr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When would I want to consider using a Redis OSS read replica?", "output": "With ElastiCache Serverless, read replicas are automatically maintained by the service. When designing your own cache, there are a variety of scenarios where deploying one or more read replicas for a given primary node might make sense. Common reasons for deploying a read replica include:Scaling beyond the compute or I/O capacity of a single primary node for read-heavy workloads: This excess read traffic can be directed to one or more read replicas.Serving read traffic while the primary is unavailable: If your primary node cannot take I/O requests (for example, due to I/O suspension for backups or scheduled maintenance), you can direct read traffic to your read replicas. For this use case, keep in mind that the data on the read replica might be stale, since the primary instance is unavailable. The read replica can also be used warmed up to restart a failed primary.Data protection scenarios: In the unlikely event of primary node failure or that the AZ in which your primary node resides becomes unavailable, you can promote a read replica in a different AZ to become the new primary. [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the regional availability of Amazon EC2 instance types?", "output": "For a list of all instances and regional availability, visitAmazon EC2 Pricing. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will there be changes to pricing and billing when previous generation instances are migrated to AWS Nitro System?", "output": "There will be no change to billing and pricing. We will continue to support the same pricing models we support today for the previous generation instances (On-Demand, 1yr/3yr Reserved Instance, Savings Plan, Spot). [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the maximum size I can set for my Amazon AppStream 2.0 fleet when using Fleet Auto Scaling policies?", "output": "Fleet Auto Scaling policies increase fleet capacity until it reaches your defined maximum size or until service limits apply. For more information, please seeFleet Auto Scaling for Amazon AppStream 2.0 (https://docs.aws.amazon.com/appstream2/latest/developerguide/autoscaling.html). For service limit information, please seeAmazon AppStream 2.0 Service Limits (https://docs.aws.amazon.com/appstream2/latest/developerguide/limits.html). [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started with EC2 Capacity Blocks?", "output": "You can search for available EC2 Capacity Blocks based on your capacity needs in theAWS Management Console,AWS Command Line Interface (AWS CLI), andAWS SDKs. Once you purchase an EC2 Capacity Block, a reservation is created in your account. When the EC2 Capacity Block start time arrives, EC2 will emit an event through Amazon EventBridge to indicate that the reservation is now active and available for use. To use an active EC2 Capacity Block, select the \u201cCapacity Block\u201d purchase option and target the capacity reservation ID for your EC2 Capacity Block while launching EC2 instances. As your EC2 Capacity Block end time approaches, EC2 will emit event through EventBridge letting you know your reservation is ending soon so you can checkpoint your workload. Around 30 minutes before your EC2 Capacity Block expires, AWS will begin terminating any running instances. The amount you are charged for your EC2 Capacity Block does not include the last 30 minutes of the reservation. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Nitro System support for Older Generation instances?", "output": "The AWS Nitro System now will provide its modern hardware and software components for previous generation EC2 instances to extend the length of service beyond the typical lifetime of the underlying hardware. With the Nitro System support, customers can continue running their workloads and applications on the instance families they were built on. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which operating systems/AMIs are supported on X2gd instances?", "output": "The following AMIs are supported: Amazon Linux 2, Ubuntu 18.04 or newer, Red Hat Enterprise Linux 8.2 or newer, and SUSE Enterprise Server 15 or newer. Customers will find additional AMIs such as Fedora, Debian, NetBSD, and CentOS available through community AMIs and the AWS Marketplace. For containerized applications, Amazon ECS and EKS optimized AMIs are available as well. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use AWS DRS to recover from a ransomware event?", "output": "Yes, you can useAWS DRSto prepare your environment for ransomware and other malicious activities. In the event of a disruption, use point-in-time recovery to launch a copy of your applications in an operational state prior to a security incident. Learn more aboutransomware recovery using AWS DRS (https://aws.amazon.com/disaster-recovery/ransomware-recovery/). [Source: https://aws.amazon.com/disaster-recovery/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "In what Regions is Amazon MSK available?", "output": "For information about the Regions in which Amazon MSK is available, visit theAWS Regions table (https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/). [Source: https://aws.amazon.com/msk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How many concurrent video streams can I process with Amazon Rekognition?", "output": "Amazon Rekognition Streaming Video Events can support 600 concurrent sessions per AWS customer. Please reach out to your account manager if you need to increase this limit. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a Workspace in EMR Studio?", "output": "Workspaces help you organize Jupyter Notebooks. All notebooks in a Workspace are saved to the same Amazon S3 location and run on the same cluster. You can also link a code repository like a GitHub repository to all notebooks in a workspace. You can create and con\ufb01gure a Workspace before attaching it to a cluster, but you should connect to a cluster before running a notebook. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "In which region is my data going to be stored?", "output": "Amazon WorkDocs is currently available in6 regions. Your data is always stored in the region you have created your WorkDocs site in. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the typical steps to go through for deploying an application using AWS CodeDeploy?", "output": "The following diagram shows the typical steps during a deployment. Creating an application and deployment group (see theConcepts (https://aws.amazon.com/codedeploy/faqs/?nc=sn&loc=6)section for an explanation of these terms) are typically one-time setup tasks per application. The recurring actions are uploading a revision and deploying it. For a detailed explanation, including step-by-step instructions for each of these tasks, seeDeployments (https://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-steps.html). [Source: https://aws.amazon.com/codedeploy/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I set up IAM Identity Center to business applications, such as Salesforce?", "output": "From the IAM Identity Center console, navigate to the applications pane, choose Configure new application, and choose an application from the list of cloud applications that are pre-integrated with IAM Identity Center. Follow the on-screen instructions to configure the application. Your application is now configured and you may assign access to it. Choose the groups or users that you want to provide with access to the application and Choose Assign Access to complete the process. [Source: https://aws.amazon.com/iam/identity-center/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I schedule several activity tasks by issuing one decision?", "output": "Yes, you can schedule up to 100 activity tasks in one decision and also issue several decisions one after the other. [Source: https://aws.amazon.com/swf/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is Amazon SNS available in all regions where AWS services are available?", "output": "Please refer to theAWS Regions and Endpointssection of the AWS documentation for the most up to date information on Amazon SNS availability. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why should I use mTLS with AWS App Mesh?", "output": "Microservices also have particular security needs, including end-to-end traffic encryption and flexible service access control, which can be addressed with a service mesh. The AWS App Mesh mTLS implementation enables your client applications to verify the servers and provides traffic encryption, and mutual TLS offers peer authentication that is used for service-to-service authentication. It adds a layer of security over TLS that allows your services to verify the client making the connection. Breaking down a monolithic application into microservices and running them in a service mesh offers various benefits, including better visibility and smart traffic routing. [Source: https://aws.amazon.com/app-mesh/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I create digitally signed code artifacts?", "output": "You can create digitally signed code artifacts using a Signing Profile through the AWS Signer console, the Signer API, SAM CLI or AWS CLI. To learn more, please see the documentation for AWS Signer. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "At which levels can Amazon API Gateway throttle inbound API traffic?", "output": "Throttling rate limits can be set at the method level. You can edit the throttling limits in your method settings through the Amazon API Gateway APIs or in the Amazon API Gateway console. [Source: https://aws.amazon.com/api-gateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Are improvements guaranteed? Is it worth expending the effort of collecting text data?", "output": "Improvements are not guaranteed \u2013 the change in performance will depend on how closely the text data matches the audio, and on the amount of data provided. More data is generally better, but most importantly, the data should cover words and word sequences that are expected to occur in the audio files you intend to transcribe. Improvements to transcription accuracy will depend on the quality of the training data as well as the use case. In some scenarios, general benchmarking indicates as much as 10% to 15% relative accuracy improvement. [Source: https://aws.amazon.com/transcribe/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do Amazon Rekognition Video asynchronous APIs work?", "output": "Amazon Rekognition Video can process videos stored in an Amazon S3 bucket. You can use an asynchronous set of operations: you start video analysis by calling a Start operation such as StartLabelDetection for detecting objects and scenes. The completion status of the request is published to an Amazon Simple Notification Service (SNS) topic. To get the completion status from the Amazon SNS topic, you can use an Amazon Simple Queue Service (SQS) queue or an AWS Lambda function. Once you have the completion status, you call a Get operation such as GetLabelDetection to get the results of the request. For a list of available Amazon Rekognition Video APIs, please seethis page. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started?", "output": "You can enable CloudTrail Insights events on individual trails in your account by using the console, the CLI, or the SDK. You can also enable CloudTrail Insights events across your organization by using an Organizational trail configured in your AWS Organizations management account. You can turn on CloudTrail Insights events by choosing the radio button in your trail definition. [Source: https://aws.amazon.com/cloudtrail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "I am currently using Lumberyard, can I continue using it for my project?", "output": "Yes, you can continue using Lumberyard and release your project that uses Lumberyard. [Source: https://aws.amazon.com/lumberyard/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I encrypt an existing unencrypted cluster?", "output": "Currently, encrypting an existing unencrypted Amazon DocumentDB cluster is not supported. To use Amazon DocumentDB encryption for an existing unencrypted cluster, create a new cluster with encryption enabled and migrate your data into it. [Source: https://aws.amazon.com/documentdb/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use CodeBuild to automate my release process?", "output": "Yes. CodeBuild is integrated with AWS CodePipeline. You can add a build action and set up a continuous integration and continuous delivery process that runs in the cloud. You can learn how to set up and monitor your builds from the CodePipeline consolehere (https://docs.aws.amazon.com/codebuild/latest/userguide/how-to-create-pipeline.html). [Source: https://aws.amazon.com/codebuild/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I monitor my gateway?", "output": "You can useAmazon CloudWatch (https://aws.amazon.com/cloudwatch/)to monitor theperformance metrics and alarms for your gateway (https://docs.aws.amazon.com/storagegateway/latest/userguide/AWSStorageGatewayMetricsList-common.html), giving you insight into storage, bandwidth, throughput, and latency. These metrics and alarms are accessible directly from CloudWatch; or by following links in the AWS Storage Gateway Console, which take you directly to the CloudWatch metrics or alarms for the resource being viewed. Please refer to the CloudWatch details and pricing pages for additional information. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I change the version of Amazon Linux or any language runtime?", "output": "No. AWS Lambda offers a single version of the operating system and managed language runtime to all users of the service. You can bring your own language runtime to use in Lambda. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I purchase Amazon Chime?", "output": "To purchase Amazon Chime, create or sign into your AWS account and create an Amazon Chime Team. Next, add users and assign permissions (Basic or Pro) to give access to features for each user. Visit the Get Started Using Amazon Chime pagehere. [Source: https://aws.amazon.com/chime/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which regions does AWS CodePipeline support?", "output": "Please refer toRegional Products and Services (https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)for details of CodePipeline availability by region. [Source: https://aws.amazon.com/codepipeline/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I uniquely identify my AS2 trading partner?", "output": "Your trading partner is uniquely identified using their AS2 Identifier (AS2 ID). Similarly, your trading partners identify your messages using your AS2 ID. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use Amazon WorkMail on my mobile device?", "output": "Yes. Amazon WorkMail is compatible with most major mobile devices supporting the Microsoft Exchange ActiveSync protocol, including iPad, iPhone, Kindle Fire, Fire Phone, Android, Windows Phone, and BlackBerry 10. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will these limits change over time?", "output": "Yes, limits can change over time. Amazon EC2 is constantly monitoring your usage within each region and your limits are raised automatically based on your use of EC2. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens in the case of local storage failure?", "output": "If the local storage fails, Aurora automatically performs a host replacement. In a multi-node database cluster, this triggers an in-region failover. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How far in advance can I reserve an EC2 Capacity Block?", "output": "You can purchase an EC2 Capacity Block as far out as eight weeks into the future or as soon as now, when capacity is available. EC2 Capacity Blocks reservations that start in the future always begin at 11:30 AM Coordinated Universal Time (UTC), and they always end at 11:30AM UTC. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does regional edge caching work?", "output": "Amazon CloudFront has multiple globally dispersedRegional Edge Caches (https://aws.amazon.com/cloudfront/features/)(or RECs), providing an additional caching layer close your end-users. They are located between your origin webserver and AWS edge locations that serve content directly to your users. As cached objects become less popular, individual edge locations may remove those objects to make room for more commonly requested content. Regional Edge Caches have a larger cache width than any individual edge location, so objects remain cached longer. This helps keep more of your content closer to your viewers, reducing the need for CloudFront to go back to your origin webserver and improving overall performance for viewers. For example, CloudFront edge locations in Europe now go to the regional edge cache in Frankfurt to fetch an object before going back to your origin webserver. Regional edge cache locations can be used with any origin, such as S3, EC2, or custom origins. RECs are skipped in Regions currently hosting your application origins. [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I grant an IAM user access to AWS Elastic Beanstalk?", "output": "You can grant IAM users access to services by using policies. To simplify the process of granting access to AWS Elastic Beanstalk, you can use one of the policy templates in the IAM console to help you get started. Elastic Beanstalk offers two templates: a read-only access template and a full-access template. The read-only template grants read access to Elastic Beanstalk resources. The full-access template grants full access to all Elastic Beanstalk operations, as well as permissions to manage dependent resources, such as Elastic Load Balancing, Auto Scaling, and Amazon S3. You can also use the AWS Policy Generator to create custom policies. For more details, see the AWS Elastic Beanstalk Developer Guide. [Source: https://aws.amazon.com/elasticbeanstalk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How many concurrent video analysis jobs can I run with Amazon Rekognition Video?", "output": "You can process up to 20 concurrent jobs with Amazon Rekognition Video. For more details on limits, please see ourlimits page. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is there a limit on a number of replies to a comment?", "output": "No, there is no limit. A comment can have unlimited replies. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started with Amazon Transcribe Call Analytics?", "output": "Please refer to theAWS regional services documentationfor information on AWS Region coverage for Amazon Transcribe Call Analytics. Please note that Amazon Transcribe Call Analytics generative call summarization is currently available only in US East (N. Virginia) and US West (Oregon). [Source: https://aws.amazon.com/transcribe/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I determine whether my website, program, or application is subject to COPPA?", "output": "For information about the requirements of COPPA and guidance for determining whether your website, program, or other application is subject to COPPA, please refer directly to the resources provided and maintained by theUnited States Federal Trade Commission (https://www.ftc.gov/tips-advice/business-center/guidance/complying-coppa-frequently-asked-questions). This site also contains information regarding how to determine whether a service is directed or targeted, in whole or in part, to children under age 13. [Source: https://aws.amazon.com/polly/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I delete all messages in a message queue without deleting the message queue itself?", "output": "Yes. You can delete all messages in an Amazon SQS message queue using the PurgeQueue action.When you purge a message queue, all the messages previously sent to the message queue are deleted. Because your message queue and its attributes remain, there is no need to reconfigure the message queue; you can continue using it.To delete only specific messages, use the DeleteMessage or DeleteMessageBatch actions.For more information, see this Tutorial:Purging Messages from an Amazon SQS Queue (https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-using-purge-queue.html). [Source: https://aws.amazon.com/sqs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will all features and AMIs on my previous generation instances be supported as a part of this migration?", "output": "Yes, all existing features and AMIs supported on previous generation instances will be supported as we migrate these instances to AWS Nitro System. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does pgvector work with Aurora machine learning?", "output": "Yes.Aurora machine learning (https://aws.amazon.com/rds/aurora/machine-learning/)(ML) exposes ML models as SQL functions, allowing you to use standard SQL to call ML models, pass data to them, and return predictions as query results. pgvector requires vector embeddings to be stored in the database, which requires running the ML model on source text or image data to generate embeddings and then moving the embeddings in batch into Aurora PostgreSQL.Aurora ML can make this a real-time process enabling embeddings to be kept up-to-date in Aurora PostgreSQL by making periodic calls toAmazon Bedrock (https://aws.amazon.com/bedrock/)orAmazon SageMaker (https://aws.amazon.com/sagemaker/)which returns the most recent embeddings from your model. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I privately access AWS Migration Hub Refactor Spaces APIs from my VPC without using public IP addresses?", "output": "Yes, you can privately access Refactor Spaces APIs from your VPC (created using Amazon Virtual Private Cloud) by creating VPC Endpoints. With VPC Endpoints, the routing between the VPC and Refactor Spaces is handled by the AWS network without the need for an internet gateway, NAT gateway, or virtual private network (VPN) connection. The latest generation ofVPC Endpoints (https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-setting-up-vpc.html)used by Refactor Spaces is powered by AWS PrivateLink, a technology that enables private connectivity between AWS services using Elastic Network Interfaces (ENIs) with private IP addresses in your VPCs.To learn more about PrivateLink support, visit theRefactor Spaces PrivateLink documentation (https://docs.aws.amazon.com/migrationhub-refactor-spaces/latest/userguide/vpc-interface-endpoints.html). [Source: https://aws.amazon.com/migration-hub/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What operating system are the browsers hosted on?", "output": "All browsers are hosted on EC2 Windows instances which run on Microsoft Windows Server. [Source: https://aws.amazon.com/device-farm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How quickly will I get an attack notification?", "output": "Typically, AWS Shield Advanced provides notification of an attack within a few minutes of attack detection. [Source: https://aws.amazon.com/shield/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which languages does Amazon Transcribe Medical support?", "output": "Amazon Transcribe Medical currently supports medical transcription in US English. [Source: https://aws.amazon.com/transcribe/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I use AWS DataSync with Amazon EFS file system resource policies?", "output": "You can use both IAM identity policies and resource policies to control client access to Amazon EFS resources in a way that is scalable and optimized for cloud environments. When you create a DataSync location for your EFS file system, you can specify an IAM role that DataSync will assume when accessing EFS. You can then useEFS file system policies (https://docs.aws.amazon.com/efs/latest/ug/iam-access-control-nfs-efs.html)to configure access for the IAM role. Because DataSync mounts EFS file systems as the root user, your IAM policy must allow the following action: elasticfilesystem:ClientRootAccess. [Source: https://aws.amazon.com/datasync/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Who are the primary users of AWS Data Exchange?", "output": "AWS Data Exchange makes it easy for AWS customers to securely exchange and use third-party data on AWS. Data analysts, product managers, portfolio managers, data scientists, quants, clinical trial technicians, and developers in nearly every industry would like access to more data to drive analytics, train\u00a0machine learning (ML) models, and make data-driven decisions. But there is no one place to find data from multiple providers and no consistency in how providers deliver data, leaving them to deal with a mix of shipped physical media, FTP credentials, and bespoke API calls. Conversely, many organizations would like to make their data available for either research or commercial purposes, but it\u2019s too hard and expensive to build and maintain data delivery, entitlement, and billing technology, which further depresses the supply of valuable data. [Source: https://aws.amazon.com/data-exchange/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I use multiple watermarks?", "output": "Presets specify placement settings for up to four watermarks. Each setting has an associated watermark ID. You can create a job with up to four watermarks by specifying an array of watermarks in the job creation call. Each element of the array specifies the Id of the watermark setting to use, and the watermark image file. [Source: https://aws.amazon.com/elastictranscoder/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will Amazon WorkMail still synchronize with my Active Directory when interoperability support isn\u2019t enabled?", "output": "Yes, Amazon WorkMail will still synchronize with your Active Directory when interoperability support is disabled. In this scenario only changes to Amazon WorkMail users and groups are synchronized. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How am I billed?", "output": "Using the Upgrade to EC2 feature is free. Once you have exported your snapshots to EC2, you will be charged for the EC2 image separately and in addition to your Lightsail snapshot. Any new EC2 instances you launch will also be billed by EC2, including their EBS storage volume(s) and data transfer. Refer to the EC2 pricing page for details on the pricing for your new instance and resources. Lightsail resources that continue to run in your Lightsail account will continue to be billed at their regular rates until they are deleted. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the difference between key-value and key-only Tags?", "output": "Lightsail tags are key-value pairs, allowing you to organize resources such as instances across different categories, e.g. project:Blog, project:Game, project:Test. This allows you full control across all use cases such as resource organization, bill reporting, and access management. The Lightsail console also allows you to tag your resources with key-only tags for quick filtering in the console. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How will the t4g.small free trial be reflected on my AWS bill?", "output": "The T4g free trial has a monthly billing cycle that starts on the first of every month and ends on the last day of that month. Under the T4g free-trial billing plan, customers using t4g.small will see a $0 line item on their bill under the On-Demand pricing plan for the first 750 aggregate hours of usage for every month during the free-trial period. Customers can start any time during the free-trial period and get 750 free hours for the remainder of that month. Any unused hours from the previous month will not be carried over. Customers can launch multiple t4g.small instances under the free trial. Customers will be notified automatically through email using AWS Budgets when their aggregate monthly usage reaches 85% of 750 free hours. When the aggregate instance usage exceeds 750 hours for the monthly billing cycle, customers will be charged based on regular On-Demand pricing for the exceeded hours for that month. For customers with a Compute Savings Plan or T4g Instance Savings Plan, Savings Plan (SV) discount will be applied to On-Demand pricing for hours exceeding the 750 free trial hours. If customers have purchased the T4g Reserved Instance (RI) plan, the RI plan applies first to any usage on an hourly basis. For any remaining usage after the RI plan has been applied, the free trial billing plan is in effect. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What resources are within a cluster?", "output": "Provisioned clusters contain broker instances and abstracted metadata nodes. Serverless clusters are a resource in and of themselves, which abstract away all underlying resources. [Source: https://aws.amazon.com/msk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do I need to take any action to take advantage of AZ and instance size flexibility?", "output": "Regional RIs do not require any action to take advantage of AZ and instance size flexibility. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a custom image?", "output": "A Custom Image is an EMR on EKS provided docker image (\u201cbase image\u201d) that contains the EMR runtime and connectors to other AWS services that you modify to include application dependencies or additional packages that your application requires. The new image can be stored in eitherAmazon Elastic Container Registry (ECR)or your own Docker container registry. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a critical bug?", "output": "A critical bug is a defect determined by AWS to impact the functionality of the affected library and has no reasonable workaround. We will determine the need for a fix based on the impact of the defect (e.g. vulnerability, inoperability, or impaired functionality) on a case-by-case basis. [Source: https://aws.amazon.com/freertos/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What kind of reports can I create in AWS Backup Audit Manager?", "output": "You can create reports related to your AWS Backup activity. These reports help you get details of your backup, copy, and restore jobs. You can use these reports to monitor your operational posture and identify any failures that might need further action. [Source: https://aws.amazon.com/backup/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How is TLE for PostgreSQL different from extensions available on Amazon Aurora and Amazon RDS today?", "output": "Aurora (https://aws.amazon.com/rds/aurora/)andAmazon RDS (https://aws.amazon.com/rds/)support a curated set of over85 PostgreSQL extensions (https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_PostgreSQL.html#PostgreSQL.Concepts.General.FeatureSupport.Extensions). AWS manages the security risks for each of these extensions under theAWS shared responsibility model (https://aws.amazon.com/compliance/shared-responsibility-model/). The extension that implementsTLE for PostgreSQL (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/PostgreSQL_trusted_language_extension.html)is included in this set. Extensions that you write or that you obtain from third-party sources and install in TLE are considered part of your application code. You are responsible for the security of your applications that use TLE extensions. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens in case of failure?", "output": "Amazon monitors and maintains the HSM and network for availability and error conditions. If an HSM fails or loses network connectivity, the HSM will be automatically replaced. You can check the health of an individual HSM using theAWS CloudHSM's APIs, SDKs, or CLI Tools, and you can check the overall health of the service at any time using theAWS Service Health Dashboard (https://status.aws.amazon.com/). [Source: https://aws.amazon.com/cloudhsm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I search for log events from a specific log stream?", "output": "You can search for log events from a specific log stream by adding the query command filter @logStream = \"log_stream_name\" to your log query. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I change the default broker configurations or upload a cluster configuration to Amazon MSK?", "output": "Yes, Amazon MSK allows you to create custom configurations and apply them to new and existing clusters. Express brokers protect more of the configurations from suboptimal values that may affect availability and durability. Express brokers also offer a simpler experience by abstracting configurations that have to do with storage since Amazon MSK fully manages the storage layer. For more information on custom configurations, see theconfiguration documentation (https://docs.aws.amazon.com/msk/latest/developerguide/msk-configuration.html). [Source: https://aws.amazon.com/msk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Amazon ECS support service-to-service communication?", "output": "\nService Connect:\u00a0Amazon ECS Service Connect simplifies service discovery, connectivity, and traffic observability for Amazon ECS. It helps you build applications faster by letting you focus on the application code and not on your networking infrastructure. You can use Amazon ECS Service Connect to define logical names for your service endpoints and use them in your client applications to connect to dependencies. Amazon ECS Service Connect helps send your traffic to healthy endpoints and provides rich traffic telemetry in the Amazon ECS console and in Amazon CloudWatch. Native Amazon ECS deployments are more robust with Amazon ECS Service Connect, as it supports automatic connection draining that helps your client applications switch to a new version of the service endpoint without encountering traffic errors. With Amazon ECS Service Connect, you can: \n  \nSet the way client applications connect to their dependencies in just one step\nWrite and operate resilient distributed applications with logical naming\nMonitor and distribute traffic between Amazon ECS tasks without deploying and configuring load balancers\nDeploy services faster and deliver seamless integration of Amazon ECS microservices comprising an application\n \nService Discovery:\u00a0Amazon ECS is integrated with\u00a0AWS Cloud Map\u00a0to make it easy for your containerized services to discover and connect with each other. AWS Cloud Map is a cloud resource discovery service that lets you define custom names for your application resources. It increases your application availability because your web service will always discover the most up-to-date locations of these dynamically changing resources.\n [Source: https://aws.amazon.com/ecs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I get started with Network Monitor?", "output": "To use Network Monitor, you create a monitor and associate your applications resources with it. You choose source subnets belonging to your Amazon Virtual Private Cloud (VPCs) and then you choose the destination IP addresses in your on-premises network. Network Monitor creates a mesh of the possible source and destination combinations, each of which is called a probe, within a single monitor. Network Monitor creation is fully managed by AWS and you should be able to view real-time metrics within minutes of setting up your monitors. Network Monitor vends these real-time metrics to CloudWatch CloudWatch Metrics, so you can easily use CloudWatch tools to better understand network health in AWS regions specific to your network. Please refrence CloudWatchdocumention (https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/WhatIsCloudWatch.html)on detailed set up instructions. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If I don\u2019t use WorkSpaces Personal for the full month, are the fees prorated?", "output": "A: If you\u2019re paying for WorkSpaces monthly, your WorkSpaces are charged for the full month\u2019s usage. If you\u2019re paying hourly (AutoStop running mode), you are charged for the hours during which your Amazon WorkSpaces are running or undergoing maintenance, plus a monthly fee for fixed infrastructure costs. In both cases, the monthly fee is prorated in the first month only. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does cross-cluster replication support Ultrawarm and Cold Storage?", "output": "No. Current implementation of cross-cluster replication does not support Ultrawarm or Cold Storage. [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I terminate an ANDB Addendum using AWS Artifact Agreements?", "output": "You can use AWS Artifact Agreements to terminate an ANDB Addendum at any time.To terminate an account ANDB Addendum, you can use theAccount agreementstab in AWS Artifact and click on the Terminate the AWS Australian Notifiable Data Breach Addendum for this Account button.To terminate an organizations ANDB Addendum, you can use theOrganization agreementstab in AWS Artifact and click on the Terminate AWS Australian Notifiable Data Breach Addendum for this Organization button. [Source: https://aws.amazon.com/artifact/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I move my Lightsail content delivery network (CDN) distribution to Amazon CloudFront?", "output": "Yes, you can move your Lightsail distribution by creating a similarly configured distribution in CloudFront. All of the settings that can be configured in a Lightsail distribution can also be configured in a CloudFront distribution. Complete the following steps to move your distribution to CloudFront:\n1. Take a snapshot of your Lightsail instance that is configured as your distribution's origin. Export the snapshot to Amazon EC2, and then create a new instance from the snapshot in EC2. For more information, see\u00a0Exporting Amazon Lightsail snapshots.\nNote:\u00a0Create an application load balancer in Elastic Load Balancing if you need to load balance your website or web application. For more information, see the\u00a0Elastic Load Balancing User Guide.\n2. Disable custom domains for your Amazon Lightsail distribution to detach certificates that you might have attached to it. For more information, see\u00a0Disabling custom domains for your Amazon Lightsail distributions.\n3. Using the AWS Command Line Interface (CLI), run the get-distributions command to get a list of your Lightsail distribution\u2019s settings. For more information, see\u00a0get-distributions\u00a0in the AWS CLI Reference.\n4. Sign in to the\u00a0Amazon CloudFront console\u00a0and create a distribution with the same configuration settings as your Lightsail distribution. For more information, see\u00a0Creating a Distribution\u00a0in the Amazon CloudFront Developer Guide.\n5. Create a certificate in AWS Certificate Manager (ACM) that you will attach to your CloudFront distribution. For more information, see\u00a0Request a Public Certificate\u00a0in the ACM User Guide.\nUpdate your CloudFront distribution to use the ACM certificate you created. For more information, see Updating your CloudFront distribution in the CloudFront User Guide. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will I be able to view instance usage against these limits?", "output": "With the Amazon CloudWatch metrics integration, you can view EC2 usage against limits in theService Quotas console. Service Quotas also enables customers to use CloudWatch for configuring alarms to warn customers of approaching limits. In addition, you can continue to track and inspect your instance usage in Trusted Advisor and Limit Monitor. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What integration options does Amazon OpenSearch Service have with Amazon Security Lake?", "output": "The integration between Amazon OpenSearch Service and Amazon Security Lake provides a streamlined experience for directly searching, gaining insights from, and analyzing data stored in Security Lake, all within the OpenSearch Service. There are two ways you can integrate Security Lake and OpenSearch Service: query-access and data-access.With the query-access integration, security analysts can use the OpenSearch Dashboards console to run direct queries on the data in Security Lake and leverage on-demand indexing and pre-built content to get started with security-related queries. For the data-access integration, the OpenSearch ingestion service provides a preconfigured Security Lakeblueprint (https://docs.aws.amazon.com/opensearch-service/latest/developerguide/configure-client-security-lake.html), which includes a default configuration for ingesting Open Cybersecurity Schema Framework (OCSF) parquet files from Security Lake. The zero-ETL integration with Security Lake is only offered on collections with OpenSearch UI as opposed to on clusters. [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the difference between monthly pricing and hourly pricing for WorkSpaces Personal?", "output": "A: With monthly billing, you pay a fixed monthly fee for unlimited usage and instant access to a running Amazon WorkSpace at all times. Hourly pricing allows you to pay for your Amazon WorkSpaces by the hour and save money on your AWS bill when your users only need part-time access to their Amazon WorkSpaces. When WorkSpaces being billed hourly are not being used, they automatically stop after a specified period of inactivity, and hourly usage metering is suspended. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why would I choose to use S3 Intelligent-Tiering?", "output": "You can use S3 Intelligent-Tiering as the default storage class for virtually any workload, especially data lakes, data analytics, machine learning, new applications, and user-generated content. S3 Intelligent-Tiering is the first cloud storage that automatically reduces your storage costs on a granular object level by automatically moving data to the most cost-effective access tier based on access frequency, without performance impact, retrieval fees, or operational overhead. If you have data with unknown or changing access patterns, including data lakes, data analytics, and new applications, we recommend using S3 Intelligent-Tiering. If you have data that does not require immediate retrieval, we recommend activating the Deep Archive Access tier where you pay as little as $1 per TB per month for data that may become rarely accessed over long periods of time. S3 Intelligent-Tiering is for data with unknown or changing access patterns. There are no retrieval fees when using the S3 Intelligent-Tiering storage class. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can EC2 Auto Scaling groups span multiple AWS regions?", "output": "EC2 Auto Scaling groups are regional constructs. They can span Availability Zones, but not AWS regions. [Source: https://aws.amazon.com/ec2/autoscaling/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a Lightsail instance?", "output": "A Lightsail instance is a virtual private server (VPS) that lives in the AWS Cloud. Use your Lightsail instances to store your data, run your code, and build web-based applications or websites. Your instances can connect to each other and to other AWS resources through both public (Internet) and private (VPC) networking. You can create, manage, and connect easily to instances right from the Lightsail console. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will enabling IAM Identity Center modify any of my existing IAM roles, users, or policies?", "output": "No, IAM Identity Center does not modify any existing IAM roles, users, or policies in your AWS accounts. IAM Identity Center creates new roles and policies specifically for use through IAM Identity Center. [Source: https://aws.amazon.com/iam/identity-center/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the typical latency for Amazon SQS?", "output": "Typical latencies for SendMessage, ReceiveMessage, and DeleteMessage API requests are in the tens or low hundreds of milliseconds. [Source: https://aws.amazon.com/sqs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How many inference compute resources should I provision for my custom model?", "output": "The number of parallel inference compute resources needed depends on how many images you need to process at a given point in time. The throughput of a single resource will depend factors including the size of the images, the complexity of those images (how many detected objects are visible), and the complexity of your custom model. We recommend that you monitor the frequency at which you need provision your custom model, and the number of images that need to be processed at a single time, in order to schedule provisioning of your custom model most efficiently.If you expect to process images periodically (e.g. once a day or week, or scheduled times during the day), you should Start provisioning your custom model at a scheduled time, process all your images, and then Stop provisioning. If you don\u2019t stop provisioning, you will be charged even if no images are processed. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What Amazon EC2 instance types and AMIs work with Amazon EFS?", "output": "Amazon EFS is compatible with all Amazon EC2 instance types and is accessible from Linux-based AMIs. You can mix and match the instance types connected to a single file system. For a step-by-step example of how to access a file system from an Amazon EC2 instance, please see theAmazon EFS Getting Started guide. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is AWS Elastic Beanstalk?", "output": "AWS Elastic Beanstalk makes it even easier for developers to quickly deploy and manage applications in the AWS Cloud. Developers simply upload their application, and Elastic Beanstalk automatically handles the deployment details of capacity provisioning, load balancing, auto-scaling, and application health monitoring. [Source: https://aws.amazon.com/elasticbeanstalk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why should I use Amazon Translate?", "output": "You should use Amazon Translate because it enables you to reach more customers, communicate with them more effectively, and decrease your TCO. Many businesses have large volumes of content, user or company authored; the only way to make all of it accessible in multiple languages in a timely manner is to use Machine Translation. Because Amazon Translate costs a fraction of the cost of human translation (0.05% at $15/1M characters for Amazon Translate vs $30K for human translation on average), businesses can now afford to translate content they could not before.For Language Service Providers (LSP) and value-added resellers, Amazon Translate supports business growth and expansion. With Amazon Translate, LSPs can increase productivity by as much as 50% and produce larger volumes of translation, freeing professional translators to focus on high-end creative content. Amazon Translate also allows you to customize your translation output using Active Custom Translation, as LSPs, you protect your IP when you use ACT provide customized translation. Translation Resellers can broaden their service portfolio without building new infrastructure or hiring staff. [Source: https://aws.amazon.com/translate/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens to my Spot instance when it gets interrupted?", "output": "You can choose to have your Spot instances terminated, stopped or hibernated upon interruption. Stop and hibernate options are available for persistent Spot requests and Spot Fleets with the \u201cmaintain\u201d option enabled. By default, your instances are terminated. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Amazon Rekognition Streaming Video Events work?", "output": "You can use your new or existing Kinesis Video Streams to get started with Amazon Rekognition Streaming Video events. When configuring your stream processor settings for Amazon Rekognition you can choose the desired labels (person, pet, or package) that you want to detect, the duration for the video (up to 120 seconds per motion event) that Rekognition should process for each event, and/or the region of interest on the frame that you want to process through Rekognition. Rekognition Streaming Video Event APIs process video only when you send a notification to Rekognition to start processing the video stream. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I add or modify request headers forwarded to the origin?", "output": "Yes, you can configure Amazon CloudFront to add custom headers, or override the value of existing headers, to requests forwarded to your origin. You can use these headers to help validate that requests made to your origin were sent from CloudFront; you can even configure your origin to only allow requests that contain the custom header values you specify. Additionally, if you use multiple CloudFront distributions with the same origin, you can use custom headers to distinguish origin request made by each different distribution. Finally, custom headers can be used to help determine the right CORS headers returned for your requests. You can configure custom headers via the CloudFront API and the AWS Management Console. There are no additional charges for this feature. For more details on how to set your custom headers, you can read morehere (https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/forward-custom-headers.html). [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What does your Amazon EMR Service Level Agreement provide?", "output": "AWS will use commercially reasonable efforts to make each Amazon EMR Service available with a Monthly Uptime Percentage for each AWS region, in each case during any monthly billing cycle, of at least 99.9% (the \u201cService Commitment\u201d).  [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon WorkMail support email archiving?", "output": "Email journaling can be enabled to capture and preserve messages in your existing archiving solution. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started with Savings Plans?", "output": "You can get started with Savings Plans from AWS Cost Explorer in the AwS Management Console or by using the API/CLI. You can easily make a commitment to a Savings Plan by using the recommendations provided inAWS Cost Explorer, to realize the biggest savings. The recommended hourly commitment is based on your historical On Demand usage and your choice of plan type, term length, and payment option. Once you sign up for a Savings Plan, your compute usage will automatically be charged at the discounted Savings Plan prices and any usage beyond your commitment will be charged at regular On Demand rates. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do your prices include taxes?", "output": "For details on taxes, please see Amazon Web Services Tax Help. [Source: https://aws.amazon.com/polly/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Amazon GuardDuty Malware Protection work?", "output": "Amazon EBS data volumes: If you have this data source enabled for Malware Protection, GuardDuty begins a malware detection scan when it identifies suspicious behavior indicative of malicious software in AmazonEC2 instance, or container workloads. It scans a replica AmazonEBS volume that GuardDuty generates based on the snapshot of your AmazonEBS volume for trojans, worms, crypto miners, rootkits, bots, and more. GuardDuty Malware Protection generates contextualized findings that can help validate the source of the suspicious behavior. These findings can also be routed to the proper administrators and can initiate automated remediation.S3 object scanning:Once a bucket is configured for malware protection, GuardDuty automatically scans newly uploaded files and, if malware is detected, generates an Amazon EventBridge notification with details about the malware, allowing for integration with existing security event management or workflow systems. You can configure to automatically quarantine malware by moving the object to an isolated bucket in your account, or use object tags to add the disposition of the scan result, allowing to better identify and categorize the scanned objects based on tags. [Source: https://aws.amazon.com/guardduty/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can the Open with Office Online feature be enabled?", "output": "Open with Office Online is available as a feature at no additional cost for all WorkDocs users who also have a valid Microsoft Office 365 \u2018Work\u2019 or \u2018School\u2019 account with a license to use Office Online. WorkDocs administrators can enable this feature in the admin console. Once the capability has been enabled at the site level, users will need to authenticate with Office Online using their Microsoft Office 365 subscription. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What levels of access can I give my users and groups using my Transfer Family web app?", "output": "Web app access controls are driven by S3 Access Grants, which offers three access levels: READ, WRITE, and READWRITE. These access levels permit related authorized actions such as list, upload, download, and copy files. READ allows you to view and retrieve objects from S3. WRITE allows you to write to and delete from S3. READWRITE allows you to do both READ and WRITE. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is an utterance?", "output": "An \u2018utterance\u2019 is the spoken or typed phrase to invoke an intent. For example, to invoke the intent to make reservations, you would provide a sample utterance such as, \u201cCan I make a reservation?\u201d [Source: https://aws.amazon.com/lex/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If I want to use AWS DRS to protect more than 300 source servers, can I recover all of the servers into a single target account?", "output": "Yes, you can recover up to 3,000 servers into a single target account. You can do this by using multiple staging accounts. (AWS DRSsupports up to 300 servers replicating into a single staging account.) [Source: https://aws.amazon.com/disaster-recovery/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What do I have to do to use HIPAA-eligible ElastiCache?", "output": "If you have an executedBusiness Associate Agreement (BAA) (https://aws.amazon.com/compliance/hipaa-compliance/)with AWS, you can use ElastiCache to build applications that store and process HI under HIPAA. If you do not have a BAA, or have other questions about using AWS for your applications,contact us (https://aws.amazon.com/contact-us/)for more information. [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If I continue to use my own Memcached clients with my ElastiCache cluster, will I be able to get this feature?", "output": "Yes, you can stop using Auto Discovery at any time. You can disable Auto Discovery by specifying the mode of operation during the ElastiCache Cluster client initialization. Also, since ElastiCache continues to support Memcached, you can use any Memcached protocol-compliant client as before. [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I pull a public image from Amazon ECR?", "output": "You pull using the familiar \u2018docker pull\u2019 command with the URL of the image. You can easily search for this URL by finding images using a publisher alias, image name, or image description using the Amazon ECR public gallery. Image URLs are in the format public.ecr.aws/<alias>/<image>:<tag>, for example public.ecr.aws/eks/aws-alb-ingress-controller:v1.1.5 [Source: https://aws.amazon.com/ecr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the key benefits of Express brokers?", "output": "No storage management: Express brokers eliminate the need toprovision or manage any storage resources. You get elastic, virtually unlimited, pay-as-you-go, and fully managed storage. For high throughput use cases, you do not need to reason about the interactions between compute instances and storage volumes and the associated throughput bottlenecks. These capabilities simplify cluster management and eliminate storage management operational overhead.Faster scaling: Express brokers allow you to scale your cluster and move partitions faster than on Standard brokers. This capability is crucial when you need to scale out your cluster to handle upcoming load spikes or scale in your cluster to reduce cost. See the sections onexpanding your cluster,removing brokers,reassigning partitions, andsetting up LinkedIns Cruise Control for rebalancingfor more details on scaling your cluster.Higher throughput: Express brokers offer up to 3x more throughput per broker than Standard brokers. For example, you can safely write data at up to 500 MBps with each m7g.16xlarge sized Express broker compared to 153.8 MBps on the equivalent Standard broker (both numbers assume sufficient bandwidth allocation towards background operations, such as replication and rebalancing).Configured for high resilience: Express brokers automatically offer various best practices pre-configured to improve your clusters resilience. These include guardrails on critical Apache Kafka configurations, throughput quotas, and capacity reservation for background operations and unplanned repairs. These capabilities make it safer and easier to run large scale Apache Kafka applications. See the sections onExpress broker configurationsandAmazon MSK Express broker quotafor more details.No Maintenance windows: There are no maintenance windows for Express brokers. Amazon MSK automatically updates your cluster hardware on an ongoing basis. See Amazon MSK Express brokers for more details. [Source: https://aws.amazon.com/msk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I configure my distribution to redirect HTTP requests to HTTPS?", "output": "Lightsail distributions automatically redirect all HTTP requests to HTTPS to ensure that your content is served securely. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I use the streaming capability?", "output": "You can use the streaming API to conduct a continually streaming conversation with a Lex bot. With streaming conversation, the bot continuously listens and can be designed to respond proactively to user interruptions and pauses. For example, you can configure the bot to keep a conversation going when a user needs more time to respond by sending periodic messages such as \u201cTake your time. Let me know once you are ready.\u201d [Source: https://aws.amazon.com/lex/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What kind of performance can I expect from Amazon EBS volumes?", "output": "Amazon EBS provides four current generation volume types that are divided into two major categories: SSD-backed storage for transactional workloads and HDD-backed storage for throughput intensive workloads. These volume types differ in performance characteristics and price, allowing you to tailor your storage performance and cost to the needs of your applications. For more information, see theAmazon EBS overview. For additional information on performance, see theAmazon EC2 User Guide's EBS Performance section. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What can I do with AWS CloudHSM?", "output": "You can use AWS CloudHSM to support a variety of use cases and applications, such as database encryption, Digital Rights Management (DRM), Public Key Infrastructure (PKI), authentication and authorization, document signing, and transaction processing. For more information, seeAWS CloudHSM use cases. (https://docs.aws.amazon.com/cloudhsm/latest/userguide/use-cases.html) [Source: https://aws.amazon.com/cloudhsm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the EC2 instance recommendations feature?", "output": "EC2 instance recommendations is a feature of AWS Migration Hub that analyzes the data collected from each on-premises server, including server specification, CPU, and memory utilization, to recommend the least expensive EC2 instance required to run the on-premises workload. You can also fine-tune recommendations by specifying preferences for AWS purchasing option, AWS Region, EC2 instance type exclusions, and CPU/RAM utilization metric (average, peak, or percentile). [Source: https://aws.amazon.com/migration-hub/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What does the EMR connector to Kinesis enable that I couldn\u2019t have done before?", "output": "Reading and processing data from a Kinesis stream would require you to write, deploy and maintain independent stream processing applications. These take time and effort. However, with this connector, you can start reading and analyzing a Kinesis stream by writing a simple Hive or Pig script. This means you can analyze Kinesis streams using SQL! Of course, other Hadoop ecosystem tools could be used as well. You don\u2019t need to developed or maintain a new set of processing applications. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the database migration steps when using AWS Database Migration Service?", "output": "During a typical simple database migration, you will create a target database, migrate the database schema, set up the data replication process, initiate the full load and a subsequent change data capture and apply, and conclude with a switchover of your production environment to the new database once the target database is caught up with the source database. [Source: https://aws.amazon.com/dms/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are SNS FIFO topics?", "output": "Similar to standard SNS topics,SNS FIFO topicsallow users to publish a message to a topic, so it can be delivered to a series of subscribing endpoints. When the delivery of those messages to subscribers must be in order (first-in-first-out), and once only, and you want SNS to take care of it, SNS FIFO topics is the way to go. Amazon SNS FIFO topics can deliver ordered messages to Amazon Simple Queue Service (Amazon SQS) FIFO queues to provide consistent end-to-end message ordering for distributed applications. You can now reduce the effort required to process your high throughput, consistently ordered transactions and simplify your messaging architecture. When strict ordering is not necessary, Amazon FIFO topics can also deliver messages to Amazon SQS standard queues, offering flexibility in how you design your applications. Example use cases include bank transaction logs, stock tickers, flight trackers, price updates, news broadcasting, and inventory management. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What does it mean to apply a trail to all AWS Regions?", "output": "Applying a trail to all AWS Regions refers to creating a trail that will record AWS account activity across all Regions in which your data is stored. This setting also applies to any new Regions added. For more details on Regions and partitions, refer to theAmazon Resource Names and AWS Service Namespaces page (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html). [Source: https://aws.amazon.com/cloudtrail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which Amazon EC2 instance types does Amazon EMR support?", "output": "See theEMR pricing pagefor details on latest available instance types and pricing per region. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are Amazon EC2 UltraClusters?", "output": "Amazon EC2 UltraClusters can help you scale to thousands of GPUs or purpose-built ML chips, such as AWS Trainium, to get on-demand access to a supercomputer. They democratize access to supercomputing-class performance for machine learning (ML), generative AI, and high-performance computing (HPC) developers through a simple pay-as-you-go usage model without any setup or maintenance costs. For more information, visit theEC2 UltraClusters page. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are my options toencrypt/decryptfiles in transit?", "output": "You can use AWS Transfer Family managed workflows to automatically decrypt files using PGP keys when they are uploaded to your AWS Transfer Family SFTP, FTPS or FTP server endpoints. For more information, refer to managed workflows documentation. Alternatively, you can subscribe to AWS Transfer Family event notifications published in Amazon Eventbridge to orchestrate granular and event-driven processing of transferred files using your own encryption/ decryption logic. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Multi-Factor Authentication (MFA)?", "output": "A: Multi-Factor Authentication adds an additional layer of security during the authentication process. Users must validate their identity by providing something they know (e.g. password), as well as something they have (e.g. hardware or software generated one-time password (OTP). [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can accelerated instances be used for jobs that don't need the accelerators?", "output": "With today's behavior, Batch will avoid scheduling jobs that do not require acceleration on accelerated instances when possible. This is to avoid cases where long-running jobs occupy the accelerated instance without taking advantage of the accelerator, increasing cost. In rare cases with Spot pricing and with accelerated instances as allowed types, it is possible that Batch will determine that an accelerated instance is the least expensive way to run your jobs, regardless of accelerator needs.\nIf you submit a job to a CE that only allows Batch to launch accelerated instances, Batch will run the jobs on those instances, regardless of their accelerator needs. [Source: https://aws.amazon.com/batch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I customize a health check?", "output": "Yes, there is an API called SetInstanceHealth that allows you to change an instance's state to UNHEALTHY, which will then result in a termination and replacement. [Source: https://aws.amazon.com/ec2/autoscaling/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What types of data can I send to Amazon CloudWatch Logs from my EC2 instances running Microsoft SQL Server and Microsoft Windows Server?", "output": "You can configure the EC2Config service to send a variety of data and log files to CloudWatch including: custom text logs, Event (Application, Custom, Security, System) logs, Event Tracing (ETW) logs, and Performance Counter (PCW) data. Learn more about the EC2Config servicehere (https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2config-service.html). [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I change the name of a file share?", "output": "Yes, you can change the name of a file share. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is AWS Storage Gateway Hardware Appliance FIPS 140-2 compliant?", "output": "No, AWS Storage Gateway Hardware Appliance is not FIPS 140-2 compliant. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What metrics can I use to monitor my AWS Lambda ephemeral storage usage?", "output": "You can use AWS CloudWatch Lambda Insight metrics to monitor your ephemeral storage usage. To learn more, see the AWS CloudWatch Lambda Insights documentation. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I optimize my database workload for Amazon Aurora MySQL-Compatible Edition?", "output": "Amazon Aurora is designed to be compatible with MySQL so that existing MySQL applications and tools can run without requiring modification. However,one area where Amazon Aurora improves upon MySQL is with highly concurrent workloads (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Managing.Performance). In order to maximize your workloads throughput on Amazon Aurora, we recommend building your applications to drive a large number of concurrent queries and transactions. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How will I be charged for Amazon EFS for AWS Lambda?", "output": "There is no additional charge for using Amazon EFS for AWS Lambda. Customers pay the standard price for AWS Lambda and for Amazon EFS. When using Lambda and EFS in the same availability zone, customers are not charged for data transfer. However, if they use VPC peering for Cross-Account access, they will incur data transfer charges. To learn more, please see Pricing. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Content Delivery Network (CDN)", "output": "When your web traffic is geo-dispersed, its not always feasible and certainly not cost effective to replicate your entire infrastructure across the globe. ACDN (https://aws.amazon.com/caching/cdn/)provides you the ability to utilize its global network of edge locations to deliver a cached copy of web content such as videos, webpages, images and so on to your customers. To reduce response time, theCDN (https://aws.amazon.com/caching/cdn/)utilizes the nearest edge location to the customer or originating request location in order to reduce the response time. Throughput is dramatically increased given that the web assets are delivered from cache. For dynamic data, manyCDNs (https://aws.amazon.com/caching/cdn/)can be configured to retrieve data from the origin servers.Amazon CloudFront (https://aws.amazon.com/cloudfront/)is a global CDN service that accelerates delivery of your websites, APIs, video content or other web assets. It integrates with other Amazon Web Services products to give developers and businesses an easy way to accelerate content to end users with no minimum usage commitments. To learn more about CDNs,click here (https://aws.amazon.com/caching/cdn/). [Source: https://aws.amazon.com/caching/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What performance does S3 Standard-IA offer?", "output": "S3 Standard-IA provides the same milliseconds latency and high throughput performance as the S3 Standard storage class. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is AWS Certificate Manager?", "output": "AWS Certificate Manager (ACM) is a service that lets you easily provision, manage, and deploy public and private Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificates for use with AWS services and your internal connected resources. SSL/TLS certificates are used to secure network communications and establish the identity of websites over the Internet as well as resources on private networks. ACM removes the time-consuming manual process of purchasing, uploading, and renewing SSL/TLS certificates. With AWS Certificate Manager, you can quickly request a certificate, deploy it on AWS resources such as Elastic Load Balancers, Amazon CloudFront distributions, and APIs on API Gateway, and let ACM handle certificate renewals. It also enables you to create private certificates for your internal resources and manage the certificate lifecycle centrally. Public and private SSL/TLS certificates provisioned through ACM and used exclusively with ACM-integrated services, such as Elastic Load Balancing, Amazon CloudFront, and Amazon API Gateway, are free. You pay for the AWS resources you create to run your application. You pay a monthly fee for the operation of each private CA until you delete it, and for the private certificates you issue that are not used exclusively withACM-integrated services (https://docs.aws.amazon.com/acm/latest/userguide/acm-services.html). [Source: https://aws.amazon.com/certificate-manager/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Where do I find all my workspaces in EMR Studio?", "output": "In EMR Studio, you may chooseWorkspacestab on the left and view all workspaces created by you and other users in the same AWS account. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What clients can I use to access Amazon WorkMail?", "output": "You can access Amazon WorkMail from Microsoft Outlook clients on Windows and Mac OS X, and on mobile devices that support the Microsoft Exchange ActiveSync protocol including iPhone, iPad, Kindle Fire, Fire Phone, Android, Windows Phone, and BlackBerry 10. Additionally, you can use the Apple Mail application on Mac OS X or the Amazon WorkMail web application to securely access Amazon WorkMail using your web browser. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the retention status of the replicas of source objects protected with S3 Object Lock?", "output": "The replicas of objects protected with S3 Object Lock follow the same retention policy as the source objects. You can use the GET Object or HEAD Object commands to view the Object Lock status of the replica objects. Both commands return theRetention mode,Retain until date, and the legal hold status for the specified object version. You can also configure Amazon S3 Inventory reports on your buckets to include theRetain until date,Retention mode, and legal hold status for all objects in a bucket. For more information see the documentation onviewing the S3 Object Lock information for an objectandconfiguring Amazon S3 Inventory. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started using Amazon ECR?", "output": "The best way to get started with Amazon ECR is to use the Docker CLI to push and pull your first image. Visit our\u00a0Getting Started\u00a0page for more information. [Source: https://aws.amazon.com/ecr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I replicate existing objects from S3 Object Lock enabled buckets?", "output": "You can use S3 Batch Replication to replicate existing objects from S3 Object Lock enabled buckets. For more information on replicating existing objects, see the documentation onS3 Batch Replication. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can multiple users collaboratively edit a file?", "output": "The editing session starts with a user editing the file. When other users view the same file, they will see a Live Edit icon that they can click to join the collaborative editing session assuming they have the right permissions (owner, co-owner, contributor) for the file. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I share an encrypted Amazon DocumentDB snapshot?", "output": "Yes. You can shareencrypted Amazon DocumentDB snapshots (https://docs.aws.amazon.com/documentdb/latest/developerguide/encryption-at-rest.html). The recipient of the shared snapshot must have access to the KMS key that was used to encrypt the snapshot. [Source: https://aws.amazon.com/documentdb/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How long does it take for emails sent using Amazon SES to arrive in recipients' inboxes?", "output": "Amazon SES attempts to deliver emails to the Internet within a few seconds of each request. However, due to a number of factors and the inherent uncertainties of the Internet, we can't predict with certainty when your email will arrive, nor can we predict the exact route the message will take to get to its destination. \nFor example, an ISP might be unable to deliver the email to the recipient because of a temporary condition such as \"mailbox full.\" In these cases, Amazon attempts to redeliver the message. If the error is permanent, such as \"mailbox does not exist,\" Amazon SES doesn't try to deliver the message again, and you receive a hard bounce notification. You can set up delivery notifications to alert you when Amazon SES successfully delivers one of your emails to a recipient's mail server. [Source: https://aws.amazon.com/ses/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Amazon EKS Service Level Agreement (SLA)?", "output": "The Amazon EKS SLA can be found\u00a0here. [Source: https://aws.amazon.com/eks/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does my T2 instance credit balance persist at stop / start?", "output": "No, a stopped instance does not retain its previously earned credit balance. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What guidance should I use to provision the size of the gateways cache disk? What happens if I provision a smaller cache disk?", "output": "You should provision your cache based on:1/ The size of your working dataset to which you need low-latency access, so you can reduce read latencies by decreasing the frequency with which data is requested from S3, and2/ The size of files written to the gateway by your applications.Smaller cache disks can result in poor performance and failures during writes if there is no free cache space to store data locally when pending upload to S3. To learn more about monitoring your cache usage, refer toMonitoring Your File Share (https://docs.aws.amazon.com/filegateway/latest/files3/monitoring-file-gateway.html#monitoring-file-gateway-resources)in the documentation. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does WorkMail offer message tracking?", "output": "Yes, WorkMail offers the option to enable WorkMail Monitoring in CloudWatch logs. When activating logging, you can define the CloudWatch log group to log into, as well as the log retention period. WorkMail will then log detailed information for messages received and sent, when rules are applied, when message journaling is initiated, and for bounce messages. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Amazon FSx enable me to protect my data?", "output": "Beyond automatically replicating your file system's data to ensure high durability, Amazon FSx provides you with two options to further protect the data stored on your file systems: Windows shadow copies to enable your end-users to easily undo file changes and compare file versions by restoring files to previous versions, and backups to support your backup retention and compliance needs. [Source: https://aws.amazon.com/fsx/windows/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Where can I find more information about API limits and latency?", "output": "Please refer toAmazon Rekognition PPE detection documentationto get the latest details on API limits and latency. [Source: https://aws.amazon.com/rekognition/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will I see an availability event in CloudWatch when a gateway restart occurs?", "output": "Yes, if you have configured the integration with CloudWatch, availability events triggered from the gateway will be available through CloudWatch. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Where can I find more information about security and running applications on AWS?", "output": "For more information about security on AWS, please refer to our Amazon Web Services: Overview of Security Processes document and visit our Security Center. [Source: https://aws.amazon.com/elasticbeanstalk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I see which Spot fleet owns my Spot Instances?", "output": "You can identify the Spot Instances associated with your Spot Fleet by describing your fleet request. Fleet requests are available for 48 hours after all its Spot Instances have been terminated. See theAmazon EC2 User Guideto learn how to describe your Spot Fleet request. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens when I \u2018build\u2019 a bot?", "output": "Building a bot triggers machine learning and creates the models for your bot. A new version of your intents and slot types is created. Once created a version is immutable. [Source: https://aws.amazon.com/lex/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why would I use AWS Outposts rack instead of operating in an AWS Region?", "output": "You can use Outposts rack to support your applications that have low latency or local data processing requirements. These applications may need to generate near real-time responses to end user applications or need to communicate with other on-premises systems or control on-site equipment. These can include workloads running on factory floors for automated operations in manufacturing, real-time patient diagnosis or medical imaging, and content and media streaming.You can use Outposts rack to securely store and process customer data that needs to remain on premises or in countries where there is no AWS Region. You can run data intensive workloads on Outposts rack and process data locally when transmitting data to AWS Regions is expensive and wasteful and for better control on data analysis, backup and restore. [Source: https://aws.amazon.com/outposts/rack/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use the same ACM certificate in more than one AWS Region?", "output": "No. ACM certificates must be in the same Region as the resource where they are being used. The only exception is Amazon CloudFront, a global service that requires certificates in the US East (N. Virginia) region. ACM certificates in this region that are associated with a CloudFront distribution are distributed to all the geographic locations configured for that distribution. [Source: https://aws.amazon.com/certificate-manager/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What kind of replicas does Aurora support?", "output": "Amazon Aurora MySQL-Compatible Edition and Amazon Aurora PostgreSQL-Compatible Edition supportAmazon Aurora replicas (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication), which share the same underlying volume as the primary instance in the same AWS region. Updates made by the primary are visible to all Amazon Aurora Replicas.With Amazon Aurora MySQL-Compatible Edition, you can also create cross-region MySQL Read Replicas based on MySQLs binlog-based replication engine. In MySQLRead Replicas (https://aws.amazon.com/rds/features/read-replicas/), data from your primary instance is replayed on your replica as transactions. For most use cases, including read scaling and high availability, we recommend using Amazon Aurora Replicas.You have the flexibility to mix and match these two replica types based on your application needs:FeatureAmazon Aurora ReplicasMySQL ReplicasNumber of replicasUp to 15Up to 5Replication typeAsynchronous (milliseconds)Asynchronous (seconds)Performance impact on primaryLowHighReplica locationIn-regionCross-regionAct as failover targetYes (no data loss)Yes (potentially minutes of data loss)Automated failoverYesNoSupport for user-defined replication delayNoYesSupport for different data or schema vs. primaryNoYesYou have two additional replication options in addition to the ones listed above. You can useAmazon Global Database (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database)for much faster physical replication between Aurora clusters in different regions. And for replication between Aurora and non-Aurora MySQL-Compatible Edition databases (even outside of AWS), you can set up your own, self-managed binlog replication. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Who should use AWS CodeCommit?", "output": "AWS CodeCommit is designed for software developers who need a secure, reliable, and scalable source control system to store and version their code. In addition, AWS CodeCommit can be used by anyone looking for an easy to use, fully managed data store that is version controlled. For example, IT administrators can use AWS CodeCommit to store their scripts and configurations. Web designers can use AWS CodeCommit to store HTML pages and images. [Source: https://aws.amazon.com/codecommit/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I set up email redirect rules on Amazon WorkMail?", "output": "Yes, you can configure email redirection rules for Amazon WorkMail mailboxes. You can setup email redirection rules on your desktop email application, such as Microsoft Outlook, or using the Amazon WorkMail web application. You will need to ensure that the Amazon Simple Email Service (Amazon SES) identity policies for your domains are up-to-date to take advantage of email redirection rules. Please visitthis pagefor more information on how to update the Amazon SES identity policy for your domain. [Source: https://aws.amazon.com/workmail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is WebRTC and how does Kinesis Video Streams support this capability?", "output": "WebRTC is an open technology specification for enabling real-time communication (RTC) across browsers and mobile applications via simple APIs. It leverages peering techniques for real-time data exchange between connected peers and provides low media streaming latency required for human-to-human interaction. WebRTC specification includes a set of IETF protocols including Interactive Connectivity Establishment (ICERFC5245 (https://www.ietf.org/rfc/rfc5245.txt)), Traversal Using Relay around NAT (TURNRFC5766 (https://tools.ietf.org/html/rfc5766)), and Session Traversal Utilities for NAT (STUNRFC5389 (http://www.ietf.org/rfc/rfc5389.txt)) for establishing peer-to-peer connectivity, in addition to protocol specifications for real-time media and data streaming. Kinesis Video Streams provides a standards compliant WebRTC implementation, as a fully-managed capability. You can use this capability to securely live stream media or perform two-way audio or video interaction between any camera IoT device and WebRTC compliant mobile or web players. As a fully-managed capability, you do not have to build, operate, or scale any WebRTC related cloud infrastructure such as signaling or media relay servers to securely stream media across applications and devices. [Source: https://aws.amazon.com/kinesis/video-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I use an AWS Lambda function to respond to Amazon CloudWatch alarms?", "output": "First, configure the alarm to send Amazon SNS notifications. Then from the AWS Lambda console, select a Lambda function and associate it with that Amazon SNS topic. See the Amazon CloudWatch Developer Guide for more on setting up Amazon CloudWatch alarms. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What level of performance latency can I expect to see from my General Purpose SSD (gp3 and gp2) volumes?", "output": "When attached to EBS-optimized instances, General Purpose SSD (gp3 and gp2) volumes can achieve single digit millisecond latencies. Your exact performance depends on your application\u2019s I/O requirements. [Source: https://aws.amazon.com/ebs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I test, analyze, or debug my executions?", "output": "You can use the TestState API to test a single step of your workflow, enabling faster feedback cycles to accelerate development. The TestState enables you to call services and endpoints directly, modify the input to mimic different scenarios, and review the response. You can access the TestState through Workflow Studio, making it easy to test as you build without the need to deploy your workflow. TestState accepts a single state definition and input, then synchronously returns the state output along with intermediate data transformations. After you run your workflow, you can analyze and debug executions through Amazon CloudWatch Logs, AWS X-Ray, and directly in the Step functions console through a visual operator experience that helps you quickly identify problem areas. [Source: https://aws.amazon.com/step-functions/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is Neptune Database ACID (Atomicity, Consistency, Isolation, Durability) compliant?", "output": "Yes, Neptune is ACID compliant with immediate consistency on the primary writer instance, and eventual consistency on the read replica instances. [Source: https://aws.amazon.com/neptune/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are S3 object tags?", "output": "S3 object tags are key-value pairs applied to S3 objects that can be created, updated, or deleted at any time during the lifetime of the object. With these, you have the ability to create AWS Identity and Access Management (IAM) policies, set up Amazon S3 Lifecycle policies, and customize storage metrics. These object-level tags can then manage transitions between storage classes and expire objects in the background. You can add tags to new objects when you upload them or add them to existing objects. Up to ten tags can be added to each S3 object, and you can use either the AWS Management Console, REST API, AWS CLI, or AWS SDKs to add object tags. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How many Availability Zones are Amazon S3 Express One Zone objects stored in?", "output": "S3 Express One Zone objects are stored in a single AWS Availability Zone (AZ) that you choose. Storing objects in one zone gives you the ability to store your data local to your compute to minimize latency. You can access data from across Availability Zones, although latency will increase. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the release cadence of macOS AMIs?", "output": "We make new macOS AMIs available on a best effort basis. You can subscribe to SNS notifications for updates. We are targeting 30-60 days after a macOS minor version update and 90-120 days after a macOS major version update to release official macOS AMIs. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I invoke an AWS Lambda function over HTTPS?", "output": "You can invoke a Lambda function over HTTPS by defining a custom RESTful API using Amazon API Gateway. This gives you an endpoint for your function which can respond to REST calls like GET, PUT, and POST. Read more about using AWS Lambda with Amazon API Gateway. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I view historical logs with Live Tail?", "output": "No, Live Tail provides real-time view of the logs data collected by CloudWatch. For historical logs, refer to Logs Insights and Log Groups features. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I encrypt communication between my applications and AWS Managed Microsoft AD using LDAPS?", "output": "Yes. AWS Managed Microsoft AD supports Lightweight Directory Access Protocol (LDAP) over Secure Socket Layer (SSL) / Transport Layer Security (TLS), also known as LDAPS, in both client and server roles. When acting as a server, AWS Managed Microsoft AD supports LDAPS over ports 636 (SSL) and 389 (TLS). You enable server-side LDAPS communication by installing a certificate on your AWS Managed Microsoft AD domain controllers from an AWS-based Active Directory Certificate Services certificate authority (CA). To learn more, seeEnable Secure LDAP (LDAPS) (https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_ldap.html). [Source: https://aws.amazon.com/directoryservice/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon Cognito add authentication services to applications through AWS SDKs?", "output": "Yes, Cognito user pools and identity pools have API operations for authentication in AWS SDKs. You can create your own custom-built application with AWS SDK components that programmatically authenticate users through API requests. Cognito user pools have separate API operations designed for server-side and client-side applications. You can learn more about API authentication with Amazon Cognito in the Developer Guide and the API Reference. [Source: https://aws.amazon.com/cognito/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I set up my EFS file system to work with AWS Transfer Family?", "output": "Prior to setting up AWS Transfer Family to work with an Amazon EFS file system, you will need to set up ownership of files and folders using the same POSIX identities (user id/group id) you plan to assign to your AWS Transfer Family users. Additionally, if you are accessing file systems in a different account, resource policies must also be configured on your file system to enable cross account access.Refer to thisblog post (https://aws.amazon.com/blogs/aws/new-aws-transfer-family-support-for-amazon-elastic-file-system/)for step-by-step instructions on using AWS Transfer Family with EFS. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I estimate my RDS Extended Support charges?", "output": "You can estimate your Extended Support charges using theAWS Pricing Calculator (https://calculator.aws/#/). Amazon RDS Extended Support charges depend on three factors: 1. number of vCPUs or ACUs running on the instance, 2. AWS Region, and 3. number of years past end of standard support.To estimate your charges,determine the number of vCPUs on your instance (https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html#Concepts.DBInstanceClass.Summary.)and the appropriate calendar year pricing for your engine version. If your version is within the year 1-2 pricing and you are using provisioned instances, you will be charged#vCPUs x Year 1 and Year 2 pricing per hour of usage for your chosen Region. If your version is on year 3 pricing and you are using provisioned instances, you will be charged#vCPUs x Year 3 pricing per hour of usage for your chosen Region.For example, if you are running a Aurora MySQL-Compatible 2 db.r5.large instance in N. Virginia on December 30, 2024, which is within the first year of RDS Extended Support, you will be charged $0.200 per hour, or 2 vCPUs x $0.100 per vCPU-hr. [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I customize the look of my Transfer Family web app?", "output": "Yes. You can customize the web portal by updating a company logo, favicon, and page title in the AWS Transfer Family console or using the AWS CLI or API. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How much data can I store in Amazon S3?", "output": "The total volume of data and number of objects you can store in Amazon S3 are unlimited. Individual Amazon S3 objects can range in size from a minimum of 0 bytes to a maximum of 5 TB. The largest object that can be uploaded in a single PUT is 5 GB. For objects larger than 100 MB, customers should consider using themultipart uploadcapability. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use Amazon WorkDocs Companion with multiple WorkDocs sites?", "output": "Yes, Amazon WorkDocs Companion can be used with multiple WorkDocs sites on your computer. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How long are deleted folders and files retained?", "output": "Deleted folders and files are moved to the Recycle Bin and are kept there for 30 days so they can be recovered if needed. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I control which operations my users are allowed to perform?", "output": "Yes. You can enable/disable file operations using the AWS IAM role you have mapped to their username. Refer to the documentation onCreating IAM Policies and Roles to control your end users (https://docs.aws.amazon.com/transfer/latest/userguide/requirements-roles.html)access [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Amazon CloudWatch Application Signals?", "output": "Amazon CloudWatch Application Signals extends Amazon CloudWatch with standardized application metrics and application-centric observability views in the AWS Management Console for CloudWatch. You can get started without writing custom instrumentation. The new views summarize application health to help determine business impact and prioritize, then offer a drill down to expediently establish root cause.When customers opt into the Application Signals with complete visibility into application transaction spans, you can access a powerful new search and analytics experience at any scale. This comprehensive solution goes beyond sampling, enabling quick connections between transaction-related business impact and application performance. With out-of-the-box analytics and visualization capabilities, CloudWatch delivers instant insights into overall application transaction health and performance. This feature empowers teams to efficiently monitor, troubleshoot, and optimize their applications with ease. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I replace or remove an access point from a bucket?", "output": "Yes. When you remove an access point, any access to the associated bucket through other access points, and through the bucket hostname, will not be disrupted. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I develop my ETL code using my own IDE?", "output": "You can create and connect to development endpoints that offer ways to connect your notebooks and IDEs. [Source: https://aws.amazon.com/glue/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is WebSocket routing in Amazon API Gateway?", "output": "WebSocket routing in Amazon API Gateway is used to correctly route the messages to a specific integration. You specify a routing key and integration backend to invoke when defining your WebSocket API. The routing key is an attribute in the message body. A default integration can also be set for non-matching routing keys. Refer todocumentation (https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-websocket-api-routes.htm)to learn more about routing. [Source: https://aws.amazon.com/api-gateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How is Aurora PostgreSQL Limitless Database different from existing Aurora scaling features?", "output": "There are two existing features for scaling:Amazon Aurora Auto Scaling with Aurora Replicas (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html)and Aurora Serverless v2.Aurora Replicas (https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html#Aurora.Replication.Replicas)allow you to increase the read capacity of your Aurora cluster beyond the limits of what a single database instance can provide. Applications that can separate their read workload from their write workload can benefit from up to 15 read replicas to achieve higher overall read throughput. Aurora Replicas do not require the application to horizontally split their data. All data is available in every replica. Aurora Replicas do not increase the storage capacity of an Aurora cluster or write throughput.Aurora Serverless v2 (https://aws.amazon.com/rds/aurora/serverless/)is an on-demand, vertical scaling configuration for Aurora that provides automatic scaling of database compute and memory based on application needs within the capacity constraints of a single compute instance. Aurora Serverless v2 is supported for both writer and reader instances. However, it does not increase the storage capacity of an Aurora cluster. If your application is designed to scale horizontally, Aurora PostgreSQL Limitless Database lets you scale the write throughput and storage capacity of your database beyond the limits of a single Aurora writer instance [Source: https://aws.amazon.com/rds/aurora/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is Auto Scaling available for multi-session fleets?", "output": "Yes, Auto Scaling is available for multi-session fleets. Admins can configure the auto scaling policies based on the number of user sessions required and service will calculate the appropriate number of AppStream 2.0 instances to be provisioned based on the maximum number of user sessions per instance configured for the fleet. [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is an annotation?", "output": "An X-Ray annotation is system-defined or user-defined data associated with a segment. A segment can contain multiple annotations. System-defined annotations include data added to the segment by AWS services, whereas user-defined annotations are metadata added to a segment by a developer. For example, a segment created by your application can automatically be injected with region data for AWS service calls, whereas you might choose to add region data yourself for calls made to non-AWS services. [Source: https://aws.amazon.com/xray/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I enable Enhanced Networking on supported instances?", "output": "In order to enable this feature, you must launch an HVM AMI with the appropriate drivers. The instances listed ascurrent generationuse ENA for enhanced networking. Amazon Linux AMI includes both of these drivers by default. For AMIs that do not contain these drivers, you will need to download and install the appropriate drivers based on the instance types you plan to use. You can use Linux or Windows instructions to enable Enhanced Networking in AMIs that do not include the SR-IOV driver by default. Enhanced Networking is only supported in Amazon VPC. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How should I plan my migration to AWS CloudHSM?", "output": "Start by ensuring that the algorithms and modes you require aresupported by AWS CloudHSM (https://docs.aws.amazon.com/cloudhsm/latest/userguide/pkcs11-library.html). Your account manager can submit feature requests to us if needed. Next, determine your key rotation strategy. We have also published an in-depthmigration guide for AWS CloudHSM (https://s3.amazonaws.com/cloudhsmv2-software/CloudHsmClient/Docs/CloudHSMUpgradeGuide-latest.pdf). You're now ready toget started (https://docs.aws.amazon.com/cloudhsm/latest/userguide/getting-started.html)with AWS CloudHSM. [Source: https://aws.amazon.com/cloudhsm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use Amazon S3 File Gateway with Amazon S3 Transfer Acceleration?", "output": "File Gateway will not use the accelerated endpoints even if your bucket is configured for S3 Transfer Acceleration. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why should I use S3 Access Grants?", "output": "You should use S3 Access Grants if your S3 data is shared and accessed by many users and applications, where some of their identities are in your corporate directory such as Okta or Entra ID, and you need a scalable, simple, and auditable way to grant access to these S3 datasets at scale. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the software license for FreeRTOS LTS?", "output": "FreeRTOS LTS libraries are distributed free under the MIT open source license. [Source: https://aws.amazon.com/freertos/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When should I use AWS Glue versus AWS Batch?", "output": "UseAWS Batchto\u00a0 efficiently run any batch computing job on AWS, regardless of the nature of the job. AWS Batch creates and manages the compute resources in your AWS account, giving you full control and visibility into the resources being used. [Source: https://aws.amazon.com/glue/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does AWS Config record configuration changes that did not result from API activity on that resource?", "output": "Yes, AWS Config will regularly scan the configuration of resources for changes that havent yet been recorded and record these changes. CIs recorded from these scans will not have a relatedEvent field in the message, and only the latest state that is different from state already recorded is selected. [Source: https://aws.amazon.com/config/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get technical support for AWS IoT Device Tester for AWS IoT Greengrass?", "output": "Use any of the following channels to get support:AWS Forum for AWS IoT Greengrass (https://forums.aws.amazon.com/forum.jspa?forumID=254)Premium Support (https://aws.amazon.com/premiumsupport/)Customer Support (https://aws.amazon.com/contact-us/) [Source: https://aws.amazon.com/greengrass/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the Lightsail service quotas?", "output": "For the latest Lightsail service quotas, including which quotas can be increased, see the Lightsail service quotas in the AWS General Reference. If you need to increase a quota, please open a case with customer service. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do I need a credit card to access the free trial?", "output": "No.Downloadthe app, sign up, and start using Amazon Chime. [Source: https://aws.amazon.com/chime/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If my AWS account has already accepted an Account NZNDB Addendum, can I accept the Organizations NZNDB Addendum so that all of my AWS accounts are covered?", "output": "Yes, using themanagement account of your organization you can use the Organization agreements tab in AWS Artifact Agreements to accept an NZNDB Addendum on behalf of all existing and future member accounts in your organization. When both the account NZNDB Addendum and organizations NZNDB Addendum are accepted, the organizations NZNDB Addendum will apply instead of the account NZNDB Addendum. [Source: https://aws.amazon.com/artifact/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is there a minimum storage duration for EFS\u2019s cost-optimized storage classes, EFS IA and EFS Archive?", "output": "EFS IA has no minimum storage duration. Data that is tiered to EFS Archive has a minimum storage duration of 90 days. Files deleted or truncated prior to the minimum duration will incur a pro-rated charge for the remaining days, based on the size of the file prior to the corresponding action. [Source: https://aws.amazon.com/efs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I choose different versions while deploying to different messaging services?", "output": "Yes. You can deploy a specific version to each messaging service. Every version of Amazon Lex will have an ARN. Each version can be associated with an alias. You can use different aliases for deployment to different messaging service. Also, you can have multiple bots deployed to the same messaging service. [Source: https://aws.amazon.com/lex/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do Savings Plans and Reserved Instances (RI) discounts apply to EC2 Capacity Blocks?", "output": "No, EC2 Capacity Blocks are not covered by Savings Plans or RI discounts. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Auto Discovery work?", "output": "An ElastiCache cluster can be created with nodes that are addressable through named endpoints. With Auto Discovery the ElastiCache cluster is also given a unique configuration endpoint, which is a DNS Record that is valid for the lifetime of the cluster. This DNS Record contains the DNS Names of the nodes that belong to the cluster. ElastiCache will ensure that the configuration endpoint always points to at least one such target node. A query to the target node then returns endpoints for all the nodes of the cluster in question. After this, you can connect to the cluster nodes just as before and use the Memcached protocol commands such as get, set, incr, and decr. For more details, seethe documentation (https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/AutoDiscovery.Using.html). To use Auto Discovery, you will need a client capable of Auto Discovery. Auto Discovery clients for .Net , Java and PHP are available for download from theElastiCache console (https://console.aws.amazon.com/elasticache/). Upon initialization, the client will automatically determine the current members of the ElastiCache cluster using the configuration endpoint. When you make changes to your cache cluster by adding or removing nodes, or if a node is replaced upon failure, the Auto Discovery client automatically determines the changes, and you do not need to initialize your clients manually. [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does S3 Storage Lens work?", "output": "S3 Storage Lens aggregates your storage usage and activity metrics on a daily basis to be visualized in the S3 Storage Lens interactive dashboard, or available as a metrics export in CSV or Parquet file format. A default dashboard is created for you automatically at the account level, and you have the option to create additional custom dashboards. S3 Storage Lens dashboards can be scoped to your AWS organization or specific accounts, Regions, buckets, or even prefix level (available with S3 Storage Lens advanced metrics). You can also use S3 Storage Lens groups to aggregate metrics using custom filters based on object metadata like object tag, size, and age. While configuring your dashboard you can use the default metrics selection, or upgrade to receive 35 additional metrics and prefix-level aggregations for an additional cost. Also, S3 Storage Lens provides recommendations contextually with storage metrics in the dashboard, so you can take action to optimize your storage based on the metrics. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I create custom images for Amazon WorkSpaces?", "output": "A: Yes, as an administrator you can create a custom image from a running WorkSpace. Once you have customized your WorkSpace with your applications and settings, select the WorkSpace in the console and select \u201cCreate Image.\u201d This creates an image with your applications and settings. Most WorkSpace images are available within 45 minutes. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How much does Predictive Scaling cost?", "output": "As with other Auto Scaling features, Predictive Scaling is free to use. You pay for the resources being utilized for running your applications. [Source: https://aws.amazon.com/autoscaling/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the Amazon S3 Express One Zone storage class?", "output": "Amazon S3 Express One Zone is a high-performance,\u00a0single-Availability Zone Amazon S3 storage class purpose-built to deliver consistent single-digit millisecond data access for customers\u2019 most latency-sensitive applications. Amazon S3 Express One Zone is the lowest latency cloud object storage class available today, with data access speed up to 10x faster and with request costs 50% lower than Amazon S3 Standard.\u00a0With S3 Express One Zone, you can select a specific AWS Availability Zone within an AWS Region to store your data. You can choose to co-locate your storage and compute resources in the same Availability Zone to further optimize performance. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is Origin Shield resilient and highly available?", "output": "Yes. All Origin Shield Regions are built using a highly-available architecture that spans several Availability Zones with fleets of auto-scaling Amazon EC2 instances. Connections from CloudFront locations to Origin Shield also use active error tracking for each request to automatically route the request to a secondary Origin Shield location if the primary Origin Shield location is unavailable. [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is the EMR Serverless cost comparable to Amazon EMR on EC2 Spot Instances?", "output": "It depends on your current EMR on EC2 cluster utilization. If you are running EMR clusters using EC2 On-Demand Instances, EMR Serverless will offer a lower total cost of ownership (TCO) if your current cluster utilization is less than 70%. If you are using the EC2 Savings Plans, EMR Serverless will offer a lower TCO if your current cluster utilization is less than 50%. And if you use EC2 Spot Instances, Amazon EMR on EC2 and Amazon EMR on EKS will continue to be more cost effective. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which operating systems/AMIs are supported on A1 Instances?", "output": "The following AMIs are supported on A1 instances: Amazon Linux 2, Ubuntu 16.04.4 or newer, Red Hat Enterprise Linux (RHEL) 7.6 or newer, SUSE Linux Enterprise Server 15 or newer. Additional AMI support for Fedora, Debian, NGINX Plus are also available through community AMIs and the AWS Marketplace. EBS backed HVM AMIs launched on A1 instances require NVMe and ENA drivers installed at instance launch. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is my data transfer plan allowance?", "output": "Every single Lightsail plan also includes a healthy amount of free IN and OUT data transfer. For example, using the cheapest Lightsail instance bundle you can send and receive up to 1 TB of data to the Internet within the month, at no extra charge. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Should I run one large cluster, and share it amongst many users or many smaller clusters?", "output": "Amazon EMR provides a unique capability for you to use both methods. On the one hand one large cluster may be more efficient for processing regular batch workloads. On the other hand, if you require ad-hoc querying or workloads that vary with time, you may choose to create several separate cluster tuned to the specific task sharing data sources stored in Amazon S3.\u00a0You can use EMR Managed Scaling to optimize resource usage. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can multiple users run queries on the same cluster?", "output": "Yes. In the batch mode, steps are serialized. Multiple users can add Hive steps to the same cluster; however, the steps will be executed serially. In interactive mode, several users can be logged on to the same cluster and execute Hive statements concurrently. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I use AWS Cloud9 with AWS CodeStar?", "output": "You can launch AWS Cloud9 environments directly from AWS CodeStar and immediately start editing and committing your CodeStar project code in the Cloud9 IDE. Any code changes that you commit to your project source repository from Cloud9 are automatically built and deployed using the tools provisioned by CodeStar. To learn more about using this integration, please visit theAWS CodeStar documentation (https://docs.aws.amazon.com/console/codestar/cloud9). [Source: https://aws.amazon.com/cloud9/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is there a I should expect from metrics that are generated by Amazon WorkSpaces?", "output": "A: Yes. WorkSpaces sends metrics to CloudWatch every 5 minutes, with at least a delay of 15 minutes for Always On instances. If an Auto Stop WorkSpaces instance stops before this time, the generated metrics will be sent to CloudWatch as soon as that instance comes back on. So, Auto Stop WorkSpaces instances may take more time to be delivered. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What type of storage is available with Amazon MQ for ActiveMQ?", "output": "Amazon MQ for ActiveMQ supports two types of broker storage  durability optimized usingAmazon Elastic File System (https://aws.amazon.com/efs/)(Amazon EFS) and throughput optimized usingAmazon Elastic Block Store (https://aws.amazon.com/ebs/)(EBS). To take advantage of high durability and replication across multiple Availability Zones, use durability optimized brokers backed by Amazon EFS. To take advantage of high throughput for your high-volume applications, use throughput optimized brokers backed by EBS. [Source: https://aws.amazon.com/amazon-mq/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What should I be aware of before getting started with the Kinesis Video Streams producer SDK?", "output": "The Kinesis Video Streams producer SDK does all the heavy lifting of packaging frames and fragments, establishes a secure connection, and reliably streams video to AWS. However there are many different varieties of hardware devices and media pipelines running on them. To make the process of integration with the media pipeline easier, we recommend having some knowledge of: 1) the frame boundaries, 2) the type of a frame used for the boundaries, I-frame or non I-frame, and 3) the frame encoding time stamp. [Source: https://aws.amazon.com/kinesis/video-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Are there any Amazon CloudFront features that will not work with IPv6?", "output": "All existing features of Amazon CloudFront will continue to work on IPv6, though there are two changes you may need for internal IPv6 address processing before you turn on IPv6 for your distributions.If you have turned on theAmazon CloudFront Access Logs feature (https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#BasicDistributionFileFormat), you will start seeing your viewers IPv6 address in the c-ip field and may need to verify that your log processing systems continue to work for IPv6.When you enable IPv6 for your Amazon CloudFront distribution, you will get IPv6 addresses in the X-Forwarded-For (http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/RequestAndResponseBehaviorS3Origin.html#RequestS3IPAddresses) header that is sent to your origins. If your origin systems are only able to process IPv4 addresses, you may need to verify that your origin systems continue to work for IPv6.Additionally, if you use IP whitelists for Trusted Signers, you should use an IPv4-only distribution for your Trusted Signer URLs with IP whitelists and an IPv4 / IPv6 distribution for all other content. This model sidesteps an issue that would arise if the signing request arrived over an IPv4 address and was signed as such, only to have the request for the content arrive via a different IPv6 address that is not on the whitelist.To learn more about IPv6 support in Amazon CloudFront, see IPv6 support on Amazon CloudFront (http://docs.aws.amazon.com/console/cloudfront/ipv6) in the Amazon CloudFront Developer Guide. [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I get started with CloudWatch RUM?", "output": "Create an app monitor in CloudWatch RUM and add the lightweight web client in the HTML header of your application. Then start using CloudWatch RUMs dashboards to receive user insights from different geolocations, devices, platforms, and browsers. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I remove a user\u2019s access to their WorkSpace?", "output": "A: To remove a user\u2019s access to their WorkSpace, you can disable their account either in the directory managed by the WorkSpaces service, or in an existing Active Directory that you have integrated the WorkSpaces service with. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do you support PromQL as a query language?", "output": "No. All metrics are ingested as CloudWatch Logs events and can be queried using CloudWatch Logs Insights queries. For more information, see thedocumentation on CloudWatch Logs Insights search language syntax (https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html). [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started with Redshift auto-copy?", "output": "<p>To get started, customers should have an Amazon S3 folder, which can be accessed by their Redshift cluster/serverless endpoint using associated IAM roles, and create a Redshift table to be used as a target. Once an Amazon S3 path and the Redshift table are ready, customers can create a copy job by using the copy command. Once the copy job is created, Redshift starts tracking the specified Amazon S3 path behind the scenes and initiates the user defined copy statements to automatically copy new files into the target table.</p> [Source: https://aws.amazon.com/redshift/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which Zero Client configurations are compatible with the IP Based Access Controls feature?", "output": "A: Zero Clients using MFA can be used with IP Based Access Controls, along with any compatible Zero Clients which do not use PCoIP Connection Manager to connect to WorkSpaces. Any connections through PCoIP Connection Manager will not be able to access WorkSpaces if IP Based Access Controls are enabled. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What alarms can I set on my storage metrics?", "output": "You can use CloudWatch to set thresholds on any of the storage metrics counts, timers, or rates and trigger an action when the threshold is breached. For example, you can set a threshold on the percentage of 4xx Error Responses and when at least three data points are above the threshold trigger a CloudWatch alarm to alert a DevOps engineer. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I migrate my existing file data into an Amazon FSx file system?", "output": "If youd like to migrate your existing files to Amazon FSx for Windows File Server file systems, we recommend the use of AWS DataSync, an online data transfer service designed to simplify, automate, and accelerate copying large amounts of data to and from AWS storage services. DataSync copies data over the internet or AWS Direct Connect. As a fully managed service, DataSync removes much of the need to modify applications, develop scripts, or manage infrastructure. For more information, seeMigrating Existing Files to Amazon FSx for Windows File Server Using AWS DataSync guide (https://docs.aws.amazon.com/fsx/latest/WindowsGuide/migrate-files-to-fsx-datasync.html).A secondary option is Windowss Robust File Copy (RoboCopy) to copy your files directly to Amazon FSx.Once you have moved your file and folder data, Amazon FSx offers programmatic share management support to help you easily migrate your file share configuration.You must include security ACLs (SACLs) in your data migration to keep using your existing audit controls for file access auditing.Learn more about migrating your existing file shares in thedocumentation guide (https://docs.aws.amazon.com/fsx/latest/WindowsGuide/migrate-to-fsx.html). [Source: https://aws.amazon.com/fsx/windows/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Where can I find code samples?", "output": "Check out the sample code in theseArticles and Tutorials. If you use EMR Studio, you can explore the features using a set ofnotebook examples. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is there a limit on the number of import files that I can upload?", "output": "No. There is no limit on the number of import files that you can upload. However, we do restrict the number of records and servers that you can import. For details, refer to the Migration Hub importlimits (https://docs.aws.amazon.com/migrationhub/latest/ug/limits.html)section in the documentation. [Source: https://aws.amazon.com/migration-hub/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Amazon CloudWatch Application Signals help me monitor business-critical applications?", "output": "Amazon CloudWatch Application Signals discovers application services such as a mortgage payment processor running in EKS and generates a standard set of application metrics for volume, latency, errors and faults of APIs (such as to add users, place orders, pay, etc.) and dependencies (such as calls between application services, to AWS services or to external endpoints). Customers can reflect business impact and importance of application services, their APIs and dependencies by defining service level objectives. New application-centric observability views in the AWS Management Console for CloudWatch will then summarize application health against SLOs and offer a drill down to expediently establish a root cause. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If I use less than 40 hours in my first month of Free Tier use, do the remaining hours roll over to the next month?A: The Amazon WorkSpaces Free Tier allows you to use a combined total of 40 hours per month. Unused hours expire when the new calendar month starts. Limited-time promotion offers might be offered via the Free Tier, refer to the WorkSpacespricing pagefor the latest information.", "output": "A: In the event you exceed 40 hours of use in a month during the Free Tier period, you are billed at the current hourly rate for Amazon WorkSpaces. Limited-time promotion offers might be offered via the Free Tier, refer to the WorkSpacespricing pagefor the latest information. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I receive notifications for file transfers using AWS Transfer Family?", "output": "You can use the Transfer Familys managed workflows to receive notifications for files uploaded over your SFTP, FTPS and FTP server endpoints. Refer tothis blog post (https://aws.amazon.com/blogs/storage/customize-file-delivery-notifications-using-aws-transfer-family-managed-workflows/). Alternatively,you can subscribe to AWS Transfer Family events in AmazonEventBridge to receive notifications usingAmazon Simple Notification Service (SNS). [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I supply my own threat intelligence?", "output": "Yes, GuardDuty allows you to upload your own threat intelligence ortrusted IP address list (https://aws.amazon.com/premiumsupport/knowledge-center/guardduty-trusted-ip-list/). When this feature is used, these lists are only applied to your account and not shared with other customers. [Source: https://aws.amazon.com/guardduty/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the best practices for bootstrapping data into CloudSearch?", "output": "After you\u2019ve launched your domain, the next step is loading your data into Amazon CloudSearch. You\u2019ll likely need to upload a single large dataset, and then make smaller updates or additions as new data comes in. The following guidelines will help make bootstrapping your initial data into CloudSearch quick and easy.1. Use the curl-v command line tool when preparing your script [Source: https://aws.amazon.com/cloudsearch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I back up the contents of my CloudHSM Cluster?", "output": "Your CloudHSM Cluster is backed up on a daily basis by AWS. Keys can also be exported (wrapped) out of your cluster and stored on-premises as long as they were not generated as non-exportable.\" [Source: https://aws.amazon.com/cloudhsm/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens if I specify a DynamoDB table that I don\u2019t have access to?", "output": "The job would fail and the exception would show up in error logs for the job. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How is Amazon SQS different from Amazon MQ?", "output": "If you're using messaging with existing applications, and want to move your messaging to the cloud quickly and easily, we recommend you considerAmazon MQ (https://aws.amazon.com/amazon-mq/). It supports industry-standard APIs and protocols so you can switch from any standards-based message broker to Amazon MQ without rewriting the messaging code in your applications. If you are building brand new applications in the cloud, we recommend you consider Amazon SQS and Amazon SNS. Amazon SQS and SNS are lightweight, fully managed message queue and topic services that scale almost infinitely and provide simple, easy-to-use APIs. [Source: https://aws.amazon.com/sqs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What file types does Amazon Kendra support?", "output": "Amazon Kendra supports unstructured and semi-structured data in .html, MS Office (.doc, .ppt), PDF, and text formats. With theMediaSearch solution (https://aws.amazon.com/blogs/machine-learning/make-your-audio-and-video-files-searchable-using-amazon-transcribe-and-amazon-kendra/), you can also use Amazon Kendra to search audio and video files. [Source: https://aws.amazon.com/kendra/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Amazon AppStream 2.0 support USB devices such as 3D mice?", "output": "Yes. Amazon AppStream 2.0 supports most USB devices such as 3D mice through the Windows Client. All USB devices are disabled by default. Administrators can enable USB devices for their users. [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What restrictions apply to AWS Lambda function code?", "output": "Lambda attempts to impose as few restrictions as possible on normal language and operating system activities, but there are a few activities that are disabled: Inbound network connections are blocked by AWS Lambda, and for outbound connections, only TCP/IP and UDP/IP sockets are supported, and ptrace (debugging) system calls are blocked. TCP port 25 traffic is also blocked as an anti-spam measure. [Source: https://aws.amazon.com/lambda/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Does Bluetooth Low Energy support in FreeRTOS work only with AWS?", "output": "No. The FreeRTOS libraries for Bluetooth Low Energy are open source and under the MIT license so developers can modify according to their specific need. [Source: https://aws.amazon.com/freertos/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What happens after the end of Extended Support period?", "output": "Once Extended Support ends for a version, we will no longer release bug fixes or security updates for that specific version. Domains running unsupported versions will be isolated and data preserved for at least 30 days. Isolated domains can no longer be accessed, and you will have to restore data into a new domain running a supported version. We strongly recommend that you update your domain to a supported version before the end of Extended Support for a specific version. If you need further assistance, please contact AWS Support. [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I set S3 permissions and storage options?", "output": "Amazon Elastic Transcoder enables you to specify which users, groups, and canonical IDs you want to grant access to your transcoded files, thumbnails and playlists, as well as the type of access that you want them to have. You can also specify whether to store transcoded content using Standard or Reduced Redundancy Storage. Please refer toAmazon Elastic Transcoder documentationfor further information. [Source: https://aws.amazon.com/elastictranscoder/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Do EMR Serverless Spark and Hive applications support user-defined functions (UDFs)?", "output": "EMR Serverless supports Java-based UDFs. You can package them as jars, upload them to S3, and use them in your Spark or HiveQL scripts. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I customize the URL of my Transfer Family web app?", "output": "Yes. You can use Amazon CloudFront to associate a custom domain name with your web app. You can also customize your sign-in URL to your Identity Center applications portal through AWS IAM Identity Center if you plan to share multiple AWS applications to your end users. [Source: https://aws.amazon.com/aws-transfer-family/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How much does Amazon EKS cost?", "output": "You pay $0.10 per hour for each Amazon EKS cluster you create and for the AWS resources you create to run your Kubernetes worker nodes. You only pay for what you use, as you use it; there are no minimum fees and no upfront commitments. Find more information in the \u00a0EKS pricing page. [Source: https://aws.amazon.com/eks/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What type of locking does Amazon EFS support?", "output": "Locking in Amazon EFS follows the NFS v4.1 protocol for advisory locking and allows your applications to use both whole file and byte range locks. [Source: https://aws.amazon.com/efs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I monitor Redis OSS CPU utilization?", "output": "ElastiCache provides two different sets of metrics to measure the CPU utilization of your cache depending on your cache deployment choice. When using ElastiCache Serverless, you can monitor the CPU utilization with the ElastiCache Processing Units (ECPU) metric. The number of ECPUs consumed by your requests depends on the vCPU time taken and the amount of data transferred. Each read and write, like the RedisOSS GET and SET commands or the Memcached get and set commands, requires 1 ECPU for each kilobyte (KB) of data transferred. Some RedisOSS commands that operate on in-memory data structures can consume more vCPU time than a GET or SET command. ElastiCache calculates the number of ECPUs consumed based on the vCPU time taken by the command compared to a baseline of the vCPU time taken by a SET or GET command. If your command takes additional vCPU time and transfers more data than the baseline of 1 ECPU, then ElastiCache calculates the ECPUs required based on the higher of the two dimensions.When designing your own cluster, you can monitor EngineCPUUtilization and CPUUtilization. The CPUUtilization metric measures the CPU utilization for the instance (node), and the EngineCPUUtilization metric measures the utilization at the engine process level. You need the EngineCPUUtilization metric in addition to the CPUUtilization metric, as the main Redis OSS process is single threaded and uses just one CPU of the multiple CPU cores available on an instance. Therefore, the CPUUtilization metric does not provide precise visibility into the CPU utilization rates at the engine process level. We recommend that you use both the CPUUtilization and EngineCPUUtilization metrics together to get a detailed understanding of CPU utilization for your RedisOSS clusters.Both sets of metrics are available in all AWS Regions, and you can access these metrics using Amazon CloudWatch or in theconsole (https://console.aws.amazon.com/elasticache/). Additionally, we recommend that you visitthe documentation (https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheMetrics.WhichShouldIMonitor.html)to learn about useful metrics for performance monitoring. [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are network activity events?", "output": "Network activity events record AWS API actions made using VPC endpoints from a private VPC to the AWS service and help you meet your network security investigations use cases. This includes AWS API calls that have successfully passed the VPC endpoint policy and those that were denied access.For example, as the VPC endpoint owner, you can view logs of actions that were denied due to VPC endpoint policies or determine if an actor outside of your data perimeter is trying to access the data in your S3 buckets. Unlike management and data events that are delivered to both the API caller and the owner of the resource, network activity events are only delivered to the owner of the VPC endpoint.To record network activity events, you must explicitly enable them when configuring your trail or event data store and choose event source(s) of the AWS service(s) you want to collect activity on. You may also add additional filters such as filtering by VPC endpoint ID or logging only the Access Denied errors. Network activity events incur additional charges. For more information, seeCloudTrail pricing (https://aws.amazon.com/cloudtrail/pricing/). [Source: https://aws.amazon.com/cloudtrail/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I import an OpenAPI definition to create a HTTP API?", "output": "Yes, you can import an API definition using OpenAPI 3. It will result in the creation of routes, integrations, and API models. For more information on importing OpenAPI definitions, see ourdocumentation (https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-import.html). [Source: https://aws.amazon.com/api-gateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does AWS WAF pricing work? Are there any upfront costs?", "output": "AWS WAF charges based on the number of web access control lists (web ACLs) that you create, the number of rules that you add per web ACL, and the number of web requests that you receive. There are no upfront commitments. AWS WAF charges are in addition toAmazon CloudFront pricing (https://aws.amazon.com/cloudfront/pricing/), theApplication Load Balancer (ALB) pricing (https://aws.amazon.com/elasticloadbalancing/pricing/),Amazon API Gateway pricing (https://aws.amazon.com/api-gateway/pricing/), and/orAWS AppSync pricing (https://aws.amazon.com/appsync/pricing/). [Source: https://aws.amazon.com/waf/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What type of filtering does CloudWatch Logs Live Tail support?", "output": "You can filter based on Log Groups, Log Streams, and filter by keywords. The log groups selection supports multiple selections across multiple accounts when in the monitoring account (cross-account observability). The log streams selection supports multiple selections based on name or a prefix. Filter by keywords is case sensitive. One or more keywords (for instance., error, exception, or fault) can be entered to further narrow the focus of the search. You can type in the keywords or copy and paste from the samples provided in the Info panel.Learn more about filter patterns. (https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/FilterAndPatternSyntax.html) [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is there an additional fee to enable Multi-Attach?", "output": "No. Multi-Attach can be enabled on an EBS Provisioned IOPS volume and there will be charges for the storage (GB-Mo) and IOPS (IOPS-Mo) provisioned. [Source: https://aws.amazon.com/ebs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is AWS Storage Gateway FedRAMP compliant?", "output": "Yes, AWS Storage Gateway is FedRAMP compliant with High authorization level in the AWS GovCloud (US) Regions, and Moderate authorization level in the AWS US Commercial Regions. More information can be found on theAWS FedRAMP compliance page (https://aws.amazon.com/compliance/fedramp/). [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I copy my Amazon WorkSpaces images to other AWS Regions?", "output": "A: Yes, you can use the WorkSpaces console, APIs, or CLI to copy your WorkSpaces Images to other AWS Regions where WorkSpaces is available. Seeour documentationfor more information. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is a certificate required?", "output": "A certificate is only required if you wish to use your custom domain name with your distribution. All Lightsail distributions are created with a unique Amazon CloudFront domain name that is HTTPS-enabled. However, if you wish to use your custom domain with your distribution, then you need to attach a certificate for your custom domain to your distribution. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How can I generate more than one thumbnail per job?", "output": "You can specify a thumbnail creation interval in seconds to create one thumbnail every n seconds. To create thumbnails in more than one size, you need to create different jobs. [Source: https://aws.amazon.com/elastictranscoder/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Amazon Chime?", "output": "Amazon Chime is a high-quality communications service that transforms online meetings with an easy-to-use app which works seamlessly across all your devices. With Amazon Chime, you can schedule and attend online meetings and video conferences, and chat, call, and collaborate, inside and outside your organization, all with a single app. Now you can work productively from wherever you are. [Source: https://aws.amazon.com/chime/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is an Amazon MQ network of brokers?", "output": "Amazon MQ for ActiveMQ uses the network of brokers feature that is part of Apache ActiveMQ. A network of brokers consists of multiple brokers connected in a mesh. Brokers in the network share information about the clients and destinations each broker hosts. The brokers use this information to route messages through the network. With Amazon MQ, the brokers in the network can either be active-standby brokers (each active broker in the network has a standby node, with shared storage, that will take over if the active node fails), or single-instance brokers (if the node fails, it will be unavailable until it is restarted). Each broker in the network maintains its own unique message store which is replicated across multiple availability zones (AZs) within a region for active/standby brokers, using durability-optimized storage. The nodes in the network forward messages to each other, so messages are stored by a single broker at any given time. You should use network of brokers if you require high availability with fast reconnection in the case of broker failure, or if you need the ability to scale horizontally. [Source: https://aws.amazon.com/amazon-mq/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I share a message queue?", "output": "You can associate an access policy statement (and specify the permissions granted) with the message queue to be shared. Amazon SQS provides APIs for creating and managing access policy statements:AddPermissionRemovePermissionSetQueueAttributesGetQueueAttributesFor more information, see theAmazon SQS API Reference (https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/Welcome.html). [Source: https://aws.amazon.com/sqs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are some of the ideal use cases for R5b instances?", "output": "R5b instances are ideal for large relational database workloads, including Microsoft SQL Server, SAP HANA, IBM DB2, and Oracle that run performance intensive applications such as commerce platforms, ERP systems, and health record systems. Customers looking to migrate large on-premises workloads with large storage performance requirements to AWS will find R5b instances to be a good fit. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started with sharing my images?", "output": "A: Log on to theAmazon WorkSpaces consoleand navigate to the \u201cImages\u201d section from the left hand navigation menu. Simply select the image you would like to share, click on the \u201cActions\u201d button and select the \u201cView details\u201d option to get started. Seeour documentation on sharing images. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why should I use Amazon ECS?", "output": "Amazon ECS is a fully managed container orchestration service makes it easy to use containers to deploy and manage long-running applications, services, and batch processes without needing to install, operate, and scale your own cluster management infrastructure. Amazon ECS maintains application availability and allows you to scale your containers up or down to meet your application's capacity requirements. When used with AWS Fargate, Amazon ECS allows you to deploy applications without needing to provision, manage, or scale compute infrastructure, reducing the time it takes for you to build, deploy, or migrate your containerized applications successfully. Furthermore, Amazon ECS is integrated with familiar features like ELB, Amazon Virtual Private Cloud (VPC), IAM, Application AutoScaling, Amazon CloudWatch, and Amazon Elastic File System (EFS), meaning that you don\u2019t need to build or maintain generalized abstractions. [Source: https://aws.amazon.com/ecs/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I calculate Extended Support charges for my domains?", "output": "Domains running versions under Extended Support will be charged an additional flat fee/Normalized Instance Hour (NIH). NIH is computed as a factor of the instance size (e.g. medium, large), and the number of instance hours. For example, if you are running an m7g.medium.search instance for 24 hours in the US East (North Virginia), which is priced at $0.068/hour (on-demand), you will typically pay $1.632 ($0.068x24) as the instance cost. If you are running a version that is in Extended Support, you will pay an additional $0.0065/NIH, which is computed as $0.0065 x 24 (number of instance hours) x 2 (size normalization factor; 2 for medium-sized instances), which comes to $0.312 for Extended Support for 24 hours. The total amount you will pay for 24 hours will be a sum of the standard instance usage cost (excluding storage) and the Extended Support cost, which is $1.944 ($1.632+$0.312). Please seedocumentation (https://docs.aws.amazon.com/opensearch-service/latest/developerguide/what-is.html)for more information. [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is the ElastiCache Serverless availability Service Level Agreement (SLA)?", "output": "ElastiCache Serverless automatically stores data redundantly across multiple AZs and provides a 99.99% availabilityService Level Agreement (SLA) (https://aws.amazon.com/elasticache/sla/)for all workloads. [Source: https://aws.amazon.com/elasticache/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is a chunk?", "output": "Upon receiving the data from a producer, Kinesis Video Streams stores incoming media data as chunks. Each chunk consists of the actual media fragment, a copy of media metadata sent by the producer, and the Kinesis Video Streams-specific metadata such as the fragment number, and server-side and producer-side timestamps. When a consumer requests media data through theGetMedia API (https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/API_dataplane_GetMedia.html)operation, Kinesis Video Streams returns a stream of chunks, starting with the fragment number that you specify in the request. [Source: https://aws.amazon.com/kinesis/video-streams/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is streaming data?", "output": "Streaming data (https://aws.amazon.com/what-is/streaming-data/)is a continuous stream of small records or events (a record or event is typically a few kilobytes) generated by thousands of machines, devices, websites, and applications. Streaming data includes a wide variety of data, such as log files, generated by customers using your mobile or web applications, ecommerce purchases, in-game player activity, information from social networks, financial trading floors, geospatial services, security logs, metrics, and telemetry from connected devices or instrumentation in data centers. Streaming data services such as Amazon MSK and Amazon Kinesis Data Streams make it easy for you to continually collect, process, and deliver streaming data. [Source: https://aws.amazon.com/msk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What features are part of Worldwide SMS capability?", "output": "You can use Amazon SNS to deliver SMS (text) messages to 200+ countries. You must obtain prior permission from recipients to send SMS messages to their phone numbers, where required by local law and regulations. Amazon SNS now delivers you SMS messages via AWS End User Messaging. Furthermore, you can set account and message-level spend quotas to avoid inadvertent overruns. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What are the benefits of using CloudWatch Application Insights for .NET and SQL Server?", "output": "Automatically recognize application metrics and logs: It scans your application resources, provides a list of recommended metrics and logs to monitor, and sets them up automatically, making it easier to set up monitoring for your applications.Intelligent problem detection: It uses built-in rules and machine learning algorithms to dynamically monitor and analyze symptoms of a problem across your application stack and detect application problems. It helps you reduce the overhead of dealing with individual metric spikes, or events, or log exceptions, and instead get notified on real problems, along with contextual information these problems.Faster troubleshooting: It assesses the detected problems to give you insights on them, such as the possible root cause of the detected problem and list of metrics and logs impacted because of the problem. You can provide feedback on generated insights to make the problem detection engine specific to your use case. [Source: https://aws.amazon.com/cloudwatch/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Why does ACM use CNAME records for DNS validation instead of TXT records?", "output": "Using a CNAME record allows ACM to renew certificates for as long as the CNAME record exists. The CNAME record directs to a TXT record in an AWS domain (acm-validations.aws) that ACM can update as needed to validate or re-validate a domain name, without any action from you. [Source: https://aws.amazon.com/certificate-manager/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is AWS Backup PCI compliant?", "output": "Yes. AWS Backup isPCI-DSS (https://aws.amazon.com/compliance/pci-dss-level-1-faqs/)compliant, which means you can use it to transfer payment information. You can download the PCI Compliance Package inAWS Artifact (https://aws.amazon.com/artifact/)to learn more about how to achieve PCI Compliance on AWS. [Source: https://aws.amazon.com/backup/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Amazon Transcribe?", "output": "Amazon Transcribe is an AWS Artificial Intelligence (AI) service that makes it easy for you to convert speech to text. Using Automatic Speech Recognition (ASR) technology, you can use Amazon Transcribe for a variety of business applications, including transcription of voice-based customer service calls, generation of subtitles on audio/video content, and conduct (text-based) content analysis on audio/video content. [Source: https://aws.amazon.com/transcribe/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What tools does AWS Shield Advanced provide me to mitigate DDoS attacks?", "output": "AWS Shield Advanced manages mitigation of layer 3 and layer 4 DDoS attacks. This means that your designated applications are protected from attacks like UDP Floods, or TCP SYN floods. In addition, for application layer (layer 7) attacks, AWS Shield Advanced can detect attacks like HTTP floods and DNS floods. You can use AWS WAF to apply your own mitigations, or, if you have Business or Enterprise support, you can engage the 24X7 AWS Shield Response Team (SRT), who can write rules on your behalf to mitigate Layer 7 DDoS attacks. [Source: https://aws.amazon.com/shield/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do Lightsail load balancers route traffic to my target instances?", "output": "Lightsail load balancers direct traffic to your healthy target instances based on a round robin algorithm. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which versions of HBase are supported on Amazon EMR?", "output": "You can look at the latest HBase versions supported on Amazon EMRhere. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Will Storage Gateway HA still have the ability to restart if its connection to AWS is broken?", "output": "Yes, gateways will be reinitialized using the same underlying shared storage, preserving local cache and upload queues. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Where is the metadata for Logical Names and Iterations stored?", "output": "The metadata that allows the EMR Kinesis input connector to work in scheduled periodic workflows is stored in Amazon DynamoDB. You must provision an Amazon Dynamo DB table and specify it as an input parameter to the Hadoop Job. It is important that you configure appropriate IOPS for the table to enable this integration. Please refer to the getting startedtutorialfor more information on setting up your Amazon Dynamo DB table. [Source: https://aws.amazon.com/emr/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What Bluetooth Low Energy versions are supported?", "output": "FreeRTOS supports Bluetooth Low Energy versions 4.2 and above. Bluetooth Low Energy version 4.2 raises the security bar by adding support for Bluetooth Low Energy Secure Connections, an enhanced security feature introduced in Bluetooth Low Energy version 4.2 to authenticate a peer device and create an encrypted channel. [Source: https://aws.amazon.com/freertos/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Which previous-generation instances will receive Nitro System support and within what time frame?", "output": "We have enabled Nitro system support for Amazon EC2 C1, H1, M1, T1, D2, M2, T2, C3, I3, M3, R3, C4, M4, and R4 instances. Customers of these instances may receive a maintenance notification of migration to Nitro System. We will add support for additional instance types in 2024. [Source: https://aws.amazon.com/ec2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "If I am a new user to GuardDuty, is Runtime Monitoring turned on by default for my accounts?", "output": "No. GuardDuty Runtime Monitoring is the only protection plan that is not enabled by default when you turn on GuardDuty for the first time. The feature can be activated from the GuardDuty console on the Runtime Monitoring page or through the API. New GuardDuty accounts created using the AWS Organizations auto-enable feature will not have Runtime Monitoring turned on unless the Auto-enable for Runtime Monitoring option is turned on. [Source: https://aws.amazon.com/guardduty/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I handle resource name conflicts when nesting applications?", "output": "Specify a unique name for each nested application in your SAM template. Resources created by the nested application will be scoped to the application's unique name. [Source: https://aws.amazon.com/serverless/serverlessrepo/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does tiered storage work?", "output": "Apache Kafka stores data in files called log segments. As each segment is complete, based on the size configured at cluster or topic level, it is copied to the low-cost storage tier. Data is held in performance-optimized storage for a specified retention time or size, and then its deleted. There is a separate time and size limit setting for the low-cost storage, which is longer than the primary storage tier. If clients request data from segments stored in the low-cost tier, the broker will read the data from it and serve the data in the same way as if its being served from the primary storage. [Source: https://aws.amazon.com/msk/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I sign up for Lightsail?", "output": "To start using Lightsail, choose Get Started and log in. You use your Amazon Web Services account to access Lightsail; if you don't already have one, you'll be prompted to create one. [Source: https://aws.amazon.com/lightsail/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What monitor configurations are supported by the AppStream 2.0 Client?", "output": "For browser-based streaming sessions, AppStream 2.0 supports the use of up to two monitors with a maximum display resolution of 2560x1440 pixels per monitor. The AppStream 2.0 client for Windows or macOS supports up to 4 monitors with a maximum display resolution of 2560x1440 pixels per monitor. For streaming sessions that are supported by the Graphics Design and Graphics Pro instance families, the AppStream 2.0 client also supports the use of up to 2 monitors with a maximum display resolution of 4096x2160 pixels per monitor. [Source: https://aws.amazon.com/appstream2/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What does delivery of a message from Amazon SNS to an AWS Lambda function do?", "output": "A message delivery from Amazon SNS to an AWS Lambda function creates an instance of the AWS Lambda function and invokes it with your message as an input. For more information on message formats, please refer to theAmazon SNS documentationand the AWS Lambda documentation. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How does Amazon FSx File Gateway provide high availability?", "output": "Just like Amazon S3 File Gateway, Amazon FSx File Gateway achieves high availability on VMware by running a series of continuous health checks against the operation of the gateway that connect to the VMware monitoring service. During a hardware, software, or network failure, VMware will trigger a gateway restart on a new host or on its existing host if the host is still operational. At a maximum, users and applications will experience up to 60 seconds of downtime during a restart. After a restart, connections to the gateway are automatically re-established, never needing manual intervention. On re-initialization the gateway will send metrics back to the cloud to give customers a full view of the availability event. [Source: https://aws.amazon.com/storagegateway/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is there a charge for the automated daily hourly snapshots?", "output": "There is no additional charge for the automated hourly snapshots. The snapshots are stored for free in an Amazon OpenSearch Service S3 bucket and will be made available for node recovery purposes. [Source: https://aws.amazon.com/opensearch-service/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "When should I use Origin Shield?", "output": "Origin Shield is ideal for workloads with viewers that are spread across different geographical regions or workloads that involve just-in-time packaging for video streaming, on-the-fly image handling, or similar processes. Using Origin Shield in front of your origin will reduce the number of redundant origin fetches by first checking its central cache and only making a consolidated origin fetch for content not already in Origin Shields cache. Similarly, Origin Shield can be used in a multi-CDN architecture to reduce the number of duplicate origin fetches across CDNs by positioning Amazon CloudFront as the origin to other CDNs. Refer to the Amazon CloudFront Developer Guide for more details on these and otherOrigin Shield Use Cases (https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/origin-shield.html#origin-shield-use-cases). [Source: https://aws.amazon.com/cloudfront/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What data sources does AWS Glue support?", "output": "AWS Glue can integrate with more than 80 data sources on AWS, on premises, and on other clouds. The service natively supports data stored in the following databases in your Amazon Virtual Private Cloud (Amazon VPC) running on Amazon Elastic Compute Cloud (Amazon EC2): [Source: https://aws.amazon.com/glue/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How would a user subscribe for notifications to be delivered over SMS?", "output": "Please refer to the 'SMS Related Question' section below. [Source: https://aws.amazon.com/sns/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Are there limits to the service?", "output": "The number of transcoding pipelines, transcoding presets and outputs per job have limits. Most of these limits can be adjusted on a customer-by-customer basis. For the current limits, please refer to thedocumentation. [Source: https://aws.amazon.com/elastictranscoder/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How many indices can I add?", "output": "Neptune Analytics supports one vector search index on embeddings stored in your graph data. [Source: https://aws.amazon.com/neptune/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I get started with AWS CodeCommit?", "output": "You can sign in to theAWS Management Console (https://console.aws.amazon.com/codecommit), create a repository, and start working with the repository using Git. If you want an introduction to the service, seeGetting Started (https://aws.amazon.com/codecommit/getting-started/), which includes a step-by-step tutorial. [Source: https://aws.amazon.com/codecommit/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What performance does S3 One Zone-IA storage offer?", "output": "S3 One Zone-IA storage class offers the same latency and throughput performance as the S3 Standard and S3 Standard-Infrequent Access storage classes. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What types of SmartCards are officially supported?", "output": "A: WorkSpaces officially Supports CAC and PIV SmartCards. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "How do I disable email notifications being sent out when my document is updated?", "output": "You can disable notification by selecting Disable email notification in the Notification Settings section under File Information in the top right hand corner of the right navigation pane. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I locally test my AWS Lambda functions using AWS Cloud9?", "output": "Yes. AWS Cloud9 can simulate the AWS Lambda execution environment for Node.js and Python to run your functions locally in the IDE. This enables you to test your serverless applications with step-through debugging without uploading your application changes to Lambda. Once tested, you can also deploy your application changes to Lambda directly from the IDE. [Source: https://aws.amazon.com/cloud9/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "In which AWS regions is Amazon WorkDocs available?", "output": "Please visit theProducts and Services by Region. [Source: https://aws.amazon.com/workdocs/faq/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can I use AWS Identity and Access Management (IAM) to manage access to AWS CodeCommit?", "output": "Yes. AWS CodeCommit supportsresource-level permissions (https://docs.aws.amazon.com/IAM/latest/UserGuide/PermissionsOverview.html). For each AWS CodeCommit repository, you can specify which users can perform which actions. You can also specify AWS multi-factor authentication (MFA) for a CodeCommit action. This allows you to add an extra level of protection for destructive actions such as deleting repositories. In addition to the AWS CodeCommit APIs, you can also specifygit pullandgit pushas actions to control access from Git clients. For example, you can create a read-only user for a repository by allowing that user access togit pullbut notgit pushon the repository. For more information on using IAM with AWS CodeCommit, seeAuthentication and Access Control for AWS CodeCommit (https://docs.aws.amazon.com/codecommit/latest/userguide/auth-and-access-control.html). For more information on authenticating API access using MFA, seeConfiguring MFA-Protected API Access (http://docs.aws.amazon.com/IAM/latest/UserGuide/MFAProtectedAPI.html). [Source: https://aws.amazon.com/codecommit/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What kinds of operations can I perform with S3 Object Lambda?", "output": "Any operation supported in a Lambda function is supported with S3 Object Lambda. This gives you a wide range of available options for processing your requests. You supply your own Lambda function to run custom computations against GET, LIST, and HEAD requests, giving you the flexibility to process data according to the needs of your application. Lambda processing time is limited to a maximum of 60 seconds. For more details, see theS3 Object Lambda documentation. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Is there a minimum storage duration charge for Amazon S3 Glacier Instant Retrieval?", "output": "S3 Glacier Instant Retrieval is designed for long-lived, rarely accessed data that is retained for months or years. Objects that are archived to S3 Glacier Instant Retrieval have a minimum of 90 days of storage, and objects deleted, overwritten, or transitioned before 90 days incur a pro-rated charge equal to the storage charge for the remaining days. View theAmazon S3 pricing pagefor information about Amazon S3 Glacier Instant Retrieval pricing. [Source: https://aws.amazon.com/s3/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "Can Amazon help me automatically optimize for the running mode that is the most cost efficient for my use case?", "output": "A: Yes. Amazon provides theCost Optimizer for Amazon WorkSpaces, which analyzes usage data to determine the most cost-effective billing option. It outputs a daily report, and can optionally convert WorkSpaces to the most cost-effective billing option. [Source: https://aws.amazon.com/workspaces/faqs/]"}
{"instruction": "Answer the following AWS FAQ question", "input": "What is Amazon EBS encryption?", "output": "Amazon EBS encryption offers seamless encryption of EBS data volumes, boot volumes and snapshots, eliminating the need to build and maintain a secure key management infrastructure. EBS encryption enables data at rest security by encrypting your data using Amazon-managed keys, or keys you create and manage using the AWS Key Management Service (KMS). The encryption occurs on the servers that host EC2 instances, providing encryption of data as it moves between EC2 instances and EBS storage. For more details, see Amazon EBS encryption in the Amazon EC2 User Guide. [Source: https://aws.amazon.com/ebs/faqs/]"}
